---
title: "Tutorial de knn en R: iris dataset"
description: |
  Flujo de trabajo paso a paso
author:
  - name: Javier 츼lvarez Li칠bana
    url: https://javier-alvarez-liebana.github.io
    affiliation: Universidad Complutense de Madrid
    affiliation_url: 
date: "`r Sys.Date()`"
output:
    distill::distill_article:
        highlight: kate
        colorlinks: true
        code_folding: false
        toc: true            
        toc_depth: 3     
---

```{r setup, include = FALSE}
# Ajuste comunes de los chunk
knitr::opts_chunk$set(fig.width = 8, fig.asp = 1, out.width = "100%",
                      message = FALSE, warning = FALSE,
                      echo = TRUE, res = 400)
```

# Objetivo {#objetivo}

El objetivo de este peque침o tutorial es saber aplicar un flujo de trabajo en el entorno `{tidymodels}` para poder implementar un algoritmo de clasificaci칩n knn en `R`. Puedes ver m치s detalles y funcionalidades en la web oficial del paquete: <https://www.tidymodels.org/>


## Paquetes necesarios

Necesitaremos los siguientes paquetes

* **An치lisis exploratorio num칠rico**: paquete `{skimr}`
* **Depuraci칩n y preprocesamiento**: paquete `{tidyverse}`
* **Modelizaci칩n**: paquete `{tidymodels}` para modelos


```{r paquetes}
# Borramos
rm(list = ls())

# Paquetes
library(skimr) # resumen num칠rico
library(tidymodels) # depuraci칩n datos
library(tidyverse) # modelos
```

# Datos {#datos}

Los datos utilizados en este primer tutorial ser치 el famoso dataset conocido como `iris`, que pasaremos a formato tibble nada m치s empezar

```{r carga-datos}
iris <- as_tibble(iris)
glimpse(iris)
```

## An치lisis exploratorio (num칠rico)

Antes de tomar ninguna decisi칩n con los datos lo primero que deber칤amos hacer es **echar un vistazo num칠rico** a c칩mo se comportan las variables. Dado que vamos a clasificar, lo primero que deber칤amos observar es como se distribuyen los niveles de nuestra variable objetivo.

```{r}
# Objetivo: predecir la especie de las plantas
iris %>% count(Species) %>% mutate(porc = 100 * n / sum(n))
```

Adem치s con la funci칩n `skim()` del paquete `{skimr}` podemos **extraer algunas estad칤sticas b치sicas** de nuestros datos.

```{r skim}
# Resumen num칠rico
iris %>% skim()
```



# Primer flujo de trabajo: knn

## Filosof칤a tidymodels

La idea detr치s de `{tidymodels}` es **tratar por separado** la depuraci칩n y preparaci칩n de los datos, el modelo o paradigma de aprendizaje que se quiere aplicar, la optimizaci칩n de los par치metros de dicho modelo, el ajuste, la evaluaci칩n y la predicci칩n correspondiente, **creando un flujo de trabajo muy flexible**. La **filosof칤a es la misma que hay detr치s de cocinar un plato**:

1. Primero **escribimos la receta**, una lista de pasos e instrucciones.
2. Despu칠s **preparamos la herramientas y utensilios para cocinar** (nuestro modelo).
3. Con la **receta + utensilios** podemos cocinar el plato muchas veces, con **distintos lotes de ingredientes (datos)**.

Tambi칠n podemos aplicar una receta distinta a distintos ingredientes, o incluso combinar partes de dos recetas. La idea es que tengamos guardado, y expl칤citamente detallado, cada uno de los componentes, para poder **combinarlos entre ellos**.

## Fase 1: muestreo y particiones

* Muestreo inicial.
* Partici칩n train-test estratificada por la variable objetivo.

Una de las **primeras acciones a realizar** es un **muestreo inicial** de los datos, que en este caso no ser치 necesario por la poca cantidad de registros disponibles, as칤 que empezaremos directaemnte con una **partici칩n train-test** estratificado por la variable `Species`: repartiremos en **70-30%** los datos **PERO asegur치ndonos de que la proporci칩n de 0's-1's se preserva**.

```{r sample, warning = FALSE}
# Partici칩n 70-30%: estratificada para que mantenga clases
# con el argumento pool podemos afinar mejor la estratificaci칩n
# para hacerla m치s exacta (por ejemplo, pool = 0.05)
iris_split <- initial_split(iris, strata = Species, prop = 0.7)
iris_split
```

En `iris_split` tenemos **guardada la informaci칩n** de lo que queremos hacer cuando lo apliquemos, pero hasta que no se aplique no realiza ninguna acci칩n.

```{r split}
iris_train <- training(iris_split)
iris_test  <- testing(iris_split)

# Comprobamos estratos
iris_train %>% count(Species) %>% mutate(porc = 100 * n / sum(n))
iris_test %>% count(Species) %>% mutate(porc = 100 * n / sum(n))
```

**Reminder**: los conjuntos que salen de `initial_split()` siguen a lo largo de todo el proceso (pero en conjuntos separados).


## Fase 2: exploraci칩n

### Resumen num칠rico: skim

Con `skim()`, del paquete `{skimr}`, podemos realizar un **primer an치lisis num칠rico** muy sencillo, haciendo uso de la funci칩n `skim()`

```{r}
library(skimr)
iris %>% skim()
```

No parece que tengamos **problemas de codificaci칩n o rango**: los valores parecen valores permitidos seg칰n lo que representa la variable. Adem치s tampoco tenemos **datos ausentes**, ya que `complete_rate` sale en todas 1 (`n_missing` est치 a cero). A la vista de los peque침os histogramas y los percentiles, no parece que tengamos **xcesivos valores at칤picos (outliers)** (al menos muy evidentes, adem치s la mediana y media se parecen entre s칤). Quiz치s la **variable con mayor dispersi칩n** sea `Petal.Length`.


Adem치s todas las **variables predictoras son num칠ricas**: recordemos que para aplicar las m칠tricas que conocemos en el KNN **necesitamos que sean num칠ricas**. En caso contrario nos tocar칤a **recategorizar**


### Balanceamiento de la variable objetivo


Una vez que hemos echado un vistazo a qu칠 tenemos (de forma muy muy preliminar), lo primero a hacer en un **problema de clasificaci칩n** es determinar **cu치l es nuestra variable objetivo**: nuestra variable $Y$ que vamos a clasificar, y que debe ser categ칩rica. En este caso nuestra variable objetivo ser치 la variable `Species`: vamos a intentar clasificar las flores, siendo la variable objetivo una variable que puede tomar 3 categor칤as (algo que podemos ver y resumir con `count()`).

```{r}
iris %>% count(Species)
```

En nuestro caso la variable objetivo est치 **.bg-purple_light[balanceada]**: tenemos proporciones similares para cada una de las modalidades.

### Importancia de las variables: objetivo vs predictores


Otra de las acciones clave ser치 analizar c칩mo se **comporta la variable objetivo en funci칩n de los valores de cada variable**. 쯃a longitud del s칠palo media es similar en cada especie de planta? 쯏 la anchura del p칠talo? Con ello podremos tener una idea preliminar de la **importancia de las variables** en la clasificaci칩n. Para ello combinaremos `group_by()` con `summarise()` (nos construye res칰menes num칠ricos, con la funci칩n que le pidamos).


```{r}
iris %>%
  group_by(Species) %>% 
  summarise("mean_long_sep" = mean(Sepal.Length)) %>% 
  ungroup()
```


Podemos hacer varias a la vez usando `across()`: le tendremos que indicar las variables a recorrer, y la funci칩n a aplicar en todas ellas.

```{r}
iris %>%
  group_by(Species) %>%
  summarise(mean = across(Sepal.Length:Petal.Width, mean)) %>% 
  ungroup()
```


Si nos fijamos en cada una de ellas:

* Las **variables relacionadas con el s칠palo** no parece que cambien mucho de una especie a otra: seguramente **no sean influyentes]** en nuestra clasificaci칩n.

* Las **variables relacionadas con el p칠talo** si parecen ser determinantes ya que la especie setosa tiene valores muy peque침os. Seguramente lo m치s complicado sea clasificar entre versicolor y virginica (se diferencia muy ligeramente)


### Colinealidad

Otro de los aspectos a considerar antes de tomar decisiones ser치 **analizar la relaci칩n entre las variables]**, empezando por la posible relaci칩n lineal, calculando la matriz de correlaciones con las herramientas de la librer칤a `{corrr}`. **Importante**: solo podemos pasarle las variables num칠ricas de la tabla.

```{r}
library(corrr)
correlate(iris %>% select(where(is.numeric)))
```


La matriz de correlaciones ser치 **siempre sim칠trica** y en la diagonal siempre ser치 1 (podemos indicarle que queremos que nos muestre con el argumento `diagonal = ...`). La matriz de correlaciones ser치 **siempre sim칠trica** y en la diagonal siempre ser치 1 (podemos indicarle que queremos que nos muestre con el argumento `diagonal = ...`)


```{r}
correlate(iris %>% select(where(is.numeric)), diagonal = "*")
```

Tambi칠n podemos mostrarla algo m치s est칠tica **redondeando los valores** con `fashion()`

```{r}
correlate(iris %>% select(where(is.numeric))) %>% fashion()
```

Incluso visualizarla con el paquete `{corrplot}`

```{r}
library(corrplot)
cor_matrix <- cor(iris %>% select(where(is.numeric)))
corrplot(cor_matrix)
```


```{r}
corrplot(cor_matrix, method = "number")
```

```{r}
corrplot(cor_matrix, method = "color")
```



```{r}
corrplot(cor_matrix, method = "ellipse")
```



En este caso tenemos dos variables muy correlacionadas: `Petal.Length` y `Petal.Width`, con una correlaci칩n de casi 1, lo que nos indica que nos van a aportar **informaci칩n redundante** una de la otra, provocando **problemas de colinealidad**.

Nuestro caso ideal ser칤a aquel en el que todas fuesen independientes (o al menos incorreladas entre s칤, sin dependencia lineal), para **maximizar la informaci칩n de los datos**. Si dos variables nos aportan lo mismo, una seguramente sobre (ya que solo nos va a aportar ruido). Veremos m치s adelante otras herramientas para cuantificar la dependencia (no solo lineal, y no solo de variables cuanti)

Tambi칠n aprenderemos a **visualizar los datos**, un paso CLAVE en el an치lisis exploratorio y la depuraci칩n, pero m치s adelante.

## Fase 3: modificaci칩n



* Asignar roles
* Recategorizar
* Tratamiento de outliers
* Tratamiento de datos ausentes
* Tratamiento de fechas
* Selecci칩n de variables
* Filtro de correlaci칩n
* Filtro de varianza cero
* Estandarizaci칩n por rango y/o normalizaci칩n (tipificaci칩n)
  
  
La lista de arriba son **algunas de las opciones que quiz치s querramos hacer** con nuestras variables antes de poder aplicar un modelo. Todo ello lo incluiremos en una recta, y vamos a empezar en este primer tutorial por una **receta sencilla**


### Definici칩n de la recta

Con la informaci칩n obtenida de la anterior fase, en la **fase de modificaci칩n o depuraci칩n** es donde tendremos que tomar decisiones para **preparar nuestros datos** de manera adecuada. Y para ello ser치 **fundamental conocer el algoritmo** que vamos a aplicar. 

El primer paso en nuestra receta ser치 indicarle en `recipe()` los **datos** y la **춺f칩rmula췉** de nuestro modelo (en nuestro caso le indicaremos que vamos la objetivo ser치 `Species` frente al resto de predictoras num칠ricas). La receta **guardar치 los roles**: 4 predictoras y 1 objetivo

```{r}
iris_rec <-
  # F칩rmula y datos
  recipe(data = iris_train, Species ~ .)
iris_rec
iris_rec %>% summary()
```

### Asignar roles

Dicha receta la hemos llamado `iris_rec` ya que **podemos querer aplicarla** para preprocesar antes de aplicar distintos modelos de clasificaci칩n  (치rboles, knn, etc): aunque el modelo sea distinto, **la receta previa puede ser la misma**. Vamos a complicar un poco nuestra receta **indic치ndole algunos roles especiales en nuestros datos** (los roles son fundamentales ya que dependiendo del rol asignado podremos 춺llamar췉 a nuestras variables).

* `update_role()`: actualizar el rol de la variable (lo machaca el que existiese).
* `add_role()`: a침adir rol a la variable (am칠n de los que ya tuviese asignados).
* `remove_role()`: eliminar rol.

Dado que el tratamiento de outliers lo estamos haciendo de manera distinta en las variables de s칠palo que en las de p칠talo, lo primero que haremos es **asignar** roles (sin eliminar el rol de predictor que ya tiene, as칤 que lo haremos con `add_role()`)

```{r}
iris_rec <-
  iris_rec %>%
  # Roles
  add_role(starts_with("Sepal"), new_role = "sepal") %>% 
  add_role(starts_with("Petal"), new_role = "petal")
iris_rec
iris_rec %>% summary()
```


En este caso adem치s todas las variables son num칠ricas y no hay aparentemente problemas de codificaci칩n. F칤jate que **nuestra receta no ha realizado ning칰n paso**, es algo as칤 como la **receta escrita que tenemos guardada en un caj칩n** para preparar un plato: la receta por s칤 sola no se pone a cocinarte men칰s, simplemente es una lista de instrucciones, lista para cuando la necesites. Las funciones que empiezan por `step_` tienen implementadas muchas de las funcionalidades que podemos realizar en depuraci칩n con `{tidyverse}`. La diferencia al incluirlo en la receta es que **se ejecutar치 cada vez que dicha receta se aplique (tanto a train como a test)**.

### Tratamiento de outliers (tidyverse)

Una de las partes m치s importantes de la fase de exploraci칩n y modificaci칩n es la **detecci칩n de outliers**, pudiendo tener diferentes definiciones de valor at칤pico:

#### Respecto a media

* **At칤pico respecto a media**: ser치 un dato muy alejado de la **media de la variable**. 쮺u치nto de alejado? Una definici칩n habitual es definir un dato at칤pico como aquel que se aleja de la media $k$ veces la desviaci칩n t칤pica (un valor habitual es $k = 2.5$).

$$x_i > \overline{x} + k* s_{j} \quad \text{ o bien } \quad x_i < \overline{x} - k *s_{j}$$

Dicha definici칩n de at칤pico solo tendr치 sentido cuando la **media sea representativa** de tu distribuci칩n, es decir, siempre y cuando tengamos cierta simetr칤a (ya que sino, la media al ser poco robusta se perturbar치 f치cilmente).


Para detectarlos usaremos el paquete `{outliers}` y su funci칩n `scores()`, que nos dar치 en cada caso una **"puntuaci칩n" de cada observaci칩n**. En caso de que queramos **detectarlos respecto a la media**, le indicaremos que `type = "z"`: nos devolver치 precisamente el valor $k$ (si aplicamos valor absoluto), ya que har치 cada observaci칩n menos la media y la dividir치 entre la desviaci칩n t칤pica.


```{r}
library(outliers)
abs(scores(c(1, -1, 0, 5, 2, 1.5, 0.5, -0.3, 0, 2, 1.7, 0.2, -0.8), type = "z"))
```

De forma que podamos detectar muy f치cil los outliers en funci칩n de los estrictos que queramos ser con ese $k$. El tipo `type = "chisq"` nos hace algo parecido pero elevando las desviaciones al cuadrado y diviendo por la varianza.



En el caso de nuestros datos, usaremos $k = 2.5$, y detectaremos aquellos datos que son outliers para luego pasarlos a un **valor ausente**.

```{r warning = FALSE}
iris_na_outliers <- 
  iris %>% 
  mutate(Sepal.Width =
           ifelse(abs(scores(Sepal.Width, type = "z")) > 2.5,
                  NA, Sepal.Width))
iris_na_outliers
```

```{r}
iris_na_outliers %>% filter(is.na(Sepal.Width))
```

Tras ello tendremos **dos opciones**: **eliminar** dichas observaciones o **imputar la media** sin los ausentes (dado que los hemos detectado con la media)

```{r}
# opci칩n 1
iris_outliers <-
  iris_na_outliers %>% 
  mutate(Sepal.Width =
           ifelse(is.na(Sepal.Width), mean(Sepal.Width, na.rm = TRUE), Sepal.Width))
```

```{r}
# opci칩n 2
iris_outliers <- iris_na_outliers %>% drop_na(Sepal.Width)
```


Si queremos hacer esto con varias variables a la vez, tendremos que usar de nuevo `across()`

```{r}
iris_na_outliers <-
  iris %>% 
  mutate(across(Sepal.Length:Petal.Width,
                function(x) { ifelse(abs(scores(x, type = "z")) > 2.5, NA, Sepal.Length) }))
```


Con `if_any()` dentro del `filter()` podemos mostrar todo los registros detectados como outlier en alguna variable.

```{r}
iris_na_outliers %>% filter(if_any(Sepal.Length:Petal.Width, is.na))
```

Tras su detecci칩n y an치lisis podemos o imputarles a todos la media (de la variable en cuesti칩n) o eliminarlos.

```{r}
# opci칩n 1
iris_outliers <-
  iris_na_outliers %>% 
  mutate(across(Sepal.Length:Petal.Width,
                function(x) { ifelse(is.na(x), mean(x, na.rm = TRUE), x) }))
```


```{r}
# opci칩n 2
iris_outliers <-
  iris_na_outliers %>% drop_na()
```



#### Respecto a mediana

* **At칤pico respecto a mediana**: ser치 un dato muy alejado de la **mediana de la variable**. 쮺u치nto de alejado? Una definici칩n habitual (conocido como **filtro de Hampel**) es definir un dato at칤pico como aquel que se aleja de la mediana $k$ veces la mediana de las desviaciones absolutas (conocida como $MAD = Me \left(\left| x_i - Me_x \right| \right)$). Un valor habitual es $k = 3$.

$$x_i > Me_{x} + k*MAD\quad \text{ o bien } \quad x_i< Me_{x} - k*MAD$$

Para ello nos bastar치 usar `scores()` con `type = "mad"` (y nos devolver치 de nuevo ese $k$).

```{r}
abs(scores(c(1, -1, 0, 5, 2, 1.5, 0.5, -0.3, 0, 2, 1.7, 0.2, -0.8), type = "mad"))
```

El **valor a imputar ser칤a la mediana**


#### Respecto a percentiles


* **At칤pico respecto a percentiles**: ser치 un dato muy alejado de los **cuartiles de la variable**. 쮺u치nto de alejado? Una definici칩n habitual es definir un dato at칤pico como aquel que se aleja de los cuartiles 1 y 3 (percentiles 25 y 75) $k$ veces el rango intercuart칤lico ($IQR = Q_3 - Q_1$). Un valor habitual es $k = 1.5$).

$$x_i > Q_3 + k* IQR \quad \text{ o bien } \quad x_i < Q_1 - k*IQR$$

Para ello nos bastar치 usar `scores()` con `type = "iqr"` (y nos devolver치 de nuevo ese $k$, siendo $k = 0$ para lo que est칠 dentro del IQR).

```{r}
abs(scores(c(1, -1, 0, 5, 2, 1.5, 0.5, -0.3, 0, 2, 1.7, 0.2, -0.8), type = "iqr"))
```

El **valor a imputar ser칤a la mediana**


#### M칠todos basados en inferencia

Existen otros procedimientos **basados en inferencia estad칤stica** (muchos de ellos en el paquete `{outliers}`)

* **Tests de Grubbs y Dixon**: ambos test nos permiten **detectar si el valor m치s alto (o bajo)** de una varibale es un outlier, pudiendo detectar un solo outlier en cada iteraci칩n (en caso de detectarlo, deber칤amos tratarlo y volver a ejecutar el test)

$\mathcal{H}_0: \text{valor m치s alto/bajo no es outlier}$

$\mathcal{H}_1: \text{ valor m치s alto/bajo s칤 es outlier}$


&nbsp;

El test de Dixon (basado en una ordenaci칩n) suele funcionar mejor cuando tenemos poca muestra que el test de Grubbs (basado en la media).

游닄 Ver m치s documentaci칩n de su funcionamiento en <https://www.itl.nist.gov/div898/handbook/eda/section3/eda35h1.htm> y <https://www.statisticshowto.com/dixons-q-test/>



Por ejemplo, para el de Dixon existe `dixon.test()`

```{r}
x <- c(1, -1, 0, 5, 2, 1.5, 0.5, -0.3, 0, 2, 1.7, 0.2, -0.8)
dixon.test(x, opposite = TRUE) # valor m치s bajo
```

```{r}
x <- c(1, -1, 0, 5, 2, 1.5, 0.5, -0.3, 0, 2, 1.7, 0.2, -0.8)
dixon.test(x, opposite = FALSE) # valor m치s alto
```


* **Test de Rosner**: al contrario que los anteriores, nos permite **detectar varios outliers** a la vez, especialmente dise침ado para evitar que un valor at칤pico nos perturbe tanto que nos enmascare otro (basado en la media). Podemos ejecutarlo con la funci칩n `rosnerTest()` del paquete `{EnvStats}`.

&nbsp;

**IMPORTANTE**: la detecci칩n de outliers deber치 combinar el an치lisis num칠rico y la visualizaci칩n.

游닄 Ver m치s documentaci칩n de su funcionamiento en <https://vsp.pnnl.gov/help/vsample/rosners_outlier_test.htm>


### Tratamiento de outliers (tidymodels)

Lo que haremos a continuaci칩n ser치 **detectar outliers** (transformando dichos outliers a `NA`)

```{r}
iris_rec <-
  iris_rec %>% 
  # Detectar outliers
  step_mutate(across(starts_with("Sepal"), function(x) { ifelse(abs(scores(x, type = "z")) > 2.5, NA, x) }),
              across(starts_with("Petal"), function(x) { ifelse(abs(scores(x, type = "mad")) > 3, NA, x) }))
  
iris_rec
iris_rec %>% summary()
```

### Tratamiento de ausentes

Y decidiremos c칩mo **.bg-purple_light[tratar los ausentes]** (los existentes y los generados al detectar los outliers). Tenemos much칤simas funciones para ello (ver `step_impute_...()`):


* `step_impute_mean()`, `step_impute_median()` y `step_impute_mode()`: imputamos por media, mediana o moda.

* `step_impute_knn()`: usaremos un knn previo para imputar los ausentes.

* `step_impute_bag()`: usaremos un 치rbol o conjunto de 치rboles para imputar los ausentes.


* `step_impute_linear()`: usaremos una regresi칩n lineal para imputar ausentes

```{r}
iris_rec <-
  iris_rec %>% 
  # Imputar ausentes
  step_impute_mean(has_role("sepal")) %>% 
  step_impute_median(has_role("petal"))

iris_rec
iris_rec %>% summary()
```

F칤jate la **utilidad de los roles**: con `has_role()` podemos indicarle a qu칠 variables aplicar la acci칩n.

### Filtro de correlaci칩n

Para tratar los **problemas de colinealidad** usaremos directamente `step_corr()`, al que le tendremos que pasar un umbral en `threshold`: se queda solo con una variable de todo par de variables cuya **correlaci칩n en valor absoluto supere el umbral** (en este caso usaremos `all_numeric_predictors()` para considerar solo las predictoras num칠ricas)


```{r}
iris_rec <-
  iris_rec %>% 
  # Filtro de correlaci칩n
  step_corr(all_numeric_predictors(), threshold = 0.9) 
  
iris_rec
iris_rec %>% summary()
```

### Normalizaci칩n

Por 칰ltimo, dado que el knn es un **algoritmo que usa una distancia (geom칠trica en nuestro caso)**, necesitamos que **todas las variables tengan el mismo peso inicial**, as칤 que vamos a **estandarizar las num칠ricas por rango** con `step_range()` (siempre entre 0 y 1, aunque podr칤amos asignarle otro rango dando valores a `max` y `min`). Con `step_normalize()` normalizar칤amos (media nula y varianza unitaria).

$$x_{range} = \frac{x - min(x)}{max(x) - min(x)}, \quad x_{normalize} = \frac{x - \overline{x}}{s_{x}}$$

Lo haremos con `step_range()` para que nos **normalice por rango** las variables predictoras que sean num칠ricas.

```{r}
iris_rec <-
  iris_rec %>% 
  # Normalizar por rango
  step_range(all_numeric_predictors())

iris_rec
iris_rec %>% summary()
```

### Filtro de varianza cero

Por 칰ltimo a침adiremos siempre un 칰ltimo **filtro de cero varianza** para que nos elimine las variables con varianza constante.

```{r}
iris_rec <-
  iris_rec %>% 
  # Filtro de cero varianza
  step_zv(all_predictors())

iris_rec
iris_rec %>% summary()
```

### Receta final: horneado (bake)

La receta final completa ser칤a por tanto la siguiente

```{r}
iris_rec <-
  # F칩rmula y datos
  recipe(data = iris_train, Species ~ .) %>%
  # Roles
  add_role(starts_with("Sepal"), new_role = "sepal") %>% 
  add_role(starts_with("Petal"), new_role = "petal") %>% 
  # Detectar outliers
  step_mutate(across(starts_with("Sepal"), function(x) { ifelse(abs(scores(x, type = "z")) > 2.5, NA, x) }),
              across(starts_with("Petal"), function(x) { ifelse(abs(scores(x, type = "mad")) > 3, NA, x) })) %>% 
  # Imputar ausentes
  step_impute_mean(has_role("sepal")) %>% 
  step_impute_median(has_role("petal")) %>% 
  # Filtro de correlaci칩n
  step_corr(all_numeric_predictors(), threshold = 0.9) %>% 
  # Normalizar por rango
  step_range(all_numeric_predictors()) %>% 
  # Filtro de cero varianza
  step_zv(all_predictors())

iris_rec
iris_rec %>% summary()
```

Una vez que la **receta est치 dise침ada** una buena pr치ctica para evitar errores es comprobar que se ejecuta correctamente (y qu칠 no sucede nada raro) en el conjunto de entrenamiento. Tras escribir la receta vamos a **prepararla** (con `prep()`) y a **hornear los datos** con `bake()`: para hornearla en el conjunto de train, basta con poner `new_data = NULL`.

```{r bake}
# Aplicada a train
bake(iris_rec %>% prep(), new_data = NULL)

# Aplicada a test
bake(iris_rec %>% prep(), new_data = iris_test)
```

Nuestra receta, aplicada a nuestros ingredientes, est치 lista. Este 춺horneado췉 con `bake()` solo lo necesitamos **si queremos ya aplicar la receta a nuestros datos**. Nosotros, al a침adir ahora un modelo de clasificaci칩n, **incluiremos la receta en un flujo de trabajo**.

## Fase 4: modelizaci칩n

### Definici칩n del modelo (utensilios de cocina)

Una vez que tenemos nuestra lista de instrucciones escrita, lo siguiente que har칤amos al **cocinar un plato** es buscar los utensilios necesarios: cuchillos, cacerolas, batidora, etc. En nuestro caso los **utensilios ser치n nuestro modelo (en este caso de clasificaci칩n)**, con `nearest_neighbor()` (echa un vistazo a los modelos del paquete `{parsnip}`). La idea del **algoritmo de los k-vecinos (knn)** es muy similar al **proceso que seguir칤amos para decidir si vemos o no una pel칤cula**: preguntar칤amos a un n칰mero de conocidos (par치metro k), decidir칤amos si ir o no en funci칩n de la mayor칤a de opiniones, y no tratar칤amos todas las opiniones por igual (dependiendo de la cercan칤a o afinidad, ponderar칤amos las opiniones).

En `nearest_neighbor()` especificaremos los siguientes argumentos (de momento):

- `mode`: admite dos opciones, `mode = "classification"` o `mode = "regression"` (en nuestro caso `mode = "classification"`).
- `neighbors`: el n칰mero de vecinos `k` que consideramos como entorno de vecindad para asignar una categor칤a a los datos.
- `weight_func`: funci칩n (kernel) para promedir distancias (`weight_func = "inv"` nos promedia por el inverso de la distancia, vecinos m치s alejados valen menos en la asignaci칩n; ver opciones en <https://epub.ub.uni-muenchen.de/1769/>)
- `dist_power`: n칰mero $r$ de la distancia de Minkowski ($r = 2$ es la distancia eucl칤dea)

$$D_{Minkow}(\boldsymbol{x}, \boldsymbol{y}) = \left(\sum_{i=1}^{p} \left|x_i - y_i \right|^r\right)^{1/r}, \quad \boldsymbol{x} = \left(x_1, \ldots, x_p\right),~ \boldsymbol{y} = \left(y_1, \ldots, y_p \right)$$


Con `set_engine("kknn")` le **especificaremos en concreto el 춺motor췉 (el paquete)** que contiene las herramientas matem치ticas necesarias con el que realizaremos el ajuste.

```{r knn}
knn_model <-
  nearest_neighbor(mode = "classification", neighbors = 10,
                   weight_func = "inv", dist_power = 2) %>%
  set_engine("kknn") # el 춺motor췉 que realiza el ajuste
knn_model
```

### Flujo de trabajo

Llegados a este punto tenemos

* Tenemos una **receta para preprocesar los datos**, una lista de instrucciones.
* Tenemos los **utensilios (modelo)**.
* Tenemos los **ingredientes (datos) ya preparados** (muestreo, partici칩n, etc).

Con dichos ingredientes podemos crear ya un **flujo de trabajo** con `workflow()`

```{r flujo}
# Flujo de trabajo
iris_wflow <-
  workflow() %>%
  add_recipe(iris_rec) %>%
  add_model(knn_model)
iris_wflow
```

En `hoteles_wflow` tenemos guardada la receta y los pasos que vamos a ejecutar para preparar nuestro 춺plato췉. 

### Ajuste

Dichos pasos vamos a **proporcion치rselos a nuestro conjunto de entrenamiento** para que nos **aplique el flujo de trabajo** que hemos construido, realizando el ajuste con `fit(data = iris_train)`.


```{r fit-knn-1}
# Aplicamos flujo
iris_knn_fit <- iris_wflow %>% fit(data = iris_train)
iris_knn_fit
```

Dicho ajuste guardado en `iris_knn_fit` podemos usarlo para **predecir el conjunto test** de dos maneras:

* **Clase**
* **Probabilidades** (de pertenencia a dichas clases, que realmente es el objetivo de estos modelos, predecir esas probabilidades de pertenencia)

Ambas se hacen con `predict()` pas치ndole un argumento de `type` diferente. **Reminder**: al tenerlo todo integrado en un flujo, **aplicar치 el procesamiento que necesite al conjunto de test**, tal cual lo hemos indicado en las instrucciones.

```{r predict-knn-1}
# Predecir el conjunto test: devuelve la clase
predict(iris_knn_fit, iris_test)

# Predecir las probabilidades (las necesitamos para la ROC)
predict(iris_knn_fit, iris_test, type = "prob")
```


Dentro del paquete `{parsnip}` que hemos cargado dentro de `{tidymodels}` tenemos a nuestra disposici칩n una funci칩n llamada `augment()` que nos permite **incluir en una misma tabla las predicciones de la clase, de las probabilidades y los datos de test originales** (a침adiendo columnas).

```{r augment}
# Para obtener las probabilidades en los datos (con variables)
prob_test <- augment(iris_knn_fit, iris_test)
prob_test
```

## Fase 5: evaluaci칩n y predicci칩n

**쮺칩mo evaluar nuestro ajuste en base a las predicciones en nuestro conjunto test?** En realidad el conjunto de test solo deber칤amos usarlo al final del proceso, no como evaluaci칩n intermedia de los hiperpar치metros, ya que dicho rol le corresponde a un **tercer conjunto de validaci칩n**, pero de momento vamos a simplificarlo en train-test.

Una de las formas m치s sencillas de **evaluar un m칠todo de clasificaci칩n es con una matriz de confusi칩n**: una matriz que nos cruce las frecuencias de las etiquetas reales frente a las predichas. En `conf_mat()` le tendremos que especificar donde est치 la etiqueta real (estamos en supervisado y la conocemos) y la predicci칩n de la clase de pertenencia, guardada si te fijas en el dataset anterior en la variable `.pred_class` (pero que podemos cambiarle de nombre)

```{r}
# Matriz de confusi칩n: etiqueta real vs etiqueta predicha
conf_mat_test <-
  prob_test %>%
  rename(pred_specie = .pred_class) %>% 
  conf_mat(truth = Species, estimate = pred_specie)
conf_mat_test 

# La guardamos en una tabla
conf_mat_test_table <- as_tibble(conf_mat_test$table)
conf_mat_test_table
```

De dicha matriz de confusi칩n podemos **obtener la mayor칤a de m칠tricas de validaci칩n**. Si llamamos $TP$ y $TN$ a los **verdaderos positivos y negativos** (registros que eran 0/1 y fueron clasificados como tal), y $FP$ y $FN$ a los **falsos positivos** (un 0 clasificado como 1) y **falsos negativos** (un 1 clasificado como 0), tenemos:

* **Prevalencia**: proporci칩n de los datos que realmente son 1's  $\frac{P}{P + N} = \frac{P}{todos}$.

* **Sensibilidad** (sensitivity, recall, hit rate, o tasa de verdaderos positivos TPR): proporci칩n de los 1's que han sido clasificados como tal  $\frac{TP}{TP + FN} = \frac{TP}{positivos}$.

* **Tasa de falsos negativos** (miss rate FNR): proporci칩n de los 1's mal clasificados  $\frac{FN}{TP + FN} = \frac{FN}{positivos} = 1 - sensibilidad$

* **Especificidad** (specificity, selectivity o tasa de verdaderos negativos TNR): proporci칩n de los 0's que han sido clasificados como tal  $\frac{TN}{FP + TN} = \frac{TN}{negativos}$.

* **Tasa de falsos positivos** (fall-out FPR): proporci칩n de los 0's mal clasificados  $\frac{FP}{TN + FP} = \frac{FP}{negativos} = 1 - especificidad$

* **Precisi칩n** (positive predictive value PPV): proporci칩n de los 1's asignados por el modelo bien clasificados  $\frac{TP}{TP + FP} = \frac{TP}{\text{clasificados como positivos}}$

* **Valor predictivo negativo** (negative predictive value NPV): proporci칩n de los 0's asignados por el modelo bien clasificados  $\frac{TN}{TN + FN} = \frac{TN}{\text{clasificados como negativos}}$

* **False discovery rate** (FDR): proporci칩n de los 1's asignados por el modelo mal clasificados  $\frac{FP}{TP + FP} = \frac{FP}{\text{clasificados como positivos}} = 1 - precision$

* **Tasa de mal clasificados** (MISC): proporci칩n de los datos bien clasificados (ya sean 0's o 1's)  $\frac{FP + FN}{TP + TN + FP + FN} = \frac{FP + FN}{todos}$

* **Tasa de bien clasificados** (accuracy ACC): proporci칩n de los datos bien clasificados (ya sean 0's o 1's)  $\frac{TP + TN}{P + N} = \frac{TP + TN}{todos} = 1 - MISC$

Dichas **m칠tricas las podemos obtener autom치ticamente** de la matriz de confusi칩n, haciendo uso de `summary()`

```{r}
# Matriz de confusi칩n + resumen: etiqueta real vs etiqueta predicha
metricas <- conf_mat_test %>% summary()
metricas
```


F칤jate que aunque no sea un problema de clasificaci칩n binaria nos proporciona m칠tricas como la sensibilidad y especificidad: lo que es, **para cada clase, construir una matriz de confusi칩n** (ser setosa vs no serlo, ser virginica vs no serlo, ser versicolor vs no serlo), y devuelve la **media de las tres sensibilidad o especificidades**





# C칩digo completo

Te dejo el c칩digo completo 

```{r eval = FALSE}
# Partici칩n 70-30% de train y test
iris_split <- initial_split(iris, strata = Species, prop = 0.7)
iris_split

# Aplicamos partici칩n
iris_train <- training(iris_split)
iris_test  <- testing(iris_split)

# Comprobamos estratos
iris_train %>% count(Species) %>% mutate(porc = 100 * n / sum(n))
iris_test %>% count(Species) %>% mutate(porc = 100 * n / sum(n))

# Receta
iris_rec <-
  # F칩rmula y datos
  recipe(data = iris_train, Species ~ .)%>%
  # Roles
  add_role(starts_with("Sepal"), new_role = "sepal") %>% 
  add_role(starts_with("Petal"), new_role = "petal")%>% 
  # Detectar outliers
  step_mutate(across(starts_with("Sepal"),
                     function(x) { ifelse(abs(scores(x, type = "z")) > 2.5, NA, x) }),
              across(starts_with("Petal"),
                     function(x) { ifelse(abs(scores(x, type = "mad")) > 3, NA, x) }))%>% 
  # Imputar ausentes
  step_impute_mean(has_role("sepal")) %>% 
  step_impute_median(has_role("petal"))%>% 
  # Filtro de correlaci칩n
  step_corr(all_numeric_predictors(), threshold = 0.9)%>% 
  # Normalizar por rango
  step_range(all_numeric_predictors())%>% 
  # Filtro de cero varianza
  step_zv(all_predictors()) # Aplicada a train

# Horneado para comprobar que todo ok
bake(iris_rec %>% prep(), new_data = NULL)
bake(iris_rec %>% prep(), new_data = iris_test)

# Modelo knn
knn_model <-
  nearest_neighbor(mode = "classification", neighbors = 10,
                   weight_func = "inv", dist_power = 2) %>%
  set_engine("kknn") # el 춺motor췉 que realiza el ajuste

# Flujo
iris_wflow <-
  workflow() %>%
  add_recipe(iris_rec) %>%
  add_model(knn_model)

# Ajuste
iris_knn_fit <- iris_wflow %>% fit(data = iris_train)

# Predecir el conjunto test: devuelve la clase
predict(iris_knn_fit, iris_test)

# Predecir las probabilidades (las necesitamos para la ROC)
predict(iris_knn_fit, iris_test, type = "prob")

# Incluir predicciones en tabla
prob_test <- augment(iris_knn_fit, iris_test)

# Matriz de confusi칩n: etiqueta real vs etiqueta predicha
conf_mat_test <-
  prob_test %>%
  rename(pred_specie = .pred_class) %>% 
  conf_mat(truth = Species, estimate = pred_specie)
conf_mat_test 

# M칠tricas en test
metricas <- conf_mat_test %>% summary()
metricas
```