---
title: "Tutorial de knn en R: hoteles dataset"
description: |
  Flujo de trabajo paso a paso
author:
  - name: Javier 츼lvarez Li칠bana
    url: https://javier-alvarez-liebana.github.io
    affiliation: Universidad Complutense de Madrid
    affiliation_url: 
date: "`r Sys.Date()`"
output:
    distill::distill_article:
        highlight: kate
        colorlinks: true
        code_folding: false
        toc: true            
        toc_depth: 3     
---

```{r setup, include = FALSE}
# Ajuste comunes de los chunk
knitr::opts_chunk$set(fig.width = 8, fig.asp = 1, out.width = "100%",
                      message = FALSE, warning = FALSE,
                      echo = TRUE, res = 400)
```

# Objetivo {#objetivo}

El objetivo de este peque침o tutorial es saber aplicar un flujo de trabajo en el entorno `{tidymodels}` para poder implementar un algoritmo de clasificaci칩n knn en `R`, y las distintas **formas de validaci칩n**. Puedes ver m치s detalles y funcionalidades en la web oficial del paquete: <https://www.tidymodels.org/>


## Paquetes necesarios

Necesitaremos los siguientes paquetes

* **An치lisis exploratorio num칠rico**: paquete `{skimr}`
* **Depuraci칩n y preprocesamiento**: paquete `{tidyverse}`
* **Modelizaci칩n**: paquete `{tidymodels}` para modelos
* **Detecci칩n de outliers**: paquete `{outliers}`
* **Detecci칩n de festivos**: paquete `{timeDate}`

```{r paquetes}
# Borramos
rm(list = ls())

# Paquetes
library(skimr) # resumen num칠rico
library(tidymodels) # depuraci칩n datos
library(tidyverse) # modelos
library(outliers) # outliers
library(timeDate) # fechas
```

# Datos {#datos}

Vamos ir a un **ejemplo real**, haciendo uso de un **dataset de reservas de hotel**

```{r}
hoteles_bruto <- read_csv(file = "./datos/hoteles.csv")
```

Los datos forman parte de un **conjunto de reservas de hotel** elaborado por Antonio et al., 2019 con 50 000 registros de reservas

游닄 **Detalle de variables**: <https://linkinghub.elsevier.com/retrieve/pii/S2352340918315191>



## An치lisis exploratorio inicial (num칠rico)

Antes de tomar ninguna decisi칩n con los datos lo primero que deber칤amos hacer es **echar un vistazo num칠rico** a c칩mo se comportan las variables. Dado que vamos a clasificar, lo primero que deber칤amos observar es como se distribuyen los niveles de nuestra variable objetivo.

### Variables

Lo primero es conocer las variables

```{r}
glimpse(hoteles_bruto)
```

* `hotel`: tipo de hotel (urbano o resort)
* `lead_time`: n칰mero de d칤as entre la reserva y la estancia.
* `stays_in_weekend_nights, stays_in_week_nights`: noches en fin de semana y entre semana
* `adults`: n칰mero de adultos
* `children`: 쯟a reserva tiene ni침os?
* `meal`: r칠gimen de comidas
* `country`: pa칤s de origen
* `market_segment`: segmento de mercado de la reserva
* `distribution_channel`: canal de distribuci칩n de la oferta
* `is_repeated_guest`: repite como hu칠sped?
* `previous_cancellations`: cancelaciones previas
* `previous_bookings_not_canceled`: reservas previas (no canceladas)
* `reserved_room_type, assigned_room_type`: tipo de habitaci칩n reservada/asignada
* `booking_changes`: cambios en la reserva
* `deposit_type`: tipo de dep칩sito
* `days_in_waiting_list`: d칤as en lista de espera
* `customer_type`: tipo de cliente
* `average_daily_rate`: tarifa media diaria
* `required_car_parking_spaces`: 쯣arking?
* `total_of_special_requests`: n칰mero de requisitos especiales demandados
* `arrival_date`: fecha de llegada 

### Balance la variable objetivo

El objetivo ser치 **predecir si una reserva incluye ni침os/as o no**, por lo que `children` ser치 nuestra variable objetivo. Primer paso: conocer c칩mo se **istribuyen los niveles de la objetivo** (es binaria)


```{r}
# Objetivo: predecir si la reserva viene o no con ni침os
hoteles_bruto %>% 
  count(children) %>%
  mutate(porc = 100*n/sum(n))
```

### skim()

Adem치s con la funci칩n `skim()` del paquete `{skimr}` podemos **extraer algunas estad칤sticas b치sicas** de nuestros datos.

```{r skim}
# Resumen num칠rico
iris %>% skim()
```

# Fase 1-2-3: muestreo-exploraci칩n-modificaci칩n

Lo primero que debemos hacer es examinar los datos y apuntar las **decisiones que deber칤amos adoptar**. Por ejemplo:

&nbsp;

* 쯅ecesitamos **muestreo**? 쮻e qu칠 forma? 쯇odremos permitirnos crear esta vez un dataset de **validaci칩n**?

* 쮻e qu칠 **tipo** es cada variable? 쯊enemos **problemas de codificaci칩n o rango**?

* 쮺칩mo **afectan las predictoras** a los niveles de la variable objetivo?

* 쮿ay problemas de **dependencia** entre las variables?

* 쯅ecesitamos **recategorizar** las variables? 쯊enemos variables de **fecha**?

* 쯊enemos **datos at칤picos**?  쯊enemos **datos ausentes**? 쮺칩mo imputarlos?

* 쯊odas las variables son **num칠ricas** para poder aplicar la m칠trica?

&nbsp;

La **filosof칤a** ser치 la siguiente: 

* modificaciones 춺estructurales췉 las hacemos fuera de la receta (modificando la base de datos)

* modificaciones m치s concretas para un algoritmo dentro de la receta (sin modificar la base de datos).


## Factores

Una de las primeras decisiones ser치 dotar a las variables de su **tipolog칤a correcta**: debemos decidir es si las variables de tipo texto son **variables cualitativas** (factores) o meros id's.

```{r}
hoteles_bruto %>%
  select(where(is.character)) %>%
  glimpse()
```


Todas las variables de tipo texto representan **categor칤as de una cualitativa** as칤 que las convertimos todas ellas a factor (modificaci칩n estructural --> fuera de la receta)

```{r}
hoteles <- 
  hoteles_bruto %>%
  mutate(across(where(is.character), as_factor))
hoteles
```

### Ordinales

쮼xiste adem치s alguna variable que pueda ser ordinal?


La variable `meal` si sigue una jerarqu칤a: `SC` (sin nada) < `BB` (Bed & Breakfast) < `HB` (Half board, media pensi칩n) < `FB` (Full board, pensi칩n completa). Adem치s tenemos un nivel para los desconocidos llamado `Undefined`

```{r}
hoteles %>%
  count(meal) %>% 
  mutate(porc = 100*n/sum(n))
```

Por ello convertiremos `meal` a cualitativa pero ordinal.

```{r}
hoteles <-
  hoteles %>%
  mutate(meal = factor(meal, levels = c("Undefined", "SC", "BB", "HB", "FB"),
                       ordered = TRUE))
```

Esto nos permitir치 hacer **operaciones asociadas a una jerarqu칤a** como comparar registros

```{r}
hoteles %>%
  group_by(meal < "HB") %>% #<<
  count() %>% 
  ungroup()
```

## Variables cuali

Una vez convertidas en cualitativas analicemos cada una de ellas. La idea b치sica es la siguiente: ver que peso suponen cada nivel en las variables, y adem치s, ver como **afectan los niveles a la variable objetivo**.

### Variable hotel

La variable `hotel` es **binaria**: urbanos vs resort (60% vs 40% aprox)

```{r}
hoteles %>%
  count(hotel, sort = TRUE) %>%
  mutate(porc = 100*n/sum(n))
```

Parece adem치s que cuando hay **ni침os en la reserva** se opta ligeramente **m치s por los resort**, pero no de forma desproporcionada.

```{r}
hoteles %>%
  group_by(hotel) %>% 
  count(children) %>%
  mutate(porc = 100*n/sum(n)) %>% 
  ungroup()
```


### Variable meal

La variable `meal` toma **5 modalidades**: quiz치s para algunos algoritmos haga falta reagrupar niveles (por ejemplo `Undefined` con `SC`)

```{r}
hoteles %>%
  count(meal, sort = TRUE) %>%
  mutate(porc = 100*n/sum(n))
```



Parece que **cuando hay ni침os** en la reserva hay el **doble de reservas con pensi칩n completa**: aunque haya pocos registros de `meal = "FB"` pueden ser determinantes. El 11% de la reservas sin ni침os van sin nada, mientras que solo el 3% de las reservas con ni침os.


```{r}
hoteles %>%
  group_by(meal) %>% 
  count(children) %>% 
  mutate(porc = 100*n/sum(n)) %>% 
  ungroup()
```


```{r}
hoteles %>%
  group_by(children) %>% 
  count(meal) %>% 
  mutate(porc = 100*n/sum(n)) %>% 
  ungroup()
```

### Variable country

La variable `country` toma **155 modalidades** pero tan solo **21 modalidades aparecen en m치s del 0.5% de registros** (una de ellas es NULL): quiz치s sea m치s pr치ctico reagrupar niveles de esos pa칤ses (representan juntos aprox el 10% del total).

```{r}
hoteles %>%
  count(country, sort = TRUE) %>%
  mutate(porc = 100*n/sum(n), cumul = cumsum(porc))
```


Aunque hay pa칤ses que representa muy poco de los datos, parece que **algunos son m치s propensos a reservas con ni침os**, as칤 que quiz치s una idea pueda ser decidir no solo por peso sino por % de ni침os, para que aprenda m치s de los 1's que de los 0's.

```{r}
hoteles %>%
  group_by(country) %>% count(children) %>% 
  mutate(porc_children = 100*n/sum(n)) %>% 
  ungroup()
```

Reminder: con estos an치lisis no vamos a eliminar registros (al menos no de manera general), solo decidir si recategorizamos/reagrupamos categor칤as. Esto adem치s es **crucial** en el k-vecinos ya que **por cada variable cuali de N modalidades, deberemos luego crear N-1 dummys** asociadas.

### Variable market_segment

La variable `market_segment` toma **7 modalidades** aunque algunas representan menos del 1% del total.

```{r}
hoteles %>%
  count(market_segment, sort = TRUE) %>%
  mutate(porc = 100*n/sum(n), cumul = cumsum(porc))
```

F칤jate que aunque `market_segment = "Aviation"` representa muy pocos registros, el 100% son sin ni침os (casi similar con `market_segment = "Corporate"` y `market_segment = "Groups"`)

```{r}
hoteles %>%
  group_by(market_segment) %>% 
  count(children) %>% 
  mutate(porc = 100*n/sum(n)) %>% 
  ungroup()
```


### Variable distribution_channel

La variable `distribution_channel` toma **5 modalidades**  pero solo **3 de ellas agrupan ya m치s del 99%** de los registros.

```{r}
hoteles %>%
  count(distribution_channel, sort = TRUE) %>%
  mutate(porc = 100*n/sum(n),
         cumul = cumsum(porc))
```

F칤jate que de `distribution_channel = "Undefined"` y `distribution_channel = "GDS"` representan **muy pocos registros**, y todos con una sola modalidad en la objetivo (pero solo pesan el 0.2% de los datos)

```{r}
hoteles %>%
  group_by(distribution_channel) %>% 
  count(children) %>% 
  mutate(porc = 100*n/sum(n)) %>% 
  ungroup()
```


### Variable reserved_room_type

La variable `reserved_room_type` toma **9 modalidades** (no nos especifican si hay jerarqu칤a) pero **solo 5 de ellas tienen un peso superior al 1%** de los registros.

```{r}
hoteles %>%
  count(reserved_room_type, sort = TRUE) %>%
  mutate(porc = 100*n/sum(n),
         cumul = cumsum(porc))
```

F칤jate que `reserved_room_type` ser치 **tremendamente importante**: si la habitaci칩n es de tipo F, el 47% viene con ni침os (frente al 8% global), del 70% incluso si es de tipo C

```{r}
hoteles %>%
  group_by(reserved_room_type) %>% 
  count(children) %>% 
  mutate(porc = 100*n/sum(n)) %>% 
  ungroup()
```


### Variable assigned_room_type

La variable `assigned_room_type` toma **10 modalidades** (no nos especifican si hay jerarqu칤a) pero solo 7 de ellas tienen un peso superior al 1% de los registros.

```{r}
hoteles %>%
  count(assigned_room_type, sort = TRUE) %>%
  mutate(porc = 100*n/sum(n),
         cumul = cumsum(porc))
```

Como suced칤a antes `assigned_room_type` ser치 tremendamente importante


Quiz치s pueda ser adem치s interesante, al margen del tipo de habitaci칩n, ver que sucede cuando la **asignada es distinta de la reservada**. 

```{r}
hoteles %>%
  mutate(same_room = as.character(reserved_room_type) == as.character(assigned_room_type)) %>%
  group_by(same_room) %>% 
  count(children) %>% 
  mutate(porc = 100*n/sum(n)) %>% 
  ungroup()
```

No parece que influya significativamente

### Variable deposit_type

La variable `deposit_type` toma **3 modalidades** pero el 99.6% de los registros es la misma.

```{r}
hoteles %>%
  count(deposit_type, sort = TRUE) %>%
  mutate(porc = 100*n/sum(n), cumul = cumsum(porc))
```

Adem치s de ser **muy pocos** los registros que no sean `No_Deposit`, pr치cticamente su totalidad son **sin ni침os** (clase ya mayoritaria en los datos).

```{r}
hoteles %>%
  group_by(deposit_type) %>% 
  count(children) %>% 
  mutate(porc = 100*n/sum(n)) %>% 
  ungroup()
```


### Variable customer_type

La variable `customer_type` toma **4 modalidades** pero **dos de ellas representan m치s del 95%** de los registros.

```{r}
hoteles %>%
  count(customer_type, sort = TRUE) %>%
  mutate(porc = 100*n/sum(n),
         cumul = cumsum(porc))
```



El 88% de las reservas con ni침os son de tipo `"Transient"`

```{r}
hoteles %>%
  group_by(children) %>% 
  count(customer_type) %>% 
  mutate(porc = 100*n/sum(n)) %>% 
  ungroup()
```


### Variable required_car_parking_spaces

La variable `required_car_parking_spaces` es binaria (muy desbalanceada).

```{r}
hoteles %>%
  count(required_car_parking_spaces, sort = TRUE) %>%
  mutate(porc = 100*n/sum(n),
         cumul = cumsum(porc))
```

El % de las reservas con ni침os es el doble cuando hay parking solicitado.

```{r}
hoteles %>%
  group_by(children) %>% 
  count(required_car_parking_spaces) %>% 
  mutate(porc = 100*n/sum(n)) %>% 
  ungroup()
```

## Dependencia entre  cuali

M치s all치 del an치lisis exploratorio num칠rico, podemos ejecutar un **contraste de independencia** (prueba $\chi^2$ de independencia) para tener mayor certeza de si la predictora es dependiente o no de la variable objetivo (si fuera independiente, no tendr칤a sentido mantenerla)

```{r warning = FALSE}
chisq.test(hoteles$children, hoteles$hotel)
```

Si fijamos $\alpha = 0.05$ (nivel de significaci칩n), si p-valor < 0.05 deber칤amos rechazar la **hip칩tesis nula de independencia** (bajo dicho nivel).

&nbsp;

Podemos hacerlo con **todas las variables a la vez** enfrent치ndola a la objetivo, entendiendo que cada columna juega el rol de una lista si usamos las funciones del paquete `{purrr}`

```{r warning = FALSE}
chisq <-
  tibble("variable" = hoteles %>% select(where(is.factor)) %>% names(),
         "p_value" = hoteles %>% select(where(is.factor)) %>%
           map_dbl(.f = function(x) { chisq.test(hoteles$children, x)$p.value}))
chisq %>% arrange(desc(p_value))
```


```{r warning = FALSE}
chisq %>% filter(p_value > 0.05)
```

**No hay evidencia suficiente para decir que existe predictora independiente de la objetivo** (al 95% de confianza) seg칰n la prueba de independencia realizada

## Resumen de las cuali

Esta es mi propuesta para un preprocesamiento b치sico (via libre para mejorarlo y completarlo)

* `hotel` --> **no hacer nada**.

* `meal`: aunque haya pocos registros de `meal = "FB"`, parece que pueden ser determinantes --> **reagrupar "Undefined" con "SC" y dejar "FB"**.

* `country`: tan solo 21 de ellas aparecen en m치s del 0.5% de registros (una de ellas es NULL) --> **reagrupar niveles de pa칤ses minoritarios** (representan juntos aprox el 10% del total) qued치ndonos con aquellos que superen en un m칤nimo de representatividad (m치s fino: incluir tambi칠n los que sean m치s propensos que otros a reservas con ni침os).

* `market_segment`:  algunas representan menos del 1% del total, aunque para `market_segment = "Aviation"` el 100% son sin ni침os (casi similar con `market_segment = "Corporate"` y `market_segment = "Groups"`) --> **agrupar los 3 junto con "complementary"** (pesan muy poco estos 칰ltimos) en un `"others"`.

* `distribution_channel`: solo 3 de ellas agrupan ya m치s del 99% de los registros --> **reagrupar "Corporate" (98.9% no children), "GDS" (100%  no children) y "Undefined" (solo 1 dato)** en `"others"` (aprox. el 7% de los datos).

* `reserved_room_type`: solo 5 de ellas tienen un peso superior al 1% de los registros, si es de tipo **C, H o L** (juntas suman el 1.3% de los datos aprox.), con ni침os superan el 70% --> **reagrupamos las 3** en un `"others"`

* `assigned_room_type`: con el mismo razonamiento que antes podemos **reaagupar las categor칤as H-I-K** en `"others"` 

* `deposit_type`: el 99.6% de registros es la misma -->  muy poca varianza y adem치s casi todos de esas clases minoritarias son de la clase mayoritaria de la  objetivo  --> **eliminar**

* `customer_type` --> **reagrupar "Transient" y "others"**

* `required_car_parking_spaces` --> **no hacer nada**


## Variables de fecha

Solo tenemos una `arrival_date`: 쯤u칠 parte de la fecha exactamente influye m치s? 쮼l a침o? 쮼l mes? 쮼l d칤a como n칰mero en s칤 o el d칤a de la semana? Tras extraer info la eliminaremos.

```{r}
library(lubridate)
hoteles <- 
  hoteles %>% 
  mutate(m_arr = month(arrival_date), y_arr = year(arrival_date),
         wday_arr = wday(arrival_date))

hoteles %>% group_by(y_arr) %>% count(children) %>% 
  mutate(porc = 100*n/sum(n))
```

No parece que el a침o influya mucho (veremos si influyen los d칤as festivos en s칤)

S칤 parece que los meses de julio, agosto y diciembre influye mucho al tener m치s ni침os --> podemos agrupar los meses en `"month_holy"` y `"month_no_holy"`

```{r}
hoteles %>% 
  group_by(m_arr) %>%
  count(children) %>% 
  mutate(porc = 100*n/sum(n))
```

Adem치s parece que los viernes, s치bados y domingos hay m치s reservas con ni침os --> podemos agrupar los meses en `"weekend"` y `"workday"`

```{r}
hoteles %>%  group_by(wday_arr) %>%  count(children) %>% 
  mutate(porc = 100*n/sum(n))
```


## Variables num칠ricas

Para las num칠ricas el proceso ser치 ligeramente diferente, ya que ya no toman modalidades, aunque la mayor칤a de ellas como veremos podr칤an funcionar tanto de cuanti como de cuali (recategorizadas)

### Variable lead_time

* `lead_time`: variable con una alta concentraci칩n a la izquierda (cola pesada a la derecha), con un m치ximo de d칤as muy elevado.

```{r}
hoteles %>% summarise(min_lead = min(lead_time), max_lead = max(lead_time))
```

Quizas no tenga sentido tanto n칰mero de d칤as (춰m치s de un a침o!) entre la reserva y la estancia --> todo lo que **supere 365, imputarle 366** (representan adem치s el 1.35% solo)

```{r}
hoteles %>%
  count(lead_time > 365)
```

### Variable stays_in_weekend_nights

* `stays_in_weekend_nights`: en realidad es una variable cualitativa m치s que cuantitativa, y a partir de 2 noches en festivo representa menos de 1% --> podr칤amos probar a **dejarla tal cual o recategorizarla en 4 categor칤as** (ninguna - 1 - 2 - m치s de 2)

```{r}
hoteles %>%
  count(stays_in_weekend_nights, sort = TRUE) %>% 
  mutate(porc = 100*n/sum(n), cumul = cumsum(porc))
```

### Variable stays_in_week_nights

* `stays_in_week_nights`: en realidad es una variable cualitativa m치s que cuantitativa, y a partir de 5 noches representa menos del 5% --> podr칤amos probar a **dejarla tal cual o recategorizarla en 7 categor칤as** (ninguna - 1 - 2 - 3 - 4 - 5 - m치s de 5)

```{r}
hoteles %>%
  count(stays_in_week_nights, sort = TRUE) %>% 
  mutate(porc = 100*n/sum(n), cumul = cumsum(porc))
```


### Variable adults

* `adults`: en realidad es una variable cualitativa m치s que cuantitativa --> podr칤amos probar a **dejarla tal cual o recategorizarla en 4 categor칤as** (ninguno - 1 - 2 - m치s de 2)

```{r}
hoteles %>% count(adults, sort = TRUE) %>% 
  mutate(porc = 100*n/sum(n), cumul = cumsum(porc))
```


### Variable is_repeated_guest

* `is_repeated_guest`: en realidad es **binaria** --> hay que convertirla a cualitativa (factor)

```{r}
hoteles %>%
  count(is_repeated_guest, sort = TRUE) %>%
  mutate(porc = 100*n/sum(n))

hoteles %>%
  group_by(is_repeated_guest) %>%
  count(children) %>% 
  mutate(porc = 100*n/sum(n)) %>%
  ungroup()
```


### Variables previous_cancellations y previous_bookings_not_canceled

* `previous_cancellations`: el 99.238% son 0 (y la mayor칤a de 1, sin ni침os) --> **eliminar**

* `previous_bookings_not_canceled`: el 95.47% son 0, el 1.9% son 1 --> se podr칤a probar a **dejarla tal cual o recategorizar en 3 categor칤as**

```{r}
hoteles %>% count(previous_cancellations == 0, sort = TRUE)

hoteles %>% count(previous_bookings_not_canceled, sort = TRUE) %>%
  mutate(porc = 100*n/sum(n), cumul = cumsum(porc))
```

### Variable booking_changes

* `booking_changes`: el 94.194% son 0 o 1 --> se podr칤a probar a **dejarla num칠rica o recategorizar en 3 categor칤as**

```{r}
hoteles %>% count(booking_changes, sort = TRUE) %>% 
  mutate(porc = 100*n/sum(n), cumul = cumsum(porc))
```

#### Variable days_in_waiting_list

* `days_in_waiting_list`: el 98% de los registros son 0 (y de los que no son casi todos no tienen ni침os) --> **eliminar variable**

```{r}
hoteles %>% count(days_in_waiting_list, sort = TRUE) %>% 
  mutate(porc = 100*n/sum(n), cumul = cumsum(porc))
```


### Variable average_daily_rate

* `average_daily_rate`: es la 칰nica num칠rica continua pero tiene **valores negativos o cero** (deber칤an ser estrictamente positivo) --> el 2.33% tiene **problemas de codificaci칩n o rango** que deberemos pasar a ausentes e imputarles un valores luego.

```{r}
hoteles %>%
  count(average_daily_rate <= 0) %>%
  mutate(porc = 100*n/sum(n))
```


### Variable total_of_special_requests

* `total_of_special_requests`: m치s del 96% son 0-1-2 --> se podr칤a **dejar num칠rica o recategorizarla en 4 categor칤as**.

```{r}
hoteles %>%
  count(total_of_special_requests, sort = TRUE) %>% 
  mutate(porc = 100*n/sum(n), cumul = cumsum(porc))
```


## Colinealidad

Por 칰ltimo, nos falta comprobar los **problemas de  colinealidad** entre las predictoras num칠ricas. Podemos tratar las **num칠ricas por separado** (aunque tengamos muchas que en realidad hacen m치s de cuali que de cuanti)

```{r}
library(corrr)
cor_matrix <- hoteles %>% select(where(is.numeric)) %>% cor() %>% round(2)
cor_matrix
```


```{r}
library(corrplot)
cor_matrix %>%
  corrplot(method = "number", tl.cex = 0.55, number.cex = 0.7, type = "lower")
```


No parece existir una correlaci칩n elevada entre ninguna.


## Fase 3: modificaci칩n (fuera de la receta)

Con lo observado en la fase de exploraci칩n deberemos tomar **dos tipos decisiones**:

* las que afectan a la **base de datos en general**: pasar a factores, problemas de codificaci칩n o rango, variables que no aportan, creaci칩n de variables en general, etc

* las que afectan a un **algoritmo en concreto**: normalizaci칩n para la m칠trica, recategorizaci칩n, tratamiento de outliers/ausentes, dummyficaci칩n, etc.

Pero antes...쯛ace falta **muestreo**? Parece que s칤 dado que tenemos muchas filas (al menos para hacer pruebas) --> muestreo **estratificado** (por ej., del 10%)

```{r}
# Muestreo del 10%
hoteles_sample <-
  hoteles_bruto %>%
  group_by(children) %>% 
  slice_sample(prop = 0.10) %>%
  ungroup()
```

Tras ello procederemos a las **modificaciones estructurales** (la tabla est치 incorrectamente codificada)

```{r}
# Convertir a cuali
hoteles_sample <-
  hoteles_sample %>% 
  mutate(across(where(is.character), as_factor)) %>%
  mutate(meal = factor(meal, levels = c("Undefined", "SC", "BB", "HB", "FB"),
                       ordered = TRUE))

# Modificaciones de variables existentes
hoteles_sample <-
  hoteles_sample %>% 
  mutate(lead_time = ifelse(lead_time > 365, 366, lead_time),
         average_daily_rate = ifelse(average_daily_rate < 0 | is.na(average_daily_rate), NA, average_daily_rate),
         is_repeated_guest = as_factor(is_repeated_guest))
```


## Fase 3: modificaci칩n (dentro de la receta)

### Partici칩n

#### Test vs lo dem치s

Antes de nada deberemos realizar nuestras particiones, y primero dividiremos en **test y lo dem치s**, con `initial_split()`, teniendo 10% en test y 90% en todo lo dem치s

```{r}
# Partici칩n 10% de test
hoteles_split <- initial_split(hoteles_sample, strata = children, prop = 0.9)
hoteles_split
```

F칤jate que en `hoteles_split` solo tenemos las instrucciones. Vamos a aplicarlas

```{r}
# Aplicamos partici칩n
hoteles_train <- training(hoteles_split)
hoteles_test <- testing(hoteles_split)
```

Tras ello nunca est치 de m치s comprobar que efectivamente lo ha realizado de manera estratificada

```{r}
# Comprobamos estratos
hoteles_train %>% count(children) %>% mutate(porc = 100 * n / sum(n))
hoteles_test %>% count(children) %>% mutate(porc = 100 * n / sum(n))
```


#### Validaci칩n

Tras ello usamos `validation_split()` para **dividir en train-validaci칩n** lo que ten칤amos en `hoteles_train` (75% del 90% nos quedar칤a 67.5% en train vs 22.5% en validaci칩n y 10% que ten칤amos en test)

```{r}
# Validaci칩n
hoteles_val <- validation_split(hoteles_train, strata = children,
                                prop = 0.75)
hoteles_val
```

De nuevo en `hoteles_val` solo tenemos las futuras instrucciones. F칤jate que de nuevo lo hacemos estratificado con `strata = children`

### Roles


Tras las particiones, el primer paso es **definir la receta**, indic치ndole el conjunto donde tenemos validaci칩n y train, y enfrentar `children` con todas. Despu칠s lo que haremos ser치 **asignar posibles roles** que nos puedan diferencias las acciones entre las variables

```{r}
# Receta
hoteles_rec <-
  # F칩rmula y datos
  recipe(data = hoteles_train, children ~ .)%>%
  # Roles
  add_role(contains("date"), new_role = "date") %>% 
  add_role(where(is.factor), new_role = "cuali") %>% 
  add_role(where(is.numeric), new_role = "cuanti") %>% 
  add_role(c(hotel, required_car_parking_spaces, is_repeated_guest), new_role = "binary") %>% 
  add_role(where(is.numeric) & !average_daily_rate, new_role = "maybe_cuali")
```

### Eliminar variables

Hab칤amos decidido que hab칤a variable que no quer칤amos usar as칤 que lo primero es eliminarlas para no acumularlas en el proceso

```{r}
# Receta
hoteles_rec <-
  hoteles_rec %>% 
  step_rm(c(deposit_type, days_in_waiting_list, previous_cancellations))
```

### Fechas

Con `step_date()` podemos indicarle directamente que extraiga de la fecha los elementos que le pidamos (en nuestro caso mes, d칤a de la semana y a침o). Adem치s con `listHolidays()` del paquete `{timeDate}` seleccionaremos festivos relevantes internacionalmente, y con `step_holiday()` marcaremos las fechas que lo sean. Tras ello eliminaremos la fecha original con `step_rm()`.

```{r}
library(timeDate)
# Receta
hoteles_rec <-
  hoteles_rec %>% 
  step_date(arrival_date, features = c("month", "dow", "year")) %>% 
  step_holiday(arrival_date,
               holidays = c(listHolidays("\\Mary"), listHolidays("\\Easter"),
                            listHolidays("\\Christ"), "NewYearsDay")) %>%
  # Eliminamos la variable
  step_rm(arrival_date)
```

Prueba a jugar con `listHolidays()` y las vacaciones que nos ofrecen (en global o para distintos pa칤ses)

```{r}
listHolidays()
```

### Outliers

En este caso yo voy a **detectar outliers a lo bruto**: detectando por la media e imputando por la media, pero solo de `has_role("cuanti")`, para no incluir a las binarias. Las cuali por la moda en caso de haber ausentes. Queda en tus manos mejorar esto.

```{r}
library(outliers)
# Receta
hoteles_rec <-
  hoteles_rec %>% 
  # Detectar outliers
  step_mutate(across(where(is.numeric), function(x) { ifelse(abs(scores(x, type = "z")) > 2.5 & !is.na(x), NA, x) })) %>% 
  # Imputar ausentes
  step_impute_mean(has_role("cuanti")) %>%
  step_impute_mode(has_role("cuali"))
```

### Filtro de correlaci칩n

Aplicamos un filtro de correlaci칩n para **prevenir problemas de colinealidad**.


```{r}
# Receta
hoteles_rec <-
  hoteles_rec %>% 
  # Filtro de correlaci칩n
  step_corr(has_role("cuanti"), threshold = 0.9)
```

### Normalizar por rango

**Normalizamos por rango** para poder aplicar una m칠trica en el knn (necesitamos todas entre [0,1] para que tengan el mismo peso)


```{r}
# Receta
hoteles_rec <-
  hoteles_rec %>% 
  # Normalizar por rango
  step_range(all_numeric_predictors())
```


### Variables dummy

Adem치s, en el caso concreto del knn, debemos **dummyficar** las cualitativas: crea k-1 variables binarias por de cada cualitativa de k niveles. F칤jate que le decimos que **tome todas las nominales, menos la variable objetivo**.

```{r}
# Receta
hoteles_rec <-
  hoteles_rec %>%
  # Dummyficamos
  step_dummy(all_nominal(), -all_outcomes())
```

### Filtro de cero varianza

```{r}
# Receta
hoteles_rec <-
  hoteles_rec %>%
  # Filtro de cero varianza
  step_zv(all_predictors())
```


# Fase 4: modelo y flujo

**쯈u칠 suceder칤a si hacemos un sobremuestreo?** 

```{r recipe2}
rec_class_bin <- recipe(data = hotel_train, children ~ .) %>%
  # Recategorizamos  
  step_mutate(previous_bookings_not_canceled =
                cut(previous_bookings_not_canceled,
                    breaks = c(-Inf, 0, 1, 2, Inf),
                    labels = c("none", "one", "two", "more")),
              booking_changes =
                cut(booking_changes, breaks = c(-Inf, 0, 1, 2, Inf),
                    labels = c("none", "one", "two", "more")),
              days_in_waiting_list =
                cut(days_in_waiting_list, breaks = c(-Inf, 0, 7, Inf),
                    labels = c("none", "week.or.less", "more.one.week")),
              previous_cancellations =
                cut(previous_cancellations, breaks = c(-Inf, 0, 1, 2, Inf),
                    labels = c("none", "one", "two", "more")),
              across(is_repeated_guest:days_in_waiting_list,
                     as.factor)) %>%
  # Imputamos ausentes (podr칤amos dejarlas como una categor칤a m치s)
  step_impute_mean(all_numeric_predictors()) %>%
  step_impute_mode(all_nominal_predictors())  %>%
  # Extraemos cosas de la fecha
  step_date(arrival_date, features = c("dow", "month")) %>%
  step_holiday(arrival_date,
               holidays =
                 c(listHolidays("\\Mary"), listHolidays("\\Easter"),
                   listHolidays("\\Christ"), "NewYearsDay")) %>%
  step_rm(arrival_date) %>%
  # Convertimos d칤as de la semana para no tener tildes
  step_mutate(arrival_date_dow =
                factor(arrival_date_dow, labels = c(7, 1:6))) %>%
  # Eliminamos variables sin varianza
  step_zv(all_predictors()) %>%
  # Reagrupamos
  step_other(all_nominal_predictors(), threshold = 0.02) %>%
  # Sobremuestreo 50-50%
  step_upsample(children, over_ratio = 1)

# Flujo de trabajo
hoteles_wflow <-
  workflow() %>%
  add_recipe(rec_class_bin)

# Aplicamos flujos
decision_tree_gini_fit <-
  hoteles_wflow %>%
  add_model(decision_tree_gini) %>%
  fit(data = hotel_train)
decision_tree_entropy_fit <-
  hoteles_wflow %>%
  add_model(decision_tree_entropy) %>%
  fit(data = hotel_train)

# Ajustes
decision_tree_gini_fit
decision_tree_entropy_fit

# Calculamos probabilidades de los dos
models <- list("gini" = decision_tree_gini_fit,
               "entropia" = decision_tree_entropy_fit)
pred_probs <- imap_dfr(models, augment,
                       new_data = hotel_test, .id = "model")

# En realidad solo nos interesa el modelo, la variable Children
# y las predicciones
pred_probs <- pred_probs %>%
  select(model, children, .pred_class, .pred_children, .pred_none)
pred_probs

# M칠tricas conjuntas
multi_metric <- metric_set(accuracy, sensitivity, specificity, roc_auc)
metrics <-
  pred_probs %>% 
  group_by(model) %>%
  multi_metric(truth = factor(children), estimate = .pred_class, .pred_children)
metrics

# Curvas ROC (feas)
roc_curves <-
  pred_probs %>% group_by(model) %>%
  roc_curve(factor(children), .pred_children)

# Ploteado
ggplot(roc_curves, aes(x = 1 - specificity, y = sensitivity, color = model)) +
  geom_line(lwd = 1.3) + geom_abline(lty = 4) +
  coord_equal() +
  scale_color_tableau(limits = c("gini", "entropia"),
                      labels = c("Gini (CART)", "Entrop칤a (C5.0)")) +
  scale_x_continuous(limits = c(0, 1), breaks = seq(0, 1, by = 0.1),
                     expand = c(0.005, 0.005)) +
  scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, by = 0.1),
                     expand = c(0.005, 0.005)) +
  labs(x = "1 - especificidad (proporci칩n falsos positivos)",
       y = "sensibilidad (proporci칩n verdaderos positivos)",
       title = "츼RBOLES DE DECISI칍N",
       color = "M칠todo",
       subtitle = "M칠tricas usadas: AUC, accuracy, sensib., especif. | Sobremuestreo: 50%-50%",
       caption =
         paste0("Autor: Javier 츼lvarez Li칠bana | ",
                "Datos: Tidymodels (hotels.csv)"))
```

## Visualizar el 치rbol

Tambi칠n podemos visualizar f치cilmente los 치rboles generados con CART (Gini, del paquete `{rpart}`): primero con `extract_fit_engine()` extraemos las rutas del 치rbol, y despu칠s con `rpart.plot(roundint = FALSE, extra = 4)` le indicamos que no redondee valores a enteros y de los modelos de visualizaci칩n elegimos `extra = 4` (prueba con varios para ver las diferencias). Para visualizar 치rboles `C5.0` ver documentaci칩n en <https://topepo.github.io/C5.0/reference/plot.C5.0.html>

```{r visualizar}
decision_tree_gini_fit %>%
  extract_fit_engine() %>%
  rpart.plot(roundint = FALSE, extra = 4)
```
  
Recuerda que parar interpretar mejor el 치rbol puedes repasar el significado de cada variable en <https://github.com/rfordatascience/tidytuesday/tree/master/data/2020/2020-02-11#data-dictionary>

## Importancia de las variables

Con `vip()` (del paquete hom칩nimo) podemos visualizar la **importancia relativa de las variables**. Para detalles del c치lculo ver <https://rdrr.io/cran/vip/man/vi_model.html> y  <https://koalaverse.github.io/vip/articles/vip.html>

```{r vip}
# Extraemos el ajuste
fit_gini <- decision_tree_gini_fit %>%
  extract_fit_engine()

# Aqu칤 se guardan los scores
fit_gini$variable.importance

# En tabla por si queremos hacer otra visualizaci칩n
tabla_vip <- vi(fit_gini)
tabla_vip

# Visualizamos
fit_gini %>% vip() +
  labs(x = "Importancia", y = "Variables",
       title = "IMPORTANCIA DE VARIABLES",
       subtitle = "Con el paquete {vip}",
       caption =
         paste0("Autor: Javier 츼lvarez Li칠bana | ",
                "Datos: Tidymodels (hotels.csv)"))
```


## Poda (prune)

Hasta ahora no hemos realizado una tarea muy habitual en 치rboles que es la **poda**. Para ello vamos a a침adir un par치metro extra `cost_complexity`, un n칰mero positivo que nos modelizar치 la penalizaci칩n por complicar el modelo (valores altos har치n podas m치s extremas).

```{r decision-tree-prune}
decision_tree_gini <-
  decision_tree(mode = "classification", tree_depth = 7,
                min_n = 0.025 * nrow(hotel_test),
                cost_complexity = 0.1) %>%
  set_engine("rpart")

# Aplicamo flujo
decision_tree_gini_fit <-
  hoteles_wflow %>% add_model(decision_tree_gini) %>%
  fit(data = hotel_train)

# Calculamos probabilidades
pred_probs <- augment(decision_tree_gini_fit, new_data = hotel_test)

# M칠tricas conjuntas
multi_metric <- metric_set(accuracy, sensitivity, specificity, roc_auc)
metrics <-
  pred_probs %>%
  multi_metric(truth = factor(children),
               estimate = .pred_class, .pred_children)
metrics

# Visualizando el 치rbol
decision_tree_gini_fit %>%
  extract_fit_engine() %>%
  rpart.plot(roundint = FALSE, extra = 4)
```

# Validaci칩n

Hasta ahora hemos probado un modelo, o varios modelos, pero con par치metros fijos y observando su m칠trica en el conjunto test. **쯏 si queremos un tercer conjunto intermedio de validaci칩n para decidir que par치metros son mejores?** A lo largo de esta secci칩n vamos a ver varias formas obtener un conjunto de validaci칩n, y a **optimizar nuestros par치metros de forma autom치tica**.

## Conjunto de validaci칩n
## Particionar a un conjunto de validaci칩n

La **validaci칩n m치s sencilla** es a침adir al inicio una tercera partici칩n de validaci칩n a partir del conjunto de entrenamiento (por ejemplo, el 30% del conjunto de entrenamiento)

```{r validation-split}
# CONJUNTO DE VALIDACI칍N INICIAL
val_set <- validation_split(hotel_train, strata = children,
                            prop = 0.70)
val_set
```

Este tipo de validaci칩n es **칰til cuando tenemos suficientes datos para realizar tres particiones** y obtener conjuntos de datos no excesivamente peque침os. En este caso, dado que hemos hecho primero una partici칩n 80-20% entre train-test y luego un 30% de entrenamiento va para validaci칩n, tendremos un **56% en entrenamiento, un 24% en validaci칩n y un 20% en test**. Tras realizar la partici칩n podemos indicarle que el **modelo que ha construido en entrenamiento**, sea **evaluado en la submuestra de validaci칩n**.
  
```{r metric-validation}
decision_tree <-
  decision_tree(mode = "classification", tree_depth = 7,
                min_n = 0.025 * nrow(hotel_test))
decision_tree_gini <- decision_tree %>%
  set_engine("rpart")
decision_tree_entropy <- decision_tree %>%
  set_engine("C5.0")

# Solo contra un conjunto de validaci칩n
decision_tree_gini_val <-
  hoteles_wflow %>%
  add_model(decision_tree_gini) %>% fit_resamples(val_set)
collect_metrics(decision_tree_gini_val) # sin std_error porque...n = 1

decision_tree_entropia_val <-
  hoteles_wflow %>%
  add_model(decision_tree_entropy) %>% fit_resamples(val_set)
collect_metrics(decision_tree_gini_val)
```

## Validaci칩n cruzada k-folds

```{r imagen-k-folds, echo = FALSE, out.width = "60%", fig.align = "center", fig.cap = "Filosof칤a de la validaci칩n cruzada (fuente: wikipedia)."}
knitr::include_graphics("./img/K-fold_cross_validation.jpg")
```
 
Dado que no siempre disponemos de un volumen suficiente de datos, una **opci칩n muy com칰n y que arroja unos resultados bastante buenos** es la llamada **validaci칩n cruzada v-folds**: dividimos en $v$ trozos nuestro conjunto de entrenamiento, de forma que realizamos las siguientes iteraciones:

* Iteraci칩n 1: entrenamos el modelo con los conjuntos $\left\lbrace 2, 3, \ldots, v \right\rbrace$ y validamos con el primer conjunto.

* Iteraci칩n 1: entrenamos el modelo con los conjuntos $\left\lbrace 1, 3, \ldots, v \right\rbrace$ y validamos con el segundo conjunto.

...

* Iteraci칩n v: entrenamos el modelo con los conjuntos $\left\lbrace 1, 2, \ldots, v1 \right\rbrace$ y validamos con el conjunto $v$-칠simo.

Este m칠todo nos permite, no solo no tener que disponer de un alto volumen de datos sino que adem치s **la validaci칩n ya no es sobre una sola muestra sino un promedio de varias** (eso s칤, muestras relacionadas entre s칤, no son independientes). Adem치s con `strata = children` le diremos que dichas particiones las hagan estratificadas para conservar 0's-1's. Antes **muestreamos 5000 para simular tener 춺pocos췉 datos**.

```{r k-folds}
# Muestreo inicial del 10% para simular tener menos datos
hoteles_sample <- hoteles_raw %>% slice_sample(prop = 0.1)

# Partici칩n 80-20%: estratificada
hoteles_split <-
  initial_split(hoteles_sample, strata = children, prop = 0.8)

# Aplicamos partici칩n
hotel_train <- training(hoteles_split)
hotel_test  <- testing(hoteles_split)

# Validaci칩n cruzada v-fold con v = 20 (20 conjuntos)
folds <- vfold_cv(hotel_train, v = 20, strata = children)
folds
```

El s칤mil m치s f치cil de visualizar es pensar en **nuestros datos como un cuadrado que hemos partido en $v$ trozos**, y en cada iteraci칩n elegimos una de las porciones para validar y el resto para entrenar. Sin embargo, esta partici칩n puede ser determinante en nuestros resultados, ya que **la forma en la que hemos hecho la partici칩n sesgar치 los resultados** (por ejemplo, partir nuestro cuadrado con cortes perpendiculares). Para eliminar ese sesgo, podemos indicarle en `repeats` las **veces que repetimos el proceso, realizando en cada repetici칩n una partici칩n distinta del cuadrado**, lo que **nos permite aumentar el n칰mero de datos en cada fold, pudiendo disminuir $v$**.

```{r k-folds-rep}
# Validaci칩n cruzada v-fold con v = 10 y 5 repeticiones
# Tenemos 50 iteraciones
folds <- vfold_cv(hotel_train, v = 10, strata = children, repeats = 5)
folds
```

Cuando nuestro conjunto lo validamos una sola vez con un conjunto de validaci칩n inicial, para tener una m칠trica real de nuestro algoritmo, lo **ideal ser칤a ejecutar un bucle, en cada iteraci칩n con una semilla aleatoria distinta**, ya que sino estamos tomando como m칠trica de referencia un solo intento (pudiendo tener buena o mala suerte, sin ser representativo de la calidad real de nuestro modelo). Con la validaci칩n cruzada obtenemos un **promedio mucho m치s ajustado a la realidad que un solo intento de validaci칩n**.

```{r flujo-k-folds}
decision_tree <-
  decision_tree(mode = "classification", tree_depth = 7,
                min_n = 0.025 * nrow(hotel_test))
decision_tree_gini <- decision_tree %>%
  set_engine("rpart")

# Aplicamos flujo a las v-folds
decision_tree_gini_cv <-
  hoteles_wflow %>%
  add_model(decision_tree_gini) %>% fit_resamples(folds)
collect_metrics(decision_tree_gini_cv)
```
## Optimizando par치metros (tune)

**쯇ara qu칠 validamos?** La verdadera **utilidad de la validaci칩n** es la **optimizaci칩n de los par치metros del modelo**, encontrar los hiperpar치metros que nos devuelvan un resultado m치s 칩ptimo (en funci칩n de una m칠trica). Para ello lo que vamos a hacer al definir el modelo es no asignar una constante a los par치metros sino que los vamos a **dejar sin fijar, asign치ndoles `tune()`** (entre par칠ntesis una etiqueta para luego ser usada): lo que har치 en validaci칩n es devolverte la **configuraci칩n 칩ptima** usando los resultados obtenidos en validaci칩n.


```{r modelo-tune}
# Modelo con tune
decision_tree <-
  decision_tree(mode = "classification",
                tree_depth = tune("depth"),
                min_n = tune("min_split"),
                cost_complexity = tune("cost"))
decision_tree_gini <- decision_tree %>%
  set_engine("rpart")

# Flujo de trabajo
hoteles_wflow <-
  workflow() %>%
  add_recipe(rec_class_bin) %>%
  add_model(decision_tree_gini)

# Par치metros a optimizar
param <- parameters(decision_tree_gini)
param$object

```

Tras indicarle los par치emtros que tiene que ajustar, vamos a **construir un grid de valores entre los que elegir**.

```{r grid-arboles}
# Construimos el grid de par치metros
grid_tree <-
  parameters(hoteles_wflow) %>%
  # Actualizamos
  update(depth = tree_depth(range = c(3, 8)),
         min_split = min_n(range = c(0.01, 0.1) * nrow(hotel_test)),
         cost = cost_complexity(range = c(-5, -1),
                                trans = log10_trans())) %>%
  grid_regular(levels = 3) 
grid_tree  # 27 modelos (3x3x3)

# Validaci칩n cruzada
folds <- vfold_cv(hotel_train, v = 5, strata = children, repeats = 3)

# Aplicamos flujo a las v-folds
decision_tree_gini_cv_tune <-
  hoteles_wflow %>%
  tune_grid(resamples = folds, grid = grid_tree,
            control = control_grid(verbose = TRUE),
            metrics = multi_metric)
# M칠tricas
decision_tree_gini_cv_tune %>% collect_metrics()
```

De las configuraciones posibles, **쯖u치l es la mejor de todas?** Con `show_best()` le podemos indicar que **obtenga AUTOM츼TICAMENTE los mejores modelos** en funci칩n de distintas m칠tricas.

```{r}
# 쮺u치l es el mejor y con qu칠 par치metros?
decision_tree_gini_cv_tune %>% show_best("accuracy")
decision_tree_gini_cv_tune %>% show_best("roc_auc")
```

## Validaci칩n en paralelo: visualizando el sobreajuste

Si queremos **probar muchos modelos y/o nuestro volumen de datos es elevado**, quiz치s nos lleve demasiado tiempo la validaci칩n cruzada para optimizar el mejor modelo. Aunque no es el objetivo de la asignatura, vamos a hacer una **incursi칩n a la programaci칩n paralelizada**. Vamos a empezar cargando algunos paquetes que necesitaremos.

```{r doparal}
library(parallel)
library(doParallel)
```

Ambos paquetes ser치n los que nos **permitan paralelizar de forma sencilla** (se puede hacer m치s 칩ptimo, pero de momento nos sirve) algunos de nuestros procesos. La idea es **mandar tareas independientes a procesadores distintos** (por ejemplo, una vez hecha la partici칩n de la validaci칩n cruzada, cada iteraci칩n se podr칤a hacer en ordenadores distintos), de forma que si una tarea tarda 6 minutos en un pc, al mandarlo a otros dos procesadores, el tiempo pueda bajar hasta los 2 minutos (no es del todo lineal ya que hay un tiempo m칤nimo necesario en cada paso pero para que nos hagamos una idea, supongamos que la reducci칩n en tiempos fuese lineal aproximadamente).

En muchas empresas u organismos de investigaci칩n se suele tener a disposici칩n de los usuarios un **conjunto de ordenadores (un cl칰ster)** com칰n a todos de forma que cada persona pueda mandar sus hilos en paralelo. Pero...no tenemos de eso. 쮼ntonces? Si es la primera vez que te lo dicen quiz치s te explote la almendra: **vamos a paralelizar en NUESTRO PROPIO ORDENADOR**. S칤, en nuestro ordenador, ya que quiz치s nunca te hayas fijado al comprar uno (a partir de ahora ya sabes que es algo clave a mirar) pero **un ordenador suele tener varios procesadores o _cores_** que **pueden funcionar de manera 춺independiente췉 uno de otro** (un port치til de gama media suele tener 4 n칰cleos, los port치tiles m치s dedicados a simulaci칩n, programaci칩n y audiovisuales suelen tener 6-8-12 n칰cleos); ver m치s detalles sobre [c칩mo paralelizar en R](https://privefl.github.io/blog/a-guide-to-parallelism-in-r/). Vamos a detectar la cantidad de n칰cleos de los que podemos disponer con `detectCores()`.

```{r detect-cores}
# Detectamos los cores que tenemos
detectCores()
```

Mi ordenador tiene `r detectCores()` (gracias, James Rhodes) pero el tuyo puede que tenga una cantidad diferente. A la hora de paralelizar es importante que lo hagamos **con cuidado** si es la primera vez que manejamos los paquetes de paralelizaci칩n ya que puede que nuestro ordenador se quede colgado por abusar de los recursos del mismo, as칤 mi consejo es que **definas el n칰mero de cores a usar como los que tienes menos uno, para asegurarte siempre de que uno anda libre** (para el resto de tareas de tu ordenador). Con `makeCluster()` montamos los cl칰ster en cada nodo y con `registerDoParallel()` registramos la paralelizaci칩n (puedes ver los hilos abiertos con `showConnections()`).

```{r make-cluster}
# Iniciamos la paralelizaci칩n
clusters <- detectCores() - 1
make_cluster <- makeCluster(clusters)
registerDoParallel(make_cluster)
showConnections()
```

Esta vez vamos a definir un grid manual de par치metros.

```{r}
# Modelo con tune
decision_tree <-
  decision_tree(mode = "classification",
                tree_depth = tune("depth"),
                min_n = tune("min_split"),
                cost_complexity = tune("cost"))
decision_tree_gini <- decision_tree %>%
  set_engine("rpart")

# Flujo de trabajo
hoteles_wflow <-
  workflow() %>%
  add_recipe(rec_class_bin) %>%
  add_model(decision_tree_gini)

# Grid
grid_manual_tree <- 
  expand_grid(depth = c(2, 4, 6, 8, 10), # 5 modelos
              min_split = c(10, 50, 100, 150), # 4 modelos,
              cost = 10^c(-5, -3, -2, -0.5)) # 4 modelos
grid_manual_tree
dim(grid_manual_tree) # 80 modelos

# v-folds con repeticiones (cuidado con pasarse que no acaba :P)
# 32 iteraciones de 80 modelos
folds <- vfold_cv(hotel_train, v = 8, strata = children, repeats = 4)

# Ajuste con tune paralelizado
decision_tree_gini_tune_par <- 
  hoteles_wflow %>% 
  tune_grid(resamples = folds, grid = grid_manual_tree,
            control = control_grid(allow_par = TRUE),
            metrics = multi_metric)
            
# finalizamos clusters
stopCluster(make_cluster)
registerDoSEQ()

# M칠tricas
decision_tree_gini_tune_par %>% collect_metrics()
decision_tree_gini_tune_par %>% show_best("accuracy")
decision_tree_gini_tune_par %>% show_best("roc_auc")

# Elegir el mejor
decision_tree_gini_tune_par %>% select_best("accuracy")
decision_tree_gini_tune_par %>% select_best("roc_auc")

decision_tree_gini_tune_par %>% 
  collect_metrics() %>% 
  mutate(cost = factor(cost),
         min_split = factor(min_split)) %>%
  ggplot(aes(x = depth, y = mean,
             color = cost, shape = min_split)) + 
  geom_point(size = 1.7) + 
  geom_line(size = 1.3, alpha = 0.8) +
  facet_wrap(~.metric, scales = "free", nrow = 2) +
  scale_color_tableau(labels = glue("coste = 1e{c(-5, -3, -2, -0.5)}")) +
  labs(y = "Promedio", x = "Profundidad del 치rbol",
       color = "Complejidad",
       shape = "M칤nimo split",
       title = "Comparativa de 치rboles (v-folds paralelizada)",
       subtitle = "Oversampling: ratio = 1",
       caption =
         paste0("Autor: Javier 츼lvarez Li칠bana | ",
                "Datos: Tidymodels (hotels.csv)"))
```



## Random forest

Por 칰ltimo, podemos aplicar f치cilmente un **random forest**, un ejemplo de **bagging (bootstrap aggregaating)** de 치rboles (obtener como clasificaci칩n final el promedio o combinaci칩n de varios clasificadores construidos a partir de submuestras aleatoriamente elegidas de la muestra original con reemplazamiento). La idea de los **random forest** es intentar **reducir la varianza** (con el bagging cl치sico puede no conseguirse por existir un predictor muy influyente que acaba produciendo 치rboles similares): am칠n de considerar submuestras aleatorias diferentes, en cada decisi칩n a tomar, se seleccionan aleatoriamente $m < p$ variables ($p$ variables en total, por ejemplo, $m = \sqrt{p}$), de forma que se hace un 춺barrido췉 de muchos 치rboles con una parte aleatoria de las variables y una parte aleatoria de los datos.

Para ello usaremos la funci칩n `rand_forest()` con tres argumentos:
* `mtry`: n칰mero de predictores que el 치rbol puede ver en cada decisi칩n (si es igual a $p$, es equivalenteun bagging cl치sico)
* `min_n`: como antes, es el n칰mero m칤nimo de observaciones que se permite tener a un nodo para dividirse.
* `trees`: 치rboles que prueba.

Ojo: vamos a lanzar 1000 치rboles, que seleccione 25 configuraciones posibles del par `mtry`-`min_n`, para decidir cual es el par de hiperpar치metros m치s 칩ptimo (en total, 25 000 치rboles).

```{r random-forest, eval = FALSE}
# Partici칩n 80-20%
hoteles_split <-
  initial_split(hoteles_raw, strata = children, prop = 0.8)

# Aplicamos partici칩n
hotel_train <- training(hoteles_split)
hotel_test  <- testing(hoteles_split)

# Conjunto de validaci칩n
val_set <- validation_split(hotel_train, strata = children,
                            prop = 0.70)

# Iniciamos la paralelizaci칩n
clusters <- detectCores() - 1

# Random forest con tune
rf_hotel <-
  rand_forest(mtry = tune(), min_n = tune(), trees = 1e2) %>% 
  set_engine("ranger", num.threads = clusters) %>% 
  set_mode("classification")

# Flujo de trabajo
hoteles_wflow <-
  workflow() %>%
  add_recipe(rec_class_bin) %>%
  add_model(rf_hotel)

# Ajuste con tune paralelizado
rf_tune_par <- 
  hoteles_wflow %>% 
  tune_grid(resamples = val_set, grid = 10,
            control = control_grid(save_pred = TRUE),
            metrics = multi_metric)
            
# finalizamos clusters (por si acaso)
stopCluster(make_cluster)
registerDoSEQ()
```


