---
title: "T√©cnicas de miner√≠a de datos"
subtitle: "M√°ster en Miner√≠a de Datos e Inteligencia de Negocio"
author:
  - "Javier √Ålvarez Li√©bana (Fac. Estudios Estad√≠sticos - UCM)"
date: "√öltima actualizaci√≥n: `r format(lubridate::today(), format = '%d-%m-%Y')`"
output:
  xaringan::moon_reader:
    css: xaringan-themer.css
    # css: [default, style.css]
    nature:
      slideNumberFormat: "%current%"
      highlightStyle: github
      highlightLines: true
      ratio: 16:9
      countIncrementalSlides: true
---


```{r settings, include = FALSE, warning = FALSE}
knitr::opts_chunk$set(fig.retina = 3, out.width = "100%",
                      cache = FALSE, comment = ">",
                      echo = TRUE, message = FALSE,
                      warning = FALSE, hiline = TRUE,
                      dpi = 100)
```

```{r xaringan-extra, include = FALSE, warning = FALSE}
# devtools::install_github("gadenbuie/xaringanExtra")
library(xaringanExtra)
use_xaringan_extra(c("tile_view", "animate_css", "tachyons"))
use_tile_view() # panel
use_extra_styles(hover_code_line = TRUE,
                 mute_unhighlighted_code = FALSE) # Hover triangle
# code line
use_clipboard( # About clipboard
  button_text = "Click para copiar c√≥digo",
  success_text = "C√≥digo copiado",
  error_text = "Ctrl+C para copiar"
)

# use_freezeframe() # restarting gifs
# use_animate_all("fade") # animates
use_panelset() # panels 
```

```{r xaringan-themer, include = FALSE, warning = FALSE}
# devtools::install_github("gadenbuie/xaringanthemer")
library(xaringanthemer)
style_duo_accent(primary_color = "#1F4257",
          secondary_color = "#EA9D8E", # #F97B64",
          background_color = "#FFFEFE",
          header_font_google = google_font("Josefin Sans"),
          text_font_google =
            google_font("Montserrat", "300", "300i", "400", "500", "600", "700", "800", "900"),
          code_font_google = google_font("Fira Mono"),
          black = "#1F4257",
          inverse_text_color = "#1F4257",
          inverse_header_color = "#1F4257",
          base_font_size = "21px",
          text_font_size = "1.1rem",
          code_font_size = "1rem",
          header_h1_font_size = "2.8rem",
          header_h2_font_size = "2.3rem",
          header_h3_font_size = "1.8rem",
          code_highlight_color = "rgba(248, 223, 88, 0.25)",
          code_inline_background_color = "rgba(248, 223, 88, 0.6)",
          code_inline_font_size = "1em",
          colors = c(purple = "#74688D",
                     yellow = "#F8DF58",
                     green = "#2c8475",
                     red = "#E54F4D",
                     orange = "#EA9D8E",
                     green_light = "rgba(44, 132, 117, 0.35)",
                     red_light = "rgba(229, 79, 77, 0.7)",
                     purple_light = "rgba(116, 104, 141, 0.5)"),
          text_bold_font_weight = 800,
          link_decoration = "underline dotted",
          link_color = "#74688D",
          inverse_link_color = "#1F4257"
)
```


class: inverse center middle

# ATAJOS DE LAS DIAPOSITIVAS


```{r packages, include = FALSE, warning = FALSE}
library(tidyverse)
library(lubridate)
library(glue)
```


$$\\[2in]$$

.left[Pulsa <kbd-black>O</kbd-black> para ver el **PANEL DE DIAPOSITIVAS**]
.left[Pulsa <kbd-black>H</kbd-black> para ver **OTROS ATAJOS**]

---

# .orange[MATERIAL] de las clases


.pull-left[

- **.bg-purple_light[Diapositivas]** del curso:
<https://dadosdelaplace.github.io/teaching/data_mining/slides>

- **.bg-red_light[Evaluaci√≥n]** de la asignatura
<https://github.com/dadosdelaplace/teaching/tree/main/data_mining/eval>

- **.bg-yellow[Scripts]** de la asignatura
<https://github.com/dadosdelaplace/teaching/tree/main/data_mining/scripts>

- **.bg-orange[Bibliograf√≠a]**: <https://github.com/dadosdelaplace/teaching/tree/main/data_mining/biblio>

&nbsp;

- **.bg-green_light[Manual introductorio de R]**: <https://dadosdelaplace.github.io/courses-intro-R/>

]

---

# Me presento: la turra

.pull-left[

```{r echo = FALSE,  out.width = "80%", fig.align = "left"}
knitr::include_graphics("./img/me.jpeg")
``` 

]

.pull-right[

* **.bg-purple_light[Javier √Ålvarez Li√©bana]**, nacido en 1989 en Carabanchel Bajo (Madrid)

* Licenciado (UCM) en **Matem√°ticas** (Erasmus en Bologna mediante). **M√°ster (UCM) en Ingenier√≠a Matem√°tica** (2013-2014)


* **.bg-orange[Doctorado en estad√≠stica]** por la Universidad de Granada


* Encargado de la **visualizaci√≥n y an√°lisis de datos covid** de la Consejer√≠a de Salud del **Principado de Asturias**

]


Intentando eso de la **.bg-yellow[divulgaci√≥n]** por **Twitter** (**.bg-yellow[@dadosdelaplace]**) e **Instagram** (**.bg-yellow[@javieralvarezliebana]**)

---

name: objetivos

# .orange[OBJETIVOS] de la asignatura


El **.bg-purple_light[prop√≥sito]** de esta asignatura ser√° cuadruple

- **.bg-orange[Quitarnos el miedo]** a programar: a programar se aprende programando, no hace falta ser Julian Assange.

--

- Aprender las **.bg-orange[t√©cnicas b√°sicas de depuraci√≥n y exploraci√≥n]** datos, aprendiendo a implementarlas en un software estad√≠stico.

--

- Aprender las **.bg-orange[t√©cnicas b√°sicas de miner√≠a de datos]**, centr√°ndonos en las t√©cnicas de **.bg-orange[aprendizaje supervisado]**.

--

- Ser capaces de **.bg-orange[interpretar y evaluar]** nuestros modelos.

&nbsp;

üìö Estas **diapositivas** han sido elaboradas con el propio `R` haciendo uso de los paquetes `{xaringan}`, `{xaringanExtra}` y `{xaringanthemer}`.

---

# .orange[EVALUACI√ìN] de la asignatura


La **.bg-purple_light[evaluaci√≥n]** del curso se har√° mediante entregas:

* El **.bg-orange[40% de la nota]** final corresponder√° a peque√±as **.bg-green_light[pr√°cticas individuales]** (entre 2 y 4 pr√°cticas) que se empezar√°n en clase y se completar√°n en casa (se deber√°n entregar ambos archivos).

* El otro **.bg-orange[40% de la nota]** vendr√° determinado por la entrega de **.bg-green_light[1-2 pr√°cticas grupales]** (m√≠nimo 3, m√°ximo 5 personas). Se podr√° solicitar a cualquier persona del grupo que explique el trabajo realizado en una tutor√≠a individual.

*  El otro **.bg-orange[20% de la nota]** se asignar√° en funci√≥n de un **.bg-green_light[datathon final]** que se realizar√° de forma grupal (m√≠nimo 2, m√°ximo 4 personas).

---

# .orange[EVALUACI√ìN] de la asignatura


* Para poder promediar nota es **.bg-red_light[obligatorio]** entregar **.bg-purple_light[todas las entregas individuales]** con una **.bg-green_light[nota superior al 3]** sobre 10, am√©n de participar en **.bg-purple_light[al menos una entrega grupal]**.

* Adem√°s la nota media de las entregas **.bg-red_light[individuales no podr√° ser un 50% inferior]** a la media de notas grupales.


* En caso de **.bg-red_light[no cumplir dichos requisitos]**, y/o haya faltado a m√°s de un tercio de las clases, tendr√° que presentarse a un examen final, cuya
nota ser√° el 100% de la nota del curso.

---

# .orange[CONTENIDOS] de la asignatura


- Las **.bg-purple_light[primeras clases]** las dedicaremos a una **.bg-orange[introducci√≥n de la programaci√≥n]** en R (ya que necesitaremos algunas nociones b√°sicas para poder funcionar) as√≠ como **.bg-orange[algunos conceptos b√°sicos de estad√≠stica]** (medidas de centralizaci√≥n, dispersi√≥n, sesgo/varianza, supervisado vs no supervisado, metolodog√≠a SEMMA, etc).

--

- Metodolog√≠as de **.bg-purple_light[aprendizaje supervisado]**:
  - Algoritmo de los **.bg-orange[k-vecinos (knn)]**: clasificaremos elementos en funci√≥n de la moda/media de los elementos m√°s cercanos.
  
  - **.bg-orange[√Årboles de decisi√≥n]**: clasificaremos elementos en funci√≥n de la moda/media de una partici√≥n final (hoja) tras segmentar nuestro espacio de variables (reglas de decisi√≥n).
  
  - **.bg-orange[Regresi√≥n lineal]**: realizaremos una predicci√≥n (variable continua) teniendo como inputs una colecci√≥n de variables continuas, asumiendo una relaci√≥n lineal.
  
  - **.bg-orange[Regresi√≥n log√≠stica y GLM]**: realizaremos una predicci√≥n continua de la probabilidad de que una variable cualitativa tome cada una de las categor√≠as (probabilidad de estar sano o enfermo, por ejemplo).
  
---

# .orange[EJEMPLOS] reales de alumnos



‚úàÔ∏è **.bg-purple_light[Clasificaci√≥n de vuelos]**: usando, entre otras, variables de tr√°fico de aereo, tipolog√≠a de vuelo, variables meteorol√≥gicas, se consigui√≥ clasificar el retraso (o no) de 4 millones de vuelos (TFM de Almudena Mar√≠a Moreno Maderuelo)

--

üì∞ **.bg-purple_light[Clasificaci√≥n de Fake News]**: usando t√©cnicas de miner√≠a de datos aplicadas a textos (miner√≠a de textos), se propuso clasificar noticias en verdaderas o falsas, analizando la frecuencia y sentimientos de las palabras analizadas, as√≠ como la relaci√≥n entre las palabras (TFM de Iv√°n Guarionex de Fr√≠as Chireno)

--

ü©∫ **.bg-purple_light[Predicci√≥n de diabetes]**: haciendo uso de diferente variables m√©dicas y de h√°bitos de salud sacados de la encuesta de salud p√∫blica de EE.UU., se pretende predecir la aparici√≥n o no de diabetes en personas adultos, y determinar posibles factores de riesgo (TFM de Mar√≠a Mart√≠nez Ramudo).

--

üó≥ **.bg-purple_light[Predicci√≥n de encuestas electorales]**: usando el promedio de diferentes encuestas, y considerando diferentes variables sociol√≥gicos (como el sesgo de las casas encuestadores), conseguir una predicci√≥n del % de voto de cada partido promediando por tama√±o de muestra y ventana temporal (TFM de Enric Palau Payeras)

---


class: inverse center middle

# CLASES

&nbsp;

.pull-left[

#### [CLASE 1: INTRODUCCI√ìN A R](#clase-1)

#### [CLASE 2: PRIMEROS DATOS Y CONCEPTOS](#clase-2)

#### [CLASE 3: TIDYDATA](#clase-3)

#### [CLASE 4: INTRO A LA MINER√çA (SEMMA)](#clase-4)

#### [CLASE 5: PRIMER ALGORITMO (KNN)](#clase-5)

#### [CLASE 6: DEPURACI√ìN PARA KNN](#clase-6)

]

.pull-right[

#### [CLASE 7: MODELIZANDO CON TIDYMODELS (KNN)](#clase-7)

#### [CLASE 8: PROFUNDIZANDO EN TIDYMODELS (KNN)](#clase-8)

#### [CLASE 9: VALIDACI√ìN CRUZADA, SOBREMUESTREO Y DATAVIZ](#clase-9)

]


---

class: inverse center middle
name: clase-1

# CLASE 1: introducci√≥n a R desde cero.

&nbsp;

### [Instalaci√≥n](#instalacion)

### [¬øQu√© es R? Primeros pasos](#que-es-R)

### [Primeros ejercicios](#ejercicios1)

### [Variables num√©ricas y caracteres](#variables)

### [Variables l√≥gicas y de tipo fecha](#logicas)

### [Ejercicios](#ejercicios2)


---

name: instalacion

# Requisitos

Para la asignatura los √∫nicos **.bg-purple_light[requisitos]** ser√°n:

--

1. **.bg-orange[Conexi√≥n a internet]** (para la descarga de algunos datos y paquetes).

--

2. **.bg-orange[Instalar R]**: ser√° nuestro lenguaje, nuestro **.bg-yellow[castellano]** para poder ¬´comunicarnos con el ordenador. La descarga la haremos (gratuitamente) desde <https://cran.r-project.org/>

--

3. **.bg-orange[Instalar R Studio]**. De la misma manera que podemos escribir castellano en un Word o en un tuit, podemos usar **distintos IDE** (entornos de desarrollo integrados, nuestro Office), para que el trabajo sea m√°s c√≥modo. Nuestro **.bg-yellow[Word]** para nosotros ser√° **RStudio**.

.left[
  <img src = "https://raw.githubusercontent.com/dadosdelaplace/slides-ECI-2022/main/img/cran-R.jpg" alt = "cran-R" align = "left" width = "460" style = "margin-top: 2vh">
]

.right[
  <img src = "https://raw.githubusercontent.com/dadosdelaplace/slides-ECI-2022/main/img/R-studio.jpg" alt = "RStudio" align = "right" width = "460" style = "margin-top: 2vh;">
]


---

# Instalaci√≥n de R

El lenguaje `R` ser√° nuestra **.bg-purple_light[gram√°tica]**, nuestra ortograf√≠a y nuestro diccionario

.pull-left[



- **Paso 1**: entra en <https://cran.r-project.org/> y selecciona **.bg-purple_light[sistema operativo]**.

- **Paso 2**: para **.bg-purple_light[Mac]** basta con que hacer click en el archivo .pkg, y abrirlo una vez descargado. Para sistemas **.bg-purple_light[Windows]**, debemos clickar en `install R for the first time` y en la siguiente pantalla en `Download R for Windows`. Una vez descargado, abrirlo como cualquier archivo de instalaci√≥n.

- **Paso 3**: abrir el **ejecutable**.

]

.pull-right[

<img src = "https://raw.githubusercontent.com/dadosdelaplace/slides-ECI-2022/main/img/cran-R.jpg" alt = "cran-R" align = "left" width = "900" style = "margin-top: 1vh">

]

**.bg-green_light[Consejito]**: siempre que tengas que descargar algo de CRAN (ya sea el propio R o un paquete), aseg√∫rate de tener conexi√≥n a **.bg-orange[internet]**.


---

# Primera operaci√≥n

Para comprobar que se ha instalado correctamente, tras abrir `R`, deber√≠as ver una **pantalla blanca** similar a esta (en realidad se llama **.bg-purple_light[consola]**). Vamos a escribir nuestra **.bg-orange[primera operaci√≥n]** en la consola:

.pull-left[

* A una variable llamada `a` le asignaremos el valor 1 (asignamos con `<-`, como una flecha)

```{r eval = FALSE}
# Una variable a con valor --> 1
a <- 1 #<<
```

]

--

.pull-right[

* A otra variable llamada `b` le asignaremos el valor 2 (cambia a la izquierda el nombre, cambia a la derecha el valor).

```{r eval = FALSE}
# Una variable b con valor --> 2
b <- 2 #<<
```

]

--

.pull-left[

* Sumamos las variables haciendo `a + b`.

```{r eval = FALSE}
# Primera operaci√≥n
a <- 1 # Una variable a con valor --> 1
b <- 2 # Una variable b con valor --> 2
a + b #<<
```
]

--

.pull-right[

* El resultado que nos devuelve ser√° `3`.

```{r echo = FALSE}
a <- 1
b <- 2
a + b
```

]

---

# .orange[INSTALACI√ìN] de RStudio

El **.bg-purple_ligth[Word]** que usaremos para trabajar y escribir en nuestro lenguaje ser√° **.bg-purple_ligth[RStudio]** (lo que se conoce como un **IDE**, un entorno integrado de desarrollo).

.pull-left[

* **Paso 1**: entra en la [web oficial de RStudio](https://www.rstudio.com/products/rstudio/download/#download) y selecciona la **.bg-purple_light[descarga gratuita]**.

* **Paso 2**: selecciona el ejecutable que te aparezca, acorde a tu sistema operativo.

* **Paso 3**: tras descargar el ejecutable, hay que abrirlo como otro cualquier otro ejecutable y dejar que **.bg-purple_light[termine la instalaci√≥n]**.

]

.pull-right[

```{r echo = FALSE,  out.width = "80%", fig.align = "left"}
knitr::include_graphics("./img/R-studio.jpg")
``` 


]

---

# .orange[ORGANIZACI√ìN] de RStudio

.pull-left[

```{r echo = FALSE,  out.width = "95%", fig.align = "left"}
knitr::include_graphics("./img/inicio_rstudio_2.jpg")
``` 

]

.pull-right[

* **.bg-purple_light[Consola]**: es el nombre para llamar a la ventana grande que te ocupa buena parte de tu pantalla. Prueba a escribir el mismo c√≥digo que antes (la suma) en ella. La consola ser√° donde **.bg-orange[ejecutaremos √≥rdenes]** y **.bg-yellow[mostraremos resultados]**.
]

---

# .orange[ORGANIZACI√ìN] de RStudio

.pull-left[

```{r echo = FALSE,  out.width = "75%", fig.align = "left"}
knitr::include_graphics("./img/inicio_rstudio_3.jpg")
``` 

]

.pull-right[

* **.bg-purple_light[Environment]** (entorno de variables): la pantalla peque√±a (puedes ajustar los m√°rgenes con el rat√≥n) que tenemos en la parte superior derecha. Nos mostrar√° las **variables que tenemos definidas, el tipo y su valor**.

]

---

# .orange[ORGANIZACI√ìN] de RStudio

.pull-left[

```{r echo = FALSE,  out.width = "85%", fig.align = "left"}
knitr::include_graphics("./img/inicio_rstudio_4.jpg")
``` 

]

.pull-right[

* **.bg-purple_light[Panel multiusos]**: la ventana que tenemos en la parte inferior derecha no servir√° para buscar **.bg-orange[ayuda de funciones]**, adem√°s de para **.bg-yellow[visualizar gr√°ficos]**. 

]

---

name: que-es-R

# ¬øQu√© es R?


<img src = "https://logos.turbio.repl.co/rlang.svg" alt = "Rstudio" align = "left" width = "300" style = "margin-top: 1vh;margin-right: 2rem;">

`R` es un **.bg-purple_light[lenguaje estad√≠stico]**, creado por y para la estad√≠stica, con 4 ventajas fundamentales:

--

* **.bg-purple_light[Software libre]** (como C++, Python, etc). no solo es gratis, sino que permite **.bg-orange[acceder libremente a c√≥digo ajeno]**.

--

* **.bg-purple_light[Lenguaje modular]**: en la instalaci√≥n que hemos realizado solo se ha instalado el m√≠nimo para poder funcionar. Al ser software libre, existen **.bg-orange[trozos de c√≥digo]** hechos por otras personas (**.bg-yellow[paquetes]**) que podemos instalar seg√∫n necesidades.

--

* **.bg-purple_light[Gran comunidad de usuarios]**: `R` tiene una comunidad de usuarios gigante para hacer estad√≠stica (Python tiene una comunidad m√°s enfocada al Machine Learning), con m√°s de 18 000 paquetes.

--

* **.bg-purple_light[Lenguaje de alto nivel]**. Los lenguajes de alto nivel, como `R` o `Python`, facilitan la programaci√≥n al usuario (menor curva de aprendizaje, aunque m√°s lentos en ejecuci√≥n).


---

# Paquetes en R

A lo largo del curso usaremos varios de esos **.bg-purple_light[paquetes]**, como por ejemplo el paquete `{ggplot2}`, un paquete para la elaboraci√≥n de **.bg-purple_light[visualizaciones de datos]**. Vamos a instalarlo (necesitamos internet para ello) con la orden `install.packages("ggplot")`

```{r eval = FALSE}
install.packages("ggplot2")
```

&nbsp;


&nbsp;



La **.bg-purple_light[instalaci√≥n]** de un paquete es el equivalente a **.bg-orange[comprar a un libro]**: solo lo debemos hacer **la primera vez** que lo usemos en un ordenador. Una vez que tenemos comprado nuestro libro, para poder usarlo, simplemente debemos indicar al programa que nos lo **.bg-purple_light[acerque de la estanter√≠a]** con `library(ggplot2)`.

```{r eval = FALSE}
library(ggplot2)
```

---

class: inverse center middle

**COMPRAR** libro --> instalar un paquete (una sola vez) `install.packages()`
<figure>
<img src = "https://cdn.cienradios.com/wp-content/uploads/sites/14/2020/09/Book-Depository-2.jpg" alt = "comprar-libros" align = "middle" width = "480" style = "margin-top: 1vh;">
</figure>

**SELECCIONAR** libro (ya comprado) --> acceder a un paquete instalado (en cada sesi√≥n que queramos usarlo) `library()`
<figure>
<img src = "https://cdn.sincroguia.tv/uploads/programs/l/a/-/la-biblioteca-de-los-libros-rechazados-704306_SPA-77.jpg" alt = "comprar-libros-2" align = "middle" width = "480" style = "margin-top: 1vh;">
</figure>


---

class: center middle

# .orange[CASOS REALES] de uso de R


.pull-left[

```{r echo = FALSE,  out.width = "97%", fig.align = "left"}
knitr::include_graphics("./img/covid_isciii.jpg")
``` 

]

.pull-right[

```{r echo = FALSE,  out.width = "97%", fig.align = "left"}
knitr::include_graphics("./img/momo_isciii.jpg")
``` 


]

Las webs del Instituto de Salud Carlos III <https://cnecovid.isciii.es/covid19/> y <https://momo.isciii.es/panel_momo/> est√°n hechas con `R` (con `{shiny}` y `{plotly}` )

---

# .orange[CASOS REALES] de uso de R

.pull-left[

```{r echo = FALSE,  out.width = "99%", fig.align = "left"}
knitr::include_graphics("./img/elpais_R.jpg")
``` 

]

.pull-right[

El **.bg-purple_light[equipo de datos]** (Borja Andrino, Kiko Llaneras y Daniele Grasso) trabaja con `R` para elaborar sus an√°lisis, desde los datos electorales hasta el cambio clim√°tico.

Es una de las razones por las que son capaces de realizar brillantes an√°lisis de grandes vol√∫menes de datos de forma r√°pida y √°gil: la **.bg-purple_light[automatizaci√≥n de procesos]** que nos permite programar en `R` puede ser fundamental para analizar datos que hasta entonces no pod√≠amos.

]


---

# .orange[Incel] vs excel

```{r echo = FALSE, out.width = '75%', fig.align = "center"}
knitr::include_graphics("./img/incel.jpg")
```

---

class: inverse center middle

# ¬øPor qu√© .orange[NO] usamos Excel?

![](./img/meme_barco.jpg)

---

# ¬øPor qu√© .orange[NO] usamos Excel?

Excel es una **.bg-purple_light[hoja de c√°lculo]**, ni m√°s ni menos, y el propio **Microsoft desaconseja su uso** para el an√°lisis de datos. El Excel es una herramienta maravillosa para ser usada como una sencilla hoja de c√°lculo (llevar cuentas de tu familia, declaraci√≥n de Renta, planificar viajes, etc).

&nbsp;

**.bg-red_light[NO EST√Å DISE√ëADO]** para ser una base de datos, y muchos menos pensado para generar un entorno flexible para el an√°lisis estad√≠stico:

* **.bg-red_light[Software de pago]**

* **.bg-red_light[Software cerrado]**: solo podemos hacer lo que Excel ha cre√≠do que interesante que podamos hacer.

* **.bg-red_light[Alto consumo de memoria]**.

* **.bg-red_light[No es universal]**: no solo es de pago sino que adem√°s, dependiendo de la versi√≥n que tengas de Excel, tendr√° un formato distinto para datos como fechas, teniendo incluso extensiones distintas.

---



# .red[EPIC FAILS] en Excel

Problemas de **.red[versiones]**


```{r echo = FALSE,  out.width = "37%", fig.align = "left"}
knitr::include_graphics("./img/excel_genes.jpg")
``` 


üìö Ver **.bg-green_light[bibliograf√≠a]** en <https://github.com/dadosdelaplace/teaching/tree/main/data_mining/biblio>


---

# .red[EPIC FAILS] en Excel

Problemas de **.red[memoria]**

```{r echo = FALSE,  out.width = "50%", fig.align = "left"}
knitr::include_graphics("./img/excel_uk.jpg")
``` 


üìö Ver **.bg-green_light[bibliograf√≠a]** en <https://github.com/dadosdelaplace/teaching/tree/main/data_mining/biblio>


---

# .red[EPIC FAILS] en Excel

Problemas de **.red[codificaci√≥n]**

```{r echo = FALSE,  out.width = "50%", fig.align = "left"}
knitr::include_graphics("./img/excel_edades.jpg")
``` 

üìö Ver **.bg-green_light[bibliograf√≠a]** en <https://github.com/dadosdelaplace/teaching/tree/main/data_mining/biblio>

---

name: primeros-pasos

# Primeros pasos en R: .orange[CALCULADORA]

Empecemos por lo sencillo: **.bg-purple-light[¬øc√≥mo usar R como una calculadora?]** Si escribimos `2 + 1` en la consola y pulsamos ENTER, la consola nos mostrar√° el resultado de la suma.

```{r}
2 + 1
```

--

Si dicha suma la quisi√©ramos utilizar para un segundo c√°lculo: ¬øy si la **.bg-purple-light[almacenamos en alguna variable]**? Por ejemplo, vamos a guardar la suma en una variable `x`

```{r}
x <- 2 + 1 #<<
```

--

Si te fijas ahora `x` aparece definida en nuestro **.bg-yellow[environment]**, y puede ser usada de nuevo

```{r}
x + 3
```

---

# Primeros pasos en R: .orange[CALCULADORA]

### Multiplicaci√≥n

```{r eval = FALSE}
x * y #<<
```

### Elevar al cuadrado

```{r eval = FALSE}
x^2 #<<
```

### Valor absoluto

```{r eval = FALSE}
abs(x) #<<
```

---

# .red[Errores]

Durante tu aprendizaje va a ser **muy habitual** que las cosas no salgan a la primera, apareciendo en consola **.bg-purple_light[mensajes de error]** en un **.bg-red_light[color rojo]**. No te asustes: lo peor que puede pasar es que tengas que reiniciar `R`).

&nbsp;

* Mensajes de **.bg-red_light[ERROR]**: ir√°n precedidos de la frase **.bg-yellow[¬´Error in‚Ä¶¬ª]**, y ser√°n aquellos fallos que **impidan la ejecuci√≥n del c√≥digo** 

```{r error = TRUE}
"a" + 1 # intentando sumar 1 a un texto
```

&nbsp;

**.bg-green_light[CONSEJO]**: lee siempre los mensajes de error para aprender de ellos (ya que suelen dar pistas de c√≥mo resolverlos).

---

# .red[Errores]

Durante tu aprendizaje va a ser **muy habitual** que las cosas no salgan a la primera, apareciendo en consola **.bg-purple_light[mensajes de error]** en un **.bg-red_light[color rojo]**. No te asustes: lo peor que puede pasar es que tengas que reiniciar `R`).

&nbsp;
 
* Mensajes de **.bg-orange[WARNING]**: ir√°n precedidos de la frase **.bg-yellow[¬´Warning in‚Ä¶¬ª]**, y son los fallos m√°s delicados ya que son posibles incoherencias pero sin que tu c√≥digo deje de ejecutarse.

```{r warning = TRUE}
sqrt(-1) # raiz cuadrada de n√∫mero negativo
```

&nbsp;

**¬øHa ejecutado la orden?** S√≠, pero te advierte de que el resultado de la operaci√≥n es un `NaN`, **Not A Number**, un valor que no existe (al menos dentro de los n√∫meros reales).


---

# ¬øD√≥nde programamos? .orange[SCRIPTS]

Un **.bg-purple_light[script]** ser√° el documento en el que programamos, nuestro equivalente a un archivo .doc, pero aqu√≠ ser√° un archivo con extensi√≥n `.R`, donde **escribiremos las √≥rdenes**. Para **.bg-purple_light[abrir nuestro primero script]**, haz click en el men√∫ superior en `File << New File << R Script`.

&nbsp;


.pull-left[


```{r echo = FALSE,  out.width = "95%", fig.align = "left"}
knitr::include_graphics("./img/inicio_rstudio_5.jpg")
``` 

]

.pull-right[

**.bg-green_light[CONSEJO]**: intenta no abusar de la consola, ya que todo lo que no escribas en un script, cuando cierres `RStudio`, lo **habr√°s perdido** (c√≥mo si en lugar de escribir en un Word y guardarlo, nunca guardases el documento).

]

---

# ¬øD√≥nde programamos? .orange[SCRIPTS]

Ahora tenemos una **cuarta ventana**: la ventana donde **escribiremos nuestros c√≥digos**


### **¬øC√≥mo ejecutar nuestro script?**

.pull-left[

```{r echo = FALSE,  out.width = "95%", fig.align = "left"}
knitr::include_graphics("./img/inicio_rstudio_6.jpg")
``` 

]

.pull-right[

1. **.bg-purple_light[Escribimos el c√≥digo]** a ejecutar.

2. **.bg-purple_light[Guardamos]** el archivo `.R` haciendo click en `Save current document`.

3. El c√≥digo **no se ejecuta salvo que se lo indiquemos**. Tenemos tres opciones:
  - **.orange[Copiar y pegar]** en consola.
  - **.orange[Seleccionar l√≠neas]** y clickar en `Run`.
  - Activar `Source on save` a la **derecha de guardar**: no solo guarda sino que ejecuta el c√≥digo completo.

]

---

name: ejercicios1

# Primeros ejercicios

.panelset[
.panel[.panel-name[Ejercicios]


* üìù **Ejercicio 1**: a√±ade debajo otra l√≠nea para definir una variable `b` con el valor `5`. Tras asignarles valores, multiplica los n√∫meros en consola.

```{r}
a <- 2
```

* üìù **Ejercicio 2**: modifica el c√≥digo inferior para definir dos variables `c` y `d`, con valores 3 y -1.

```{r eval = FALSE}
c <- # deber√≠as asignarle el valor 3
d <- # deber√≠as asignarle el valor -1
```

* üìù **Ejercicio 3**: con las variables `a` y `b` del ej. 1, crea una nueva variable `e` guardando el resultado de su multiplicaci√≥n `a * b`. Escribe `e` en consola para ver su resultado

]

.panel[.panel-name[Soluci√≥n ej. 1]

```{r}
# Para poner comentarios en el c√≥digo se usa #

# Definici√≥n de variables
a <- 2
b <- 5

# Multiplicaci√≥n
a * b
```
]

.panel[.panel-name[Soluci√≥n ej. 2]

```{r}
# Definici√≥n de variables
c <- 3
d <- -1
```
]

.panel[.panel-name[Soluci√≥n ej. 3]

```{r}
# Variables
a <- 2
b <- 5

# Resultado
e <- a * b

# Muestro en consola
e
```

]
]

---

# Primeros ejercicios


.panelset[
.panel[.panel-name[Ejercicios extra]


* üìù **Ejercicio 4**: asigna un valor positivo a `x` y calcula su ra√≠z cuadrada; asigna otro negativo y calcula su valor absoluto con la funci√≥n `abs()`.


* üìù **Ejercicio 5**: usando la variable `x` ya definida, completa/modifica el c√≥digo inferior para guardar en una nueva variable `z` el resultado guardado en `x` menos 5.

```{r eval = FALSE}
z <- ? - ? # completa el c√≥digo
z
```

* üìù **Ejercicio 6**: usando las variables `x` e `y` ya definidas, calcula el m√°ximo de ambas (funci√≥n `max()`), y gu√°rdalo en una nueva variable `t`.

]

.panel[.panel-name[Soluci√≥n ej. 4]

```{r}
# Ra√≠z cuadrada
x <- 73 # por ejemplo
sqrt(x)

# Valor absoluto
y <- -19 # por ejemplo
abs(y)
```
]

.panel[.panel-name[Soluci√≥n ej. 5]

```{r}
z <- x - 5
z
```
]

.panel[.panel-name[Soluci√≥n ej. 6]

```{r}
t <- max(x, y)
t
```

]
]


---


name: variables

# De la .orange[celda] a la .green[tabla]
 

¬øDe qu√© tipo pueden ser los datos que tenemos contenidos en cada celda de una ¬´tabla¬ª?


```{r echo = FALSE,  out.width = "55%", fig.align = "center"}
knitr::include_graphics("./img/celdas.jpg")
``` 

* **.bg-purple_light[Celda]**: un dato **.bg-orange[individual]** de un tipo concreto.
* **.bg-purple_light[Variable]**: una **.bg-orange[concatenaci√≥n de valores]** del mismo tipo (**vectores**).
* **.bg-purple_light[Matriz]**: **.bg-orange[concatenaci√≥n de variables]** del **.bg-yellow[mismo tipo]** y longitud.
* **.bg-purple_light[Tabla]**: **.bg-orange[concatenaci√≥n de variables]** de **.bg-yellow[distinto tipo]** pero igual longitud.

---

# .orange[Celdas]: tipos de datos individuales

¬øExisten **variables m√°s all√° de los n√∫meros**?

&nbsp;

Piensa por ejemplo en los **datos guardados de una persona**:

* La edad o el peso ser√° un **.bg-purple_light[n√∫mero]**.
* Su nombre ser√° una cadena de **.bg-purple_light[texto]**.
* Su fecha de nacimiento ser√° precisamente eso, una **.bg-purple_light[fecha]**.
* A la pregunta ¬´¬øest√° usted soltero/a?¬ª la respuesta ser√° lo que llamamos una **.bg-purple_light[variable l√≥gica]** (`TRUE` si est√° soltero/a o `FALSE` en otro caso).

```{r echo = FALSE,  out.width = "40%", fig.align = "center"}
knitr::include_graphics("./img/celdas.jpg")
``` 

---

# Variables .orange[NUM√âRICAS]

El **dato m√°s sencillo**, dato que ya hemos usado en nuestros primeros pasos como calculadora, ser√°n las variables que guardan simplemente n√∫meros

```{r}
a <- 1
b <- 2
a + b
```

--

En el c√≥digo anterior, tanto `a` como `b` como la suma `a + b` son de **.bg-purple_light[tipo num√©rico]**

```{r}
class(a) #<<
typeof(a) #<<
```


---

# Variables .orange[NUM√âRICAS]

Como ya hemos visto, con los datos num√©ricos podemos realizar todas las **.bg-purple_light[operaciones aritm√©ticas]** que se nos ocurrir√≠a hacer en una **calculadora** como sumar (`+`), restar (`-`), multiplicar (`+`), dividir (`/`), ra√≠z cuadrada (`sqrt()`), valor absoluto (`abs()`), elevar al cuadrado (`^2`), elevar al cubo (`^3`), etc.



```{r}
a <- 5
a^3 # Elevar al cubo
```

```{r}
b <- -43
abs(b) # valor absoluto
```

---

# Variables de .orange[TEXTO]

No solo de n√∫meros viven los datos: imagina que adem√°s de la edad de una persona queremos **guardar su nombre** (**.bg-purple_light[tipo caracter]**: una **cadena de texto**)

```{r}
nombre <- "Javier" #<<
class(nombre)
```

--

Las cadenas de texto son un **tipo especial de dato** con los que obviamente no podremos hacer operaciones aritm√©ticas (pero s√≠ **.bg-purple_light[otras operaciones]** como pegar o localizar patrones).

```{r error = TRUE}
nombre + 1 # error al sumar n√∫mero a texto
```

&nbsp;

--

**.bg-green_light[IMPORTANTE]**: las variables de tipo texto van **.bg-red_light[SIEMPRE ENTRE comillas]**.


---

name: primer-paquete

# .orange[PRIMERA FUNCI√ìN]: paste

Una **.bg-purple_light[funci√≥n]** es un **trozo de c√≥digo encapsulado** bajo un nombre, que depende de unos **.bg-purple_light[argumentos de entrada]**.

--

Nuestra primera funci√≥n ser√° `paste()`: dadas dos cadenas de texto como argumento de entrada nos permite pegarlas, indic√°ndole en el argumento `sep = ` el caracter que queremos entre medias.

```{r}
# todo junto, sin espacios, igual a paste0("Javier", "√Ålvarez")
paste("Javier", "√Ålvarez", sep = "") 
```



```{r}
paste("Javier", "√Ålvarez", sep = "?*?") # separados por un ?*?
```


---

# .orange[PRIMERA FUNCI√ìN]: paste


```{r}
paste("Javier", "√Ålvarez") #<<
```

Por defecto, `paste()` a√±ade un espacio, es decir, `sep = " "`. Muchas funciones en `R` tendr√°n lo que llamamos **.bg-purple_light[argumentos por defecto]**, el valor que tomar√° sino se le asigna otro. Puedes mirar la **.bg-green_light[ayuda de la funci√≥n]** escribiendo en consola `? paste`

Existe una funci√≥n similar llamada `paste0()` que pega por defecto con `sep = ""` (sin nada).

```{r}
paste0("Javier", "√Ålvarez") 
paste("Javier", "√Ålvarez", sep = "") 
```

---

# .orange[PRIMER PAQUETE]: glue

Otra forma **m√°s intuitiva de trabajar con textos** es usar el **paquete** `{glue}`.

```{r}
library(glue) # solo la 1¬™ vez install.packages("glue")
```

--

Con dicho paquete podemos **.bg-purple_light[usar variables dentro de cadenas]** de texto. Por ejemplo, la frase ¬´la edad es de ... a√±os¬ª, donde la edad concreta la tenemos guardada en una variable.

```{r}
edad <- 33
glue("La edad es de {edad} a√±os") #<<
```

Dentro de las llaves tambi√©n podemos ejecutar operaciones

```{r}
unidades <- "d√≠as"
glue("La edad es de {edad * 365} {unidades}") #<<
```

---


# .orange[VECTORES]: concatenaci√≥n

¬øY si en lugar de querer almacenar un solo elemento, por ejemplo , tenemos una **colecci√≥n de elementos**?

Hasta ahora solo hemos operado con el contenido de las **celdas**, pero cuando trabajamos con datos normalmente tendremos columnas que representan variables o caracter√≠sticas: llamaremos **.bg-purple_light[vectores]** a una **.bg-orange[concatenaci√≥n]** de variables del **.bg-orange[mismo tipo]**
 
--

La forma m√°s sencilla es con el comando `c()` (c de concatenar), y basta con introducir sus **elementos entre par√©ntesis y separados por comas** (por ejemplo, la edad de 4 personas).

```{r}
edades <- c(33, 27, 60, 61) #<<
edades
```


&nbsp;

--

**.bg-green_light[IMPORTANTE]**: un n√∫mero individual (`x <- 1`) es en realidad un vector de longitud uno. 

---

# .orange[VECTORES]: concatenaci√≥n


Como ves ahora en el `environment` tenemos una **.bg-purple_light[colecci√≥n de elementos]** guardada

.pull-left[

```{r}
edades
```

]


.pull-right[
```{r echo = FALSE,  out.width = "80%", fig.align = "left"}
knitr::include_graphics("./img/vectores_enviroment.jpg")
``` 
]

--

.pull-left[

La **.bg-purple_light[longitud de un vector]** se puede calcular con `length()`

```{r}
length(edades) #<<
```

]


.pull-right[

Tambi√©n podemos **.bg-purple_light[concatenar vectores]**

```{r}
c(edades, edades, 8)
```

]

---

# Vectores: .orange[SECUENCIAS NUM√âRICAS]

En muchas ocasiones querremos **.bg-purple_light[crear secuencias num√©ricas]** mucho m√°s r√°pido (por ejemplo, un vector con los d√≠as del mes). El comando `seq()` nos permite crear una **secuencia** desde un elemento inicial hasta un elemento final, avanzando de uno en uno.

```{r}
seq(1, 31)
```

--

El comando `1:n` nos devuelve lo mismo que la orden `seq(1, n)`. Adem√°s, si el elemento inicial es mayor que el final, `R` entender√° solo que la secuencia es **decreciente**.

```{r}
n <- 5
n:1
```

---

# Vectores: .orange[SECUENCIAS NUM√âRICAS]

Tambi√©n podemos definir **.bg-purple_light[otro tipo de distancia]** (**.bg-orange[paso de discretizaci√≥n]**) entre dos elementos consecutivos

```{r}
seq(1, 7, by = 0.5) # secuencia desde 1 a 7 de 0.5 en 0.5
```

--

Otras veces nos interesar√° definir una **.bg-purple_light[secuencia con un n√∫mero concreto]** de elementos.

```{r}
seq(1, 50, l = 7) # secuencia desde 1 a 50 de longitud 7
```

--

Tambi√©n podemos crear **.bg-purple_light[vectores de elementos repetidos]** con la funci√≥n `rep()`

```{r}
rep(0, 7) # vector de 7 ceros
```


---

# .green[OPERACIONES] .orange[ARITM√âTICAS]
 
Dado que un **.bg-purple_light[n√∫mero es un vector]** de longitud 1, toda **.bg-orange[operaci√≥n aritm√©tica]** (suma, resta, multiplicaci√≥n, etc) que podamos hacer con un n√∫mero la vamos a poder a hacer con un vector de n√∫meros.

--

Si hacemos por ejemplo la operaci√≥n `2 * x`, siendo `x` un vector, lo que suceder√° es que la operaci√≥n se realizar√° en **.bg-purple_light[CADA ELEMENTO]** del vector (una sola l√≠nea de c√≥digo paro realizar operaciones en 10, 20, 1000 o 100000 elementos).

```{r}
# Multiplicamos por 2 a CADA ELEMENTO del vector
x <- c(2, 4, 6)
2 * x #<<
```

--

&nbsp;

**.bg-green_light[IMPORTANTE]**: el **.bg-purple_light[resultado]** de una operaci√≥n aritm√©tica sobre un vector ser√° **.bg-orange[otro vector]**.

---

# .green[OPERACIONES] .orange[ARITM√âTICAS]
 
 
De la misma manera podemos **.bg-purple_light[sumar o restar una constante]** al vector

```{r}
# Sumamos 3 a CADA ELEMENTO DEL VECTOR
x + 3
```

--

Los vectores tambi√©n pueden **.bg-purple_light[interactuar entre ellos]**, as√≠ que podemos definir sumas de vectores, como `x + y`

```{r}
y <- c(1, 3, 5)

# suma de vectores 
x + y #<< 
```

--

**.bg-green_light[IMPORTANTE]**: salvo que especifiquemos lo contrario, toda operaci√≥n aritm√©tica que hagas a un vector ser√° **.bg-purple_light[elemento a elemento]**.

 
---


# .green[OPERACIONES] con .orange[AUSENTES]

Imagina que tenemos un vector de temperaturas pero varios de los d√≠as el aparato de medici√≥n no funcionaba, por lo que tenemos un **.bg-purple_light[dato ausente]** marcado como `NA`.

```{r}
x <- c(21, NA, 13, NA, NA, 25, 36, 17, 19, 5)
sum(x)
```

--

Dado que hay d√≠as que no tenemos disponibles, la suma tampoco la podemos conocer.  Para evitar que nos impida hacer ciertas operaciones, en muchas funciones de `R` podemos a√±adir el **argumento** `na.rm = TRUE`: primero elimina ausentes, y luego ejecuta la funci√≥n.

```{r}
# eliminando datos ausentes antes de aplicar la funci√≥n
sum(x, na.rm = TRUE) #<<
mean(x, na.rm = TRUE)
```


---

# .green[OPERACIONES] con .orange[AUSENTES]

Para **comprobar** si tenemos un **dato ausente**  podemos hacer uso de la funci√≥n `is.na()`

```{r}
is.na(x)
```

--

Tambi√©n puede aparecernos un **.bg-purple_light[resultado no permitido]**, marcado como `NaN` (not a number): no es un dato ausente, es un dato resultado de una **operaci√≥n no permitida**.

```{r}
x <- c(1, NA, 3, 4, 6, 7, sqrt(-1), NA)
x
is.nan(x)
```


---

# .orange[SELECCIONAR] elementos

Otra operaci√≥n muy habitual es la **.bg-purple_light[extraer un subconjunto del mismo]**. La forma m√°s sencilla es **usar el operador de selecci√≥n** `[i]` para **acceder al elemento i-√©simo**

```{r}
edades <- c(20, 30, 33, NA, 61)

# accedemos a la edad de la tercera persona en la lista
edades[3] #<<

# accedemos a la edad de la cuarta persona
edades[4]
```

---

# .orange[SELECCIONAR] elementos

Un n√∫mero no es m√°s que un vector de longitud uno, as√≠ que esta operaci√≥n tambi√©n la podemos aplicar usando un **.bg-purple_light[vector de √≠ndices a seleccionar]**

```{r}
# Tercer y cuarto elemento
edades[c(3, 4)] #<<
```

--

Esta l√≥gica para acceder a elementos tambi√©n sirve para **vectores de caracteres**.

```{r}
y <- c("hola", "qu√©", "tal", "todo", "ok", "?")
y[1:2]
```

--

**.bg-green_light[TIP]**: para **.bg-purple_light[acceder al √∫ltimo elemento]** podemos pasarle como √≠ndice la longitud del vector 

```{r}
y[length(y)] 
```

---

# .green[OPERACIONES] .orange[ARITM√âTICAS]
 

Dado que la operaci√≥n (por ejemplo, una suma) se realiza elemento a elemento, ¬øqu√© suceder√° si **.bg-purple_light[sumamos dos vectores de distinta longitud]**?

--

Por ejemplo, definamos `z` con los 4 primeros impares, e intentemos hacer la suma `x + z`.

```{r}
z <- c(1, 3, 5, 7)
x + z
```

--

.pull-left[


```{r echo = FALSE,  out.width = "99%", fig.align = "left"}
knitr::include_graphics("./img/recycle.jpg")
``` 


]

.pull-right[

`R` intenta molestarte lo menos posible, as√≠ que lo que hace es **.bg-purple_light[reciclar elementos]**: si tiene un vector de 4 elementos y le intentas sumar uno de 3 elementos, lo que har√° ser√° reciclar elementos del vector con menor longitud: har√° `1 + 2`, `3 + 4`, `5 + 6` pero‚Ä¶ `7 + 2` (vuelve al primero).

]

---

# Vectores: .orange[CARACTERES]

Un vector es una **.bg-purple_light[concatenaci√≥n de elementos del mismo tipo]**, pero no tienen porque ser necesariamente n√∫meros. Vamos a crear una frase de ejemplo, con 4 elementos.

.pull-left[

```{r}
vector <- c("Me", "llamo", "Javi") #<<
vector
length(vector)
```

]

.pull-right[

```{r}
frase <- "Mi llamo Javi"
frase
length(frase)
```

]

F√≠jate la **diferencia** entre tenerlo guardado en un vector o tenerlo como una sola cadena de texto (unida).

---

# Vectores: .orange[CARACTERES]

Cuando usamos la funci√≥n `paste()` con variables diferentes, us√°bamos `sep = ...`. Cuando la funci√≥n `paste()` la aplicamos a un vector de caracteres, decidiremos que caracter queremos que vaya entre palabra con el argumento `collapse = ...`.

```{r}
paste(vector, collapse = ".") # separados por un punto
```

Podemos **combinar las secuencias de n√∫meros y un vector de caracteres** con `glue()`

```{r}
edad <- 10:12 # edades
glue("La edad es de {edad} a√±os")
```


---

name: logicas

# Datos de tipo .orange[L√ìGICO]

Un tipo de datos muy importante en todo lenguaje de programaci√≥n: los **.bg-purple_light[valores l√≥gicos]**. Un valor l√≥gico puede tomar **tres valores**:

* `TRUE` (guardado internamente como un `1`).
* `FALSE` (guardado internamente como un `0`).
* `NA` (**.bg-purple_light[dato ausente]**, son las siglas de **.bg-orange[not available]**).

--

Los valores l√≥gicos suelen ser resultado de evaluar **.bg-purple_light[condiciones l√≥gicas]** (preguntar a los datos). Por ejemplo, imaginemos que definimos un vector de temperaturas. ¬øQu√© d√≠as hizo menos de 22 grados?

```{r}
x <- c(15, 20, 31, 27, 15, 29)
x < 22 #<<
```

Nos devolver√° un **vector l√≥gico** con `TRUE` o `FALSE` en cada hueco, en funci√≥n de si cumple o no la condici√≥n pedida.

---

# Datos de tipo .orange[L√ìGICO]


Dicha condici√≥n l√≥gica puede hacerse con `<=` (menor o igual), `>` (mayor) o `>=` (mayor igual).

```{r}
x <= 22
```

--

```{r}
x > 30
```

--

```{r}
x >= 15
```

---

# Datos de tipo .orange[L√ìGICO]

Tambi√©n podemos comparar **.bg-purple_light[si es igual a otro elemento]**, para lo que usaremos el operador `==`, pudiendo usar tambi√©n su opuesto `!=` (¬´distinto de¬ª).

```{r}
x == 15
x != 15
```

--

Si tuvi√©ramos un **.bg-purple_light[dato ausente]** (por error del aparato ese d√≠a, marcado como `NA`), la condici√≥n evaluada tambi√©n ser√≠a `NA`

```{r}
y <- c(15, 20, NA, 31, 27, 7, 29, 10)
y < 22
```

---

# Datos de tipo .orange[L√ìGICO]

Las **.bg-purple_light[condiciones pueden ser combinadas]**, principalmente de dos maneras:

.pull-left[

* **.bg-purple_light[Intersecci√≥n]**: **.bg-orange[TODAS]** las condiciones concatenadas se deben cumplir (conjunci√≥n y) para devolver un `TRUE`.

```{r}
x
x < 30 & x > 15
```

]

.pull-right[

* **.bg-purple_light[Uni√≥n]**: basta con que **.bg-orange[AL MENOS UNA]** de las condiciones se cumpla (conjunci√≥n o) para devolver un `TRUE`.

```{r}
x
x < 30 | x > 15
```

]

---

name: fecha

# Datos de tipo .orange[FECHA]


Un tipo de datos muy especial: los **.bg-purple_light[datos de tipo fecha]**. 

```{r}
# Cadena de texto
fecha_char <- "2021-04-21"
class(fecha_char)
```

Podr√≠amos pensar que no tiene nada de especial ya que parece una simple cadena de texto pero representa un **.bg-purple_light[instante en el tiempo]**, que deber√≠amos poder operar como tal.

--

¬øQu√© suceder√≠a si **sumamos un 1 (un d√≠a)** a una fecha definida como una cadena de texto?

```{r error = TRUE}
fecha_char + 1
```

--

Si guardamos las fechas como un cadena de texto **.bg-red_light[no podemos operar con ellas]**

---

# Datos de tipo .orange[FECHA]

Para trabajar con fechas tenemos el paquete `{lubridate}`, y su funci√≥n `as_date()`: nos **.bg-purple_light[convierte texto a fecha]**.

```{r}
library(lubridate)
fecha <- as_date(fecha_char) #<<
class(fecha)
```

--

```{r}
fecha + 1 # d√≠a siguiente
```

--

```{r}
fecha - 3 # 3 d√≠as antes
```

--

Al convertir texto a fecha, aunque se visualice como un texto, **.bg-purple_light[internamente es un n√∫mero]**. 

---

# Datos de tipo .orange[FECHA]

La funci√≥n `as_date()` tiene un argumento opcional, el **.bg-purple_light[formato]**, que por defecto ser√° `format = "yyyy-mm-dd"` (que podemos cambiar)


```{r}
as_date("10-03-2020", format = "%d-%m-%Y") #<<
```

--

```{r}
as_date("10-03-20", format = "%d-%m-%y")
```

--

```{r}
as_date("03-10-2020", format = "%m-%d-%Y")
```

--

```{r}
as_date("Octubre 21, 1995 21:24", format = "%B %d, %Y %H:%M")
```

---

# Datos de tipo .orange[FECHA]

Para facilitar conversiones de formatos habituales, el paquete tambi√©n tiene a nuestra disposici√≥n diferentes funciones preparadas para directamente **.bg-purple_light[convertir fechas en distintos formatos]**, como la funci√≥n `ymd_hms()` o `ydm_hms()`

```{r}
ymd_hms("2017-11-28 14:02:00") # convertir a fecha una cadena a√±o-mes-d√≠a + hora
ydm_hms("2017-22-12 10:00:00") # convertir a fecha una cadena a√±o-d√≠a-mes + hora
```

--

De la misma manera tenemos la funci√≥n `dmy_hms()`

```{r}
dmy_hms("1 Jan 2017 23:59:59") # convertir a fecha una cadena textual de fecha + hora
```

 
---

# Datos de tipo .orange[FECHA]


Tambi√©n podemos hacerlo de forma muy simplificada con `ymd()`

```{r}
ymd(20170131)
```

--

Otra de las funcionalidades que nos proporciona dicho paquete es obtener autom√°ticamente la **.bg-purple_light[fecha de hoy]**, haciendo uso de la funci√≥n `today()`

```{r}
hoy <- today() #<<
hoy
```

--

Tambi√©n podemos obtener el **.bg-purple_light[¬´hoy y ahora¬ª]** con la funci√≥n `now()`

```{r}
now() #<<
```
 
---

# Datos de tipo .orange[FECHA]

Tambi√©n tenemos disponibles funciones para **.bg-purple_light[extraer facilmente algunas variables]**.

.pull-left[

```{r}
year(fecha)
month(fecha)
hour(fecha)
second(fecha)
```

]

.pull-right[
```{r}
week(fecha)
wday(fecha)
wday(fecha, week_start = 1) # D√≠a de la semana 
```

]


---

# Datos de tipo .orange[FECHA]


Tambi√©n podemos **.bg-purple_light[realizar comparaciones]**

```{r}
fecha_actual <- today()
fecha_actual > ymd(20170131) # Actual vs 2017-01-31
fecha_actual > ymd(21000131) # Actual vs 2100-01-31
```
 
--

Con la funci√≥n `leap_year()` podremos saber si la fecha **.bg-purple_light[corresponde a un a√±o bisiesto]**

```{r}
leap_year(as_date(ymd(20190131)))
```

---

# Datos de tipo .orange[FECHA]

.pull-left[

```{r echo = FALSE,  out.width = "101%", fig.align = "right", fig.cap = "Chuleta de https://lubridate.tidyverse.org/"}
knitr::include_graphics("./img/lubridate.png")
``` 

]

.pull-right[

Tambi√©n podemos hacer uso de diferentes funciones para **.bg-purple_light[a√±adir intervalos]** de tiempo.

```{r}
fecha + weeks(0:2)
fecha + seconds(2)
```

]

---


name: ejercicios2

# Ejercicios


.panelset[
.panel[.panel-name[Ejercicios]


* üìù **Ejercicio 1**: define una variable `edad` que guarde tu edad y otra `nombre` con tu nombre.

* üìù **Ejercicio 2**: define otra variable con tus apellidos y junta las variables `nombre` y `apellidos` en una sola cadena de texto que guardes en `nombre_completo`.
 
* üìù **Ejercicio 3**: define un vector que contenga los n√∫meros `1`, `10`, `-1` y `2`, y gu√°rdalo en una variable llamada `vector_num`. Obt√©n la longitud del vector anterior.
 
* üìù **Ejercicio 4**: crea una secuencia de -2 a 17 de forma que salte de uno en uno (y tambi√©n de forma decreciente). Repite el proceso pero saltando de 3 en 3.


]

.panel[.panel-name[Soluci√≥n ej. 1]

```{r}
# variable num√©rica
edad <- 33
edad

# variable de tipo texto
nombre <- "Javi"
nombre
```
]

.panel[.panel-name[Soluci√≥n ej. 2]

```{r}
apellidos <- "√Ålvarez Li√©bana"

# Opci√≥n 1
nombre_completo <- glue("{nombre} {apellidos}")
nombre_completo

# Opci√≥n 2
nombre_completo <- paste(nombre, apellidos)
nombre_completo
```
]

.panel[.panel-name[Soluci√≥n ej. 3]

```{r}
vector_num <- c(1, 10, -1, 2)
vector_num

# longitud
length(vector_num)
```

]

.panel[.panel-name[Soluci√≥n ej. 4]

```{r}
secuencia <- -2:17
secuencia
# otra forma
secuencia <- seq(-2, 17, by = 1)

# decreciente
17:-2

# de 3 en 3
seq(-2, 17, by = 3)
```

]

]

---

# Ejercicios


.panelset[
.panel[.panel-name[Ejercicios]


* üìù **Ejercicio 5**: crea una secuencia que repita 7 veces el patr√≥n -1, 2, 4. Despu√©s crea otra que repita dicho patr√≥n pero de forma intercalada.
 
* üìù **Ejercicio 6**: crea una secuencia de 7 valores l√≥gicos en los que haya 2 valores ciertos, 3 valores falsos y 2 valores ausentes.


* üìù **Ejercicio 7**: toma el vector `vector_num` del ejercicio 3 y obt√©n un vector l√≥gico que nos diga que valores son mayores de 0. Obt√©n otro vector l√≥gico que nos diga que valores est√°n entre 0 y 7. Obt√©n otro vector l√≥gico que nos diga que valores son distintos de 1 en valor absoluto.

* üìù **Ejercicio 8**: obt√©n la fecha de hoy, define la fecha de tu cumplea√±os, y calcula la diferencia de d√≠as.
 
* üìù **Ejercicio 9**: suma un mes y una semana a la fecha de tu cumplea√±os

 

]

.panel[.panel-name[Sol ej. 5]

```{r}
secuencia <- rep(c(-1, 2, 4), 7)
secuencia

# intercalada
rep(c(-1, 2, 4), each = 7)
```

]

.panel[.panel-name[Sol ej. 6]

```{r}
secuencia <- c(FALSE, TRUE, NA, FALSE, NA, TRUE, FALSE)
secuencia
```

]

.panel[.panel-name[Sol ej. 7]

```{r}
vector_num > 0
vector_num > 0 & vector_num < 7
abs(vector_num) != 1
```

]


.panel[.panel-name[Sol ej. 8]

```{r}
library(lubridate)
hoy <- today()
cumple <- as_date("1989-09-10")
hoy - cumple
```

]

.panel[.panel-name[Sol ej. 9]

```{r}
cumple + months(1) + weeks(1)
```

]

]

---

# Ejercicios extras

.panelset[
.panel[.panel-name[Ejercicios extra]


* üìù **Ejercicio 10**: construye con `glue()` una frase que diga ¬´Hola, me llamo ‚Ä¶ y tengo ‚Ä¶ a√±os¬ª.

* üìù **Ejercicio 11**: modifica el c√≥digo inferior para crear un vector de nombre `vector_num` que contenga los n√∫meros 1, 5 y -7.

```{r eval = FALSE}
# Vector de n√∫meros
vector_num <- c(1)
vector_num
```

* üìù **Ejercicio 12**:  extrae el mes, a√±o y d√≠a de la semana de tu cumplea√±os

]

.panel[.panel-name[Soluci√≥n ej. 10]

```{r}
nombre <- "Javi"
edad <- 33
glue("Hola, me llamo {nombre} y tengo {edad} a√±os")
```
]

.panel[.panel-name[Soluci√≥n ej. 11]

```{r}
# Vector de n√∫meros
vector_num <- c(1, 5, -7)
vector_num

# longitud
length(vector_num)
```

]

.panel[.panel-name[Soluci√≥n ej. 12]

```{r}
library(lubridate)
cumple <- as_date("1989-09-10")
month(cumple)
day(cumple)
year(cumple)
wday(cumple, week_start = 1, label = TRUE)
```

]


]


---

class: inverse center middle
name: clase-2

# CLASE 2: primeros datos. Primeros conceptos.

&nbsp;

### [Operaciones con vectores](#operaciones-vectores)

### [Matrices](#matrices)

### [data.frame y tibble](#data.frame)

### [Ejercicios datasets](#ejercicios-tibble)

### [Intro estad√≠stica](#intro-estadistica)



---

name: operaciones-vectores


# .green[OPERACIONES] .orange[ARITM√âTICAS]


Los **.bg-purple_light[valores l√≥gicos]** `TRUE` y `FALSE` son **.bg-orange[guardados internamente]** como `0` y `1`, por lo que podemos usar operaciones aritm√©ticas con ellos.

--

Por ejemplo, si queremos **.bg-purple_light[averiguar el n√∫mero de elementos que cumplen una condici√≥n]** (por ejemplo, `< 3`), los que lo hagan tendr√°n asignado un 1 y los que no un 0, por lo que basta con sumar dicho vector l√≥gico para obtener el n√∫mero de elementos que cumplen dicha condici√≥n (elementos que son `TRUE`).

```{r}
# sumamos el vector de TRUE/FALSE
x
sum(x < 3) 
```

---

# .green[OPERACIONES] .orange[ESTAD√çSTICAS]

Tambi√©n podemos realizar **.bg-purple_light[operaciones estad√≠sticas]** con los vectores, como calcular su **suma**, su **media**, su **mediana**, entre otros.

--

Hagamos antes un **.bg-purple_light[breve repaso]** de algunos t√©rminos estad√≠sticos:

* **.bg-purple_light[Media]**: medida de **.bg-orange[centralizaci√≥n]** que consiste en sumar todos los elementos y dividirlos entre la cantidad de elementos sumados (funci√≥n `mean()`). La m√°s conocida pero la menos robusta: dado un conjunto, si se introducen valores at√≠picos o outliers (valores muy grandes o muy peque√±os), la media se perturba con mucha facilidad.

$$\overline{x} = \frac{1}{n} \sum_{i=1}^{n} x_i$$

```{r}
x <- c(165, 170, 181, 191, 150, 155, 167, 173, 177)
mean(x)
```

---

# .green[OPERACIONES] .orange[ESTAD√çSTICAS]

Tambi√©n podemos realizar **.bg-purple_light[operaciones estad√≠sticas]** con los vectores, como calcular su **suma**, su **media**, su **mediana**, entre otros.


Hagamos antes un **.bg-purple_light[breve repaso]** de algunos t√©rminos estad√≠sticos:

* **.bg-purple_light[Mediana]**: medida de **.bg-orange[centralizaci√≥n]** (funci√≥n `median()`) que consiste en, tras **.bg-orange[ordenar]** los datos de menor a mayor, quedarnos con el valor que ocupa el medio (deja tantos n√∫meros por debajo como por encima). 


$$Me_{x} = \displaystyle \arg \min_{x_i} \left\lbrace F_i > 0.5 \right\rbrace, \quad F_i = \frac{\# \left\lbrace x_j \leq x_i \right\rbrace}{n}$$

```{r}
x <- c(165, 170, 181, 191, 150, 155, 167, 173, 177)
median(x)
```

---

# .green[OPERACIONES] .orange[ESTAD√çSTICAS]

Tambi√©n podemos realizar **.bg-purple_light[operaciones estad√≠sticas]** con los vectores, como calcular su **suma**, su **media**, su **mediana**, entre otros.


Hagamos antes un **.bg-purple_light[breve repaso]** de algunos t√©rminos estad√≠sticos:

* **.bg-purple_light[Moda]**: medida de **.bg-orange[centralizaci√≥n]** que consiste en encontrar el **.bg-orange[valor o valores m√°s repetidos]**. Es la medida de centralizaci√≥n m√°s robusta. 

$$Mo_{x} = \displaystyle \arg \max_{x_i}  f_i , \quad f_i = \frac{\# \left\lbrace x_j = x_i \right\rbrace}{n}$$

&nbsp;

**.bg-red_light[PROBLEMA]**: la moda no siempre es f√°cil de calcular (aunque existen paquetes para calcularla como `{modeest}`)


---

# .green[OPERACIONES] .orange[ESTAD√çSTICAS]

Otra de las funciones m√°s √∫til es la **.bg-purple_light[suma de elementos]** de un vector con `sum()`

```{r}
# suma
sum(x) #<<
sum(x) / length(x) # media artesanal
```

--

Otra funci√≥n √∫til es la **.bg-purple_light[suma acumulada]** de un vector haciendo uso de `cumsum()`

```{r}
# suma acumulada
cumsum(c(1, 2, 4, 7, 7, 10)) #<<
```

---

# .green[OPERACIONES] .orange[ESTAD√çSTICAS]

No solo de medidas de centralizaci√≥n vive la estad√≠stica: **.bg-purple_light[¬øc√≥mo calcular las medidas de dispersi√≥n?]**

* **.bg-purple_light[Varianza]**: definida como la media de desviaciones (respecto a la media) al cuadrado, tal que $s_{x}^{2} = \frac{1}{n} \sum_{i = 1}^{n} \left(x_i - \overline{x} \right)^2 = \overline{x^2} - \overline{x}^2$

```{r}
var(x)
```

--

**.bg-green_light[IMPORTANTE]**: las funciones de `R` (y de cualquier calculadora) nos devuelve la **.bg-red_light[cuasivarianza]** (dividido entre $n-1$)
 
```{r}
# Varianza real
mean((x - mean(x))^2)
```

---


# .green[OPERACIONES] .orange[ESTAD√çSTICAS]

No solo de medidas de centralizaci√≥n vive la estad√≠stica: **.bg-purple_light[¬øc√≥mo calcular las medidas de dispersi√≥n?]**

* **.bg-purple_light[Desv. t√≠pica (standard deviation)]**: definida como la ra√≠z cuadrada de la varianza, tal que $s_{x} = \sqrt{s_{x}^{2} }$

```{r}
sd(x)
```

--

**.bg-green_light[IMPORTANTE]**: las funciones de `R` (y de cualquier calculadora) nos devuelve la **.bg-red_light[cuasidesviaci√≥n t√≠pica]** (ra√≠z de la cuasivarianza, dividida entre $n-1$)
 
```{r}
# Desv. t√≠pica real
sqrt(mean((x - mean(x))^2))
```


---

# .green[OPERACIONES] .orange[ESTAD√çSTICAS]

Tambi√©n pueden sernos √∫tiles las **.bg-purple_light[medidas de posici√≥n/localizaci√≥n]**, como los **.bg-orange[percentiles]** (valores que nos dividen en partes iguales los datos).

```{r}
y <- c(1, 2, 5, 5, 10, 10, 10, 13, 15, 20, 25)

# Percentiles por defecto: cuartiles
quantile(y) #<<
```

--

En `quantile()` hay un argumento por defecto `probs = c(0, 0.25, 0.5, 0.75, 1)` (**percentiles** a calcular) que puede ser cambiado, por ejemplo, para percentiles 20%-30%-70%-90%.

```{r}
quantile(y, probs = c(0.2, 0.3, 0.7, 0.9))
```

---


# Valores .orange[√öNICOS]

Con la funci√≥n `unique()` podemos tambi√©n extraer los **.bg-purple_light[valores √∫nicos de una variable]**

```{r}
colores <- c("azul", "azul", "verde", "amarillo",
             "azul", "rojo", "rojo", "azul", "rojo",
             "verde", "morado")
unique(colores) #<<
```

---



# .orange[FILTRAR] elementos


Otras veces no querremos seleccionar un elemento en concreto sino **.bg-purple_light[filtrar algunos elementos en concreto]** y no extraerlos, **.bg-orange[eliminarlos]**.

Deberemos repetir la misma operaci√≥n pero con el signo `-` delante: el operador `[-i]` **no selecciona** el elemento i-√©simo del vector sino que lo **elimina**

```{r}
y
y[-2] 
```

---

# .orange[FILTRAR] elementos

Lo habitual es que dicho filtro lo hagamos **.bg-purple_light[en base a una condici√≥n l√≥gica]**. Supongamos que tenemos las edades de dos grupos de personas y que queremos quedarnos **solo con los mayores edad**: vamos a seleccionar los **elementos que cumplen una condici√≥n dada**.

```{r}
edades_1 <- c(7, 20, 18, 3, 19, 9, 13, 3, 45)
edades_2 <- c(17, 21, 58, 33, 15, 59, 13, 1, 45)
```

--

```{r}
edades_1[edades_1 >= 18] #<<
edades_2[edades_2 >= 18]
```

Lo que hemos hecho ha sido pasar como **√≠ndices a seleccionar un vector l√≥gico** `TRUE/FALSE`: solo filtrar√° los lugares donde se guarde un `TRUE`.

---

# .orange[FILTRAR] elementos

Esto tambi√©n nos puede servir para **.bg-purple_light[limpiar de datos ausentes]**, combinando la funci√≥n `is.na()`: nos localiza el lugar que ocupan los ausentes, con el operador `!` (**negar el valor l√≥gico** que venga detr√°s).

```{r}
x <- c(7, NA, 20, 3, 19, 21, 25, 80, NA)
x[is.na(x)] # solo valores ausentes
x[!is.na(x)] # sin valores ausentes: ! es el s√≠mbolo de 
```

--

Tambi√©n podemos probar a **combinar condiciones l√≥gicas** para nuestra selecci√≥n.

```{r}
x[x >= 18 & x <= 25] # los valores que cumplen ambas (&): entre 18 y 25 a√±os
```

---
 

# .green[SELECCIONAR] elementos: .orange[WHICH]

A veces no querremos el elemento en s√≠, sino el **.bg-purple_light[lugar que ocupa]**: ¬øqu√© valores de un vector cumplen una condici√≥n l√≥gica? Para obtener dicho √≠ndice usaremos la funci√≥n `which()`.

```{r}
x <- c(7, NA, 20, 3, 19, 21, 25, 80, NA)
which(x >= 18) # Obtenemos los lugares 
```

--

Esta funci√≥n es muy √∫til especialmente cuando queremos el valor que ocupa el **.bg-purple_light[m√°ximo/m√≠nimo]** de un vector, con las funciones `which.max()` y `which.min()`.

```{r}
max(x, na.rm = TRUE)
which.max(x) # Lugar que ocupa el m√°ximo
```


---

# .green[SELECCIONAR] elementos: .orange[any/all]
 

Existen dos funciones muy √∫tiles para saber si **.bg-purple_light[todos o alguno de los elementos]** de un vector cumple una condici√≥n: `all()` y `any()` nos devolver√° un √∫nico valor l√≥gico.

```{r}
x <- c(1, 2, 3, 4, 5, NA, 7)
all(x < 3) #<<
any(x < 3)
all(x > 0)
```


---

# .orange[NOMBRAR] elementos

`R` nos permite dar **.bg-purple_light[significado l√©xico a nuestros valores]** (significan algo, no solo n√∫meros), pudiendo poner **nombres a los elementos** de un vector.

```{r}
x <- c("edad" = 31, "tlf" = 613910687, "cp" = 33007)
x
```

--

Esto es una ventaja ya que nos permite su **.bg-purple_light[selecci√≥n usando dichos nombres]**

```{r}
x[c("edad", "cp")] # seleccionamos los elementos que tienen ese nombre asignado
```

--

Con la funci√≥n `names()` podemos, no solo **.bg-purple_light[consultar los nombres]** sino **cambiarlos**.

---

# .orange[ORDENAR] vectores


Una acci√≥n tambi√©n habitual al trabajar con datos es saber **.bg-purple_light[ordenarlos]**: de menor a mayor edad, datos m√°s recientes vs antiguos, etc. Para ello tenemos la funci√≥n `sort()`, que podemos usar directamente para ordenar de **menor a mayor**.

```{r}
edades <- c(81, 7, 25, 41, 65, 20, 33, 23, 77)

# orden de joven a mayor
sort(edades) #<<
```

--

Por defecto, `sort()` ordena de menor a mayor. Con el argumento opcional `decreasing = TRUE` podemos **ordenar de mayor a menor**.

```{r}
# orden de mayor a joven
sort(edades, decreasing = FALSE) #<<
```

---

# .orange[ORDENAR] vectores

Otra forma de ordenar es obtener los **√≠ndices de los elementos ordenados**, y luego usar dichos √≠ndices para **reorganizar los elementos**, con la funci√≥n `order()`.

```{r}
order(x) #<<
x[order(x)]
```

---


# .orange[MEDIR] tiempos de ejecuci√≥n

Hay un paquete muy √∫til para **.bg-purple_light[medir tiempos de distintas √≥rdenes]** que hacen lo mismo (el paquete `{microbenchmark}`). Vamos a comparar `order()` y `sort()`.

```{r}
library(microbenchmark) # instalar primera vez
x <- rnorm(1e3) # 1000 elementos aleatorias
microbenchmark(sort(x), x[order(x)], times = 1e3) #<<
```


---

name: ejercicios-vectores

# Ejercicios de vectores


.panelset[
.panel[.panel-name[Ejercicios]


* üìù **Ejercicio 1**: define el vector `x` como la concatenaci√≥n de los 5 primeros n√∫meros impares, y calcula su suma.
 
* üìù **Ejercicio 2**: obt√©n los elementos de `x` mayores que 4. Determina los lugares que ocupan. Calcula el n√∫mero de elementos de `x` mayores que 4.

* üìù **Ejercicio 3**: calcula el vector `1/x` y obt√©n la versi√≥n ordenada (de menor a mayor).

* üìù **Ejercicio 4**: define un vector con tu estatura y peso, y nombra cada elemento.

 
]

.panel[.panel-name[Soluci√≥n ej. 1]

```{r}
x <- c(1, 3, 5, 7, 9)

# otra forma
x <- seq(1, 9, by = 2)

# Suma
sum(x)
```
]

.panel[.panel-name[Soluci√≥n ej. 2]

```{r}
# Elementos mayores que 4
x[x > 4]

# Lugares que ocupan
which(x > 4)

# Cantidad de elementos mayores que 4
sum(x > 4)
```
]

.panel[.panel-name[Soluci√≥n ej. 3]

```{r}
y <- 1/x

# una forma
sort(y)

# otra forma
y[order(y)]
```

]


.panel[.panel-name[Soluci√≥n ej. 4]

```{r}
x <- c("estatura" = 180, "peso" = 80)
x
```

]

]

---

# Ejercicios de vectores

.panelset[
.panel[.panel-name[Ejercicios]

 
* üìù **Ejercicio 5**:  encuentra del vector `x` del ejercicio 1 los elementos mayores (estrictos) que 1 y menores (estrictos) que 7. Encuentra una forma de averiguar si todos los elementos son o no positivos.
 
 
* üìù **Ejercicio 6**: define el vector `x <- c(-1, 0, -2, 5, 3, 7)` y obt√©n los elementos que ocupan una posici√≥n impar.
 
 
* üìù **Ejercicio 7**: define el vector de los primeros n√∫meros impares (hasta el 21) y extrae los elementos que ocupan los lugares `1, 4, 5, 8`. Elimina del vector el segundo elemento

 
* üìù **Ejercicio 8**: define un vector de 8 valores y determina la media, la mediana y los cuartiles.

]

.panel[.panel-name[Soluci√≥n ej. 5]

```{r}
x <- c(1, 3, 5, 7, 9)
# valores >1 y <7
x[x > 1 & x < 7]

# ¬øTodos positivos?
all(x > 0)
sum(all(x <= 0)) # debe dar 0
```

]

 
 
.panel[.panel-name[Soluci√≥n ej. 6]

```{r}
x <- c(-1, 0, -2, 5, 3, 7)
x[seq(1, length(x), by = 2)]
```

]

.panel[.panel-name[Soluci√≥n ej. 7]

```{r}
x <- seq(1, 21, by = 2)

# posiciones pedidas
x[c(1, 4, 5, 8)]

# sin las posiciones pedidas
x[-c(1, 4, 5, 8)]

# eliminamos del vector el segundo elemento
x[-2]
```
]

.panel[.panel-name[Soluci√≥n ej. 8]

```{r}
x <- c(0, -2, 3, 7, -5, 9, 3, 1)
mean(x)
median(x)
quantile(x)
```
]


]

---

name: matrices

# De la .orange[celda] a la .green[tabla]
 

```{r echo = FALSE,  out.width = "55%", fig.align = "center"}
knitr::include_graphics("./img/celdas.jpg")
``` 

* **.bg-purple_light[Celda]**: un dato **.bg-orange[individual]** de un tipo concreto.

* **.bg-purple_light[Variable]**: una **.bg-orange[concatenaci√≥n de valores]** del mismo tipo (**vectores**).


&nbsp;

--

**.bg-purple_light[Matriz]**: **.bg-orange[concatenaci√≥n de variables]** del **.bg-yellow[mismo tipo]** y longitud.

---

# .orange[MATRICES]: concatenando variables


Cuando analizamos datos solemos tener varias **variables distintas** de cada individuo: necesitamos una ¬´tabla¬ª con **.bg-purple_light[distintas variables]** (de **.bg-orange[IGUAL longitud]**).

Las **.bg-purple_light[matrices]** son una concatenaci√≥n de variables, del **.bg-orange[mismo tipo e igual longitud]**, dispuestas en **p columnas** (datos p-dimensionales) 

--

&nbsp;

Vamos a empezar definiendo una **matriz sencilla**: imagina que tenemos las estaturas y pesos de 5 personas. ¬øC√≥mo juntar las dos variables creando nuestro primer conjunto de datos? F√≠jate que son del mismo tipo e igual longitud.

```{r}
estaturas <- c(150, 160, 170, 180, 190)
pesos <- c(60, 70, 80, 90, 100)
```

---

# .orange[MATRICES]: concatenando variables

```{r}
estaturas <- c(150, 160, 170, 180, 190)
pesos <- c(60, 70, 80, 90, 100)
```

¬øC√≥mo juntar las dos variables creando nuestro primer conjunto de datos? Vamos a **.bg-purple_light[crear una matriz]**, un conjunto de n√∫meros organizado en 2 columnas (una por variable) y 5 filas o registros (una por persona). Para ello usaremos la funci√≥n `cbind()`, que nos **concatena vectores de igual longitud en columnas**.

 
```{r}
# Construimos la matriz por columnas
datos_matriz <- cbind(estaturas, pesos) #<<
datos_matriz
```

---

# .orange[MATRICES]: concatenando variables


.pull-left[

```{r echo = FALSE,  out.width = "99%", fig.align = "left"}
knitr::include_graphics("./img/datos_matriz_1.jpg")
``` 


]


.pull-right[

```{r eval = FALSE}
View(datos_matriz)
```

Podemos **.bg-purple_light[visualizar la matriz]** en un formato ¬´excelizado¬ª con la funci√≥n `View()`.


Tambi√©n podemos **.bg-purple_light[construir la matriz por filas]** con la funci√≥n `rbind()` (aunque lo recomendable es tener cada variable en  columna y cada individuo en fila).

```{r}
# Construimos la matriz por filas
rbind(estaturas, pesos) 
```

]

---
 
 
# .orange[MATRICES]: concatenando variables

Podemos comprobar las **.bg-purple_light[dimensiones de una matriz]** con `dim()`, `nrow()` y `ncol()`: nuestros datos est√°n **.bg-orange[tabulados]**:

```{r}
dim(datos_matriz) # vector
nrow(datos_matriz)
ncol(datos_matriz)
```

---

# .orange[MATRICES]: concatenando variables


Veamos un ejemplo con **tres variables/columnas**: edades, tel√©fonos y c√≥digos postales.

```{r}
edades <- c(14, 24, 56, 31, 20, 87, 73) 
tlf <- c(NA, 683839390, 621539732, 618211286, NA, 914727164, NA)
cp <- c(33007, 28019, 37005, 18003, 33091, 25073, 17140)

# Construimos la matriz por columnas
datos_matriz <- cbind(edades, tlf, cp) #<<
datos_matriz
```


---

# .orange[MATRICES]: a√±adir registros/variables

Las funciones `cbind()` y `rbind()` no solo nos permiten crear matrices desde cero sino tambi√©n **.bg-purple_light[a√±adir filas o columnas]** a matrices existentes.

```{r}
# A√±adimos una fila
rbind(datos_matriz, c(27, 620125780, 28051))
```

---

# .orange[MATRICES]: valores repetidos

Podemos definir una **.bg-purple_light[matriz de n¬∫ repetidos]** con `matrix(..., nrow = ..., ncol = ...)`

```{r}
# matriz de ceros de 3 filas, 2 columnas,
matrix(0, nrow = 3, ncol = 2) #<<
```

--

Tambi√©n podemos definir una **.bg-purple_light[matriz a partir de un vector num√©rico]**, reorganizando los valores en forma de matriz (sabiendo que los elementos se van colocando por columnas).

```{r}
matrix(1:15, ncol = 5) # Matriz con el vector 1:15
```

---

# .green[OPERACIONES] con .orange[MATRICES]

Con las matrices sucede como con los vectores: cuando aplicamos una **.bg-purple_light[operaci√≥n aritm√©tica]** lo hacemos **.bg-orange[elemento a elemento]**

```{r}
z <- matrix(1:15, ncol = 5) 
z / 5
z + 3
```

---

# .orange[MATRICES] de .green[CARACTERES]

Tambi√©n podemos crear matrices de otros tipos de datos, siempre y cuando las **.bg-purple_light[columnas sean del mismo tipo e igual longitud]**, por ejemplo una **.bg-orange[matriz de caracteres]**.

```{r}
# matriz de caracteres
nombres <- c("Javier", "Carlos", "Mar√≠a")
apellidos <- c("√Ålvarez", "Garc√≠a", "P√©rez")
cbind(nombres, apellidos)
```

--

```{r}
# matriz de valores l√≥gicos
cbind(c(TRUE, FALSE), c(FALSE, TRUE))
```

---

# .orange[SELECCIONAR] elementos

Si recuerdas para los vectores, us√°bamos el operador `[i]` para **acceder al elemento i-√©simo**. En el caso de las matrices la l√≥gica ser√° la misma:

* para **.bg-purple_light[acceder a la fila i-√©sima]** se usa el operador `[i, ]` (dejando libre la columna).

```{r}
datos_matriz[1, ] # fila 1
```

---

# .orange[SELECCIONAR] elementos

Si recuerdas para los vectores, us√°bamos el operador `[i]` para **acceder al elemento i-√©simo**. En el caso de las matrices la l√≥gica ser√° la misma:

* para **.bg-purple_light[acceder a la columna j-√©sima]** se usa el operador `[, j]` (dejando libre la fila).

```{r}
datos_matriz[, 3] # columna 3
```


---

# .orange[SELECCIONAR] elementos

Si recuerdas para los vectores, us√°bamos el operador `[i]` para **acceder al elemento i-√©simo**. En el caso de las matrices la l√≥gica ser√° la misma:

* para **.bg-purple_light[acceder conjuntamente al elemento (i, j)]** se usa el operador `[i, j]`.

```{r}
datos_matriz[1, 3] # elemento (1, 3)
datos_matriz[2, 2] # elemento (1, 3)
```


---

# .orange[NOMBRAR] variables

Una matriz por defecto adopta los nombres de los vectores como los nombres de columnas, pero podemos 
**.bg-purple_light[personalizar los nombres de las variables]**

```{r}
estaturas <- c(150, 160, 170)
pesos <- c(60, 70, 80)
cbind("altura" = estaturas, "pesaje" = pesos)
```


--

Si las columnas tienen nombres podemos hacer uso de ellos para **acceder a las columnas**

```{r}
datos_matriz[, c("edades", "tlf")]
```

---

# .orange[NOMBRAR] variables

Tambi√©n podemos **.bg-purple_light[asignar nombres]** a las filas de una matriz con `row.names()` y acceder a filas y columnas por nombres.

```{r}
row.names(datos_matriz) <- c("Javi", "Laura", "Patricia", "Carlos", "Juan", "Luis", "Carla")
datos_matriz
datos_matriz["Javi", "edades"]
```

---

# .orange[OPERACIONES] por filas/columnas

Normalmente, para explicar las **operaciones con matrices** en un lenguaje de programaci√≥n al uso, necesitar√≠amos hablar de una **herramienta llamada bucles**. Lo mencionaremos m√°s adelante pero no los vamos a necesitar de momento (cu√°ntos menos los usemos en `R`, mejor)

--

Imagina que tuvi√©semos nuestra matriz de estaturas y pesos.

```{r}
datos_matriz <- cbind(estaturas, pesos)
datos_matriz
```

--

¬øC√≥mo podemos **.bg-purple_light[aplicar una operaci√≥n para cada una de las filas o columnas]** de una matriz?

---

# .orange[OPERACIONES] por filas/columnas

Imagina que queremos obtener la **.bg-purple_light[media de cada columna]**. Lo haremos con la funci√≥n `apply()`, y le indicaremos como argumentos la matriz, el **.bg-orange[sentido de la operaci√≥n]** (`MARGIN = 1` por filas, `MARGIN = 2` por columnas) y la **funci√≥n a aplicar**

```{r}
# Media (mean) por columnas (MARGIN = 2)
apply(datos_matriz, MARGIN = 2, FUN = "mean")
```

--

Si la funci√≥n **requiere de argumentos extras** se lo podemos indicar al final.

```{r}
estaturas_bis <- c(150, NA, 170, 180, 190)
datos_matriz_bis <- cbind(estaturas_bis, pesos) 
apply(datos_matriz_bis, MARGIN = 2, FUN = "mean")
```

---

name: ejercicios-matrices

# Ejercicios de matrices

.panelset[
.panel[.panel-name[Ejercicios]


* üìù **Ejercicio 1**: modifica el c√≥digo para definir una matriz `x` de ceros de 3 filas y 7 columnas.
 
```{r eval = FALSE}
# Matriz
x <- matrix(0, nrow = 2, ncol = 3)
x
```

* üìù **Ejercicio 2**: a la matriz anterior, suma un 1 a cada n√∫mero de la matriz y divide el resultado entre 5.
 

* üìù **Ejercicio 3**: tras definir la matriz `x` calcula su transpuesta y obt√©n sus dimensiones
 

]

.panel[.panel-name[Soluci√≥n ej. 1]

```{r}
x <- matrix(0, nrow = 3, ncol = 7)
x
```

]

.panel[.panel-name[Soluci√≥n ej. 2]

```{r}
# sumamos 1
x + 1

# dividimos entre 5
(x + 1) / 5
 
```

]

.panel[.panel-name[Soluci√≥n ej. 3]

```{r}
# dimensiones originales
dim(x)

# transpuesta
y <- t(x)
y
dim(y)
```

]


]

---

# Ejercicios de matrices

.panelset[
.panel[.panel-name[Ejercicios]


* üìù **Ejercicio 4**: define la matriz `x <- matrix(1:12, nrow = 4)`. Obt√©n la primera fila, la tercera columna, y el elemento (4, 1).

* üìù **Ejercicio 5**: en la matriz anterior, pon a cada fila `i` el nombre `fila_i` (fila_1, fila_2, fila_3, fila_4).

* üìù **Ejercicio 6**: con la matriz anterior definida como `matrix(1:12, nrow = 4)`, calcula la media de todos los elementos, la media de cada fila y la media de cada columna. Calcula la suma de de cada fila y de cada columna

]

.panel[.panel-name[Soluci√≥n ej. 4]

```{r}
x <- matrix(1:12, nrow = 4)

# primera fila
x[1, ]

# tercera columna
x[, 3]

# (4, 1)
x[4, 1]
```

]

.panel[.panel-name[Soluci√≥n ej. 5]

```{r}
x
row.names(x) <- glue("fila_{1:4}")
x
```

]

.panel[.panel-name[Soluci√≥n ej. 6]

```{r}
# media por filas
apply(x, MARGIN = 1, FUN = mean)

# media por columnas
apply(x, MARGIN = 2, FUN = mean)

# suma por filas
apply(x, MARGIN = 1, FUN = sum)

# suma por columnas
apply(x, MARGIN = 2, FUN = sum)
```

]

]



---

# Ejercicios extras (matrices y vectores)

.panelset[
.panel[.panel-name[Ejercicios extra]

* üìù **Ejercicio 1**: define un vector `y` que contenga los 5 primeros pares, y otro `x` con los 5 primeros impares. Haz la suma de `x` (ejercicio 1 anterior) e `y`.
 
* üìù **Ejercicio 2**: encuentra del vector `x <- c(-1, 0, -2, 5, 3, 7)` el lugar (el √≠ndice) que ocupa su m√≠nimo y su m√°ximo.
 

* üìù **Ejercicio 3**: define el vector `c(-1, 0, 4, 5, -2)`, calcula la ra√≠z cuadrada del vector y determina que lugares son de tipo `NaN`.

* üìù **Ejercicio 4**:  el siguiente c√≥digo define una matriz de dimensiones `4 x 3` y calcula la suma por columnas. Modifica el c√≥digo para que realice la suma por filas.
 
```{r eval = FALSE}
matriz <- matrix(1:12, nrow = 4)
apply(matriz, MARGIN = 2, FUN = "sum")
```

]

.panel[.panel-name[Soluci√≥n ej. 1]

```{r}
y <- c(0, 2, 4, 6, 8)
x <- y + 1 # forma m√°s r√°pida de (1, 3, 5, 7, 9)
x + y
```

]

.panel[.panel-name[Soluci√≥n ej. 2]

```{r}
x <- c(-1, 0, -2, 5, 3, 7)
which.max(x)
which.min(y)
```

]

.panel[.panel-name[Soluci√≥n ej. 3]

```{r}
x <- c(-1, 0, 4, 5, -2)
sqrt(x)
is.nan(sqrt(x))
```

]

.panel[.panel-name[Soluci√≥n ej. 4]

```{r}
matriz <- matrix(1:12, nrow = 4)
apply(matriz, MARGIN = 1, FUN = "sum")
```

]

]

---

name: data.frame

# .orange[TABLAS]: variables .green[data.frame]
 


```{r echo = FALSE,  out.width = "45%", fig.align = "center"}
knitr::include_graphics("./img/celdas.jpg")
``` 

* **.bg-purple_light[Celda]**: un dato **.bg-orange[individual]** de un tipo concreto.

* **.bg-purple_light[Variable]**: una **.bg-orange[concatenaci√≥n de valores]** del mismo tipo (**vectores**).

* **.bg-purple_light[Matriz]**: **.bg-orange[concatenaci√≥n de variables]** del **.bg-yellow[mismo tipo]** y longitud.

&nbsp;

--

* **.bg-purple_light[data.frame (tabla)]**: **.bg-orange[concatenaci√≥n de variables]** de **.bg-yellow[DISTINTO tipo]** e igual longitud.


---

# .red[PROBLEMAS] de las .green[MATRICES]


Retomemos nuestra matriz de edades, tel√©fonos y c√≥digos postales.

```{r}
edades <- c(14, 24, 56, 31, 20, 87) 
tlf <- c(NA, 683839390, 621539732, 618211286, NA, 914727164)
cp <- c(33007, 28019, 37005, 18003, 33091, 25073)

# Construimos la matriz por columnas
datos_matriz <- cbind(edades, tlf, cp) #<<
datos_matriz
```

--

¬øQu√© suceder√° si ahora **.bg-purple_light[a√±adimos una columna con los nombres]** (tipo caracter) de cada persona?

---


# .red[PROBLEMAS] de las .green[MATRICES]

```{r}
nombres <- c("Sonia", "Carla", "Pepito", "Carlos", "Lara", "Sandra", "Javi")
datos_matriz_nueva <- cbind(nombres, datos_matriz)
```

```{r echo = FALSE}
datos_matriz_nueva 
```

**.bg-red_light[¬øHas visto lo que ha sucedido?]**

--

Como una **.bg-purple_light[matriz solo puedes tener un tipo de dato]**, al a√±adir una variable de tipo texto, `R` se ha visto obligado a **convertir los n√∫meros en texto** (poni√©ndole **comillas**). 

```{r error = TRUE}
datos_matriz_nueva[, "edades"] + 1
```

---

# .red[PROBLEMAS] de las .green[MATRICES]

Las **.bg-purple_light[matrices]** nos permiten almacenar distintas variables SIEMPRE Y CUANDO tengan

* **.bg-orange[Misma longitud]**.
* **.bg-orange[Mismo tipo]** de dato (sin mezclar).

Esto es bastante limitante en la vida real nuestros datos tendr√°n variables de todo tipo: supongamos que queremos **guardar de 7 personas las siguientes variables**.


```{r}
# Nombres
nombres <- c("Sonia", "Carla", "Pepito", "Carlos", "Lara", "Sandra", "Javi")

# Apellidos
apellidos <- c(NA, "Gonz√°lez", "Fern√°ndez", "Mart√≠nez", "Li√©bana", "Garc√≠a", "Ortiz")

# C√≥digo postal
cp <- c(28019, 28001, 34005, 18410, 33007, 34500, 28017)

# Edades
edades <- c(45, 67, NA, 31, 27, 19, 50)
```

---


# .red[PROBLEMAS] de las .green[MATRICES]

Las **.bg-purple_light[matrices]** nos permiten almacenar distintas variables SIEMPRE Y CUANDO tengan

* **.bg-orange[Misma longitud]**.
* **.bg-orange[Mismo tipo]** de dato (sin mezclar).

Esto es bastante limitante en la vida real nuestros datos tendr√°n variables de todo tipo: supongamos que queremos **guardar de 7 personas las siguientes variables**.


```{r}
# Tel√©fono
tlf <- c(618910564, 914718475, 934567891, 620176565, NA, NA, 688921344)

# Estado civil (no lo sabemos de una persona)
casado <- c(TRUE, FALSE, FALSE, NA, TRUE, FALSE, FALSE)

# Fecha de creaci√≥n (fecha en el que esa persona entra en el sistema)
# lo convertimos a tipo fecha
fecha_creacion <-
  as_date(c("2021-03-04", "2020-10-12", "1990-04-05",
            "2019-09-10", "2017-03-21", "2020-07-07",
            "2000-01-28"))
```


---

# .red[PROBLEMAS] de las .green[MATRICES]

Aahora tenemos un **popurr√≠ de variables**, de la misma longitud pero de tipos distintos:

* `(edades, tlf, cp)` son variables **num√©ricas**.
* `(nombres, apellidos)` son variables de **texto**.
* `casado` es una variable **l√≥gica**.
* `fecha_creacion` de tipo **fecha**.

¬øQu√© suceder√≠a si **.bg-purple_light[intentamos mezclar todo en una matriz]**?

--

```{r}
# Juntamos por columnas
datos_matriz <-
  cbind(nombres, apellidos, edades, tlf, cp, casado, fecha_creacion)
datos_matriz
```

---

# .red[PROBLEMAS] de las .green[MATRICES]

```{r}
datos_matriz
```

Dado que en una **.bg-purple_light[matriz solo podemos almacenar datos del mismo tipo]**, los n√∫meros los convierte a texto, las variables l√≥gicas las convierte a texto (`TRUE` era un valor l√≥gico, `"TRUE"` es un texto, sin significado de verdadero/falso) y las fechas las ha convertido a texto.

```{r error = TRUE}
datos_matriz[1, "fecha_creacion"] - datos_matriz[2, "fecha_creacion"]
```

---

# .orange[TABLAS]: variables .green[data.frame]

Vamos a aprender c√≥mo juntar variables de distinto tipo, sin **modificar la integridad** del dato. El formato de **.bg-purple_light[tabla de datos]** que vamos a empezar a usar se llama `data.frame`: una **.bg-purple_light[colecci√≥n de variables de igual longitud]** pero cada una puede ser de un **.bg-orange[tipo distinto]**.

--

Para crearlo basta con usar la funci√≥n `data.frame()`, pas√°ndole como argumentos (separados por comas) las variables que queremos reunir.

```{r}
# Creamos nuestro primer data.frame
tabla <- data.frame(nombres, apellidos, edades, tlf,
                    cp, casado, fecha_creacion) #<<
tabla
```

---

# .orange[TABLAS]: variables .green[data.frame]

```{r}
tabla
class(tabla)
dim(tabla)
```

---

# .orange[TABLAS]: variables .green[data.frame]

Al igual que con matrices, podemos **.bg-purple_light[crear un data.frame]** indicando **nombre de columnas**

```{r}
tabla <- data.frame("nombre" = nombres, "apellido" = apellidos, "edad" = edades, "tel√©fono" = tlf, 
                    "cp" = cp, "casado" = casado, "fecha_registro" = fecha_creacion)
tabla
```

&nbsp;

**.bg-green_light[¬°TENEMOS NUESTRO PRIMER CONJUNTO DE DATOS!]** Puedes visualizarlo escribiendo su nombre en consola o con `View(tabla)`

---

# .orange[TABLAS]: variables .green[data.frame]

Si tenemos uno ya creado y queremos **.bg-purple_light[a√±adir una columna]** es tan simple como usar la `funci√≥n data.frame()` que ya hemos visto para concatenar la columna. Vamos a√±adir por ejemplo una nueva variable, el **n√∫mero de hermanos** de cada individuo.

```{r}
# A√±adimos una nueva columna con n¬∫ de hermanos/as
hermanos <- c(0, 0, 1, 5, 2, 3, 0)
tabla <- data.frame(tabla, "n_hermanos" = hermanos)
tabla
```

---

# .orange[TABLAS]: variables .green[data.frame]

Si queremos **.bg-purple_light[acceder a una columna, fila o elemento]** en concreto, los `data.frame` tienen las mismas ventajas que una matriz, as√≠ que bastar√≠a con usar los mismos operadores.

```{r}
tabla[5, ] # Accedemos a la quinta fila
```

--

.pull-left[

```{r echo = FALSE,  out.width = "99%", fig.align = "left", fig.cap = "Men√∫ desplegable de variables (columnas)"}
knitr::include_graphics("./img/tabla_dolar.jpg")
``` 
]

.pull-right[

No solo tiene las ventajas de una matriz sino que tambi√©n tiene las **.bg-purple_light[ventajas de una ¬´base¬ª de datos]**: podemos aceder a las variables por el √≠ndice de columna que ocupan pero tambi√©n **.bg-purple_light[acceder por su nombre]**, poniendo el nombre de la tabla, el s√≠mbolo `$` y, con el tabulador, nos aparecer√° un men√∫ de columnas a elegir.

]

---

# Primer .orange[AN√ÅLISIS DE DATOS]

.panelset[
.panel[.panel-name[USArrests]

Nuestro primer conjunto ser√° `USArrests`, un dataset de **.bg-purple_light[arrestos en EE.UU.]** del paquete `{datasets}` (si escribimos `datasets::` y pulsamos tabulador, se nos abre un desplegable con distintos conjuntos de datos para ser usado)

```{r}
# install.packages("datasets") # Descomentar si nunca se ha instalado
library(datasets)
datasets::USArrests
```

Contiene **.bg-purple_light[estad√≠sticas de arrestos en 1973 (por cada 100 000 habitantes)]** por agresi√≥n, asesinato y violaci√≥n, en cada uno de los 50 estados de Estados Unidos.
]

.panel[.panel-name[Visualizar]

Con `View()` se nos abrir√° el conjunto en un formato ¬´excelizado¬ª. Adem√°s con `head()` podemos **.bg-purple_light[visualizar la cabecera]** (primeras) del conjunto de datos.

```{r}
head(USArrests)
```

]

.panel[.panel-name[Variables]

Con la funci√≥n `names()` podemos obtener directamente el **.bg-purple_light[nombre de las variables]** (tambi√©n podemos usarlo para renombrarlas)

```{r}
names(USArrests)
```

El conjunto contiene los **3 tipos de delito** mencionados (para cada estado), y adem√°s el **porcentaje de poblaci√≥n que vive en √°reas urbanas**. Esto lo podemos saber ejecutando la ayuda con `? datasets::USArrests`.

]

.panel[.panel-name[Individuos]

Con la funci√≥n `row.names()` podemos obtener el **.bg-purple_light[nombre de las filas]** (de los estados) para cada uno de ellos.

```{r}
row.names(USArrests)
```

]


.panel[.panel-name[Dimensiones]

¬øC√≥mo averiguar el **.bg-purple_light[n√∫mero de registros y el n√∫mero de variables]**?

```{r}
dim(USArrests)
nrow(USArrests)
ncol(USArrests)
```

]

.panel[.panel-name[Selecci√≥n]

Al igual que antes, podemos **.bg-purple_light[seleccionar filas por √≠ndices]** y **.bg-purple_light[variables nombre]**.


```{r}
USArrests[c(2, 10), c("Murder", "Assault")]
```

Tambi√©n podemos usar las ventajas de los `data.frame` para acceder a las variables.

```{r}
USArrests$Murder
```

]

.panel[.panel-name[subset]

En el caso de los `data.frame` tenemos adem√°s a nuestro disposici√≥n una **herramienta muy potente**: la funci√≥n `subset()`. Dicha funci√≥n nos va a permitir **.bg-purple_light[seleccionar filas y columnas a la vez]**, tomando de entrada la tabla, `subset = ...` igual a la **condici√≥n l√≥gica** para filtrar registros (filas) y `select = ...` igual al  nombre de las columnas que queremos seleccionar.

```{r}
subset(USArrests, subset = UrbanPop > 70, select = c("Murder"))
```

]

.panel[.panel-name[Caso pr√°ctico]

* üìù **Ejercicio**: filtra aquellos estados cuyo porcentaje de poblaci√≥n urbana sea inferior al 70% y donde las agresiones sean superiores a 250 por cada 100 000 habitantes, seleccionando solo las variables `Murder` y `Rape`

]

.panel[.panel-name[Caso pr√°ctico]

* üìù **Ejercicio**: filtra aquellos estados cuyo porcentaje de poblaci√≥n urbana sea inferior al 70% y donde las agresiones sean superiores a 250 por cada 100 000 habitantes, seleccionando solo las variables.

```{r}
subset(USArrests, subset = UrbanPop < 70 & Assault > 250,
       select = c("Murder", "Rape"))
```

]

]

---

name: tibble

# Mejorando los data.frame: .orange[TIBBLE]
 
Las tablas en formato `tibble` (con `tibble()` del paquete `{tibble}`, su clase ser√° `tbl_df`) son un tipo de `data.frame` mejorado, para una gesti√≥n **.bg-purple_light[m√°s √°gil, eficiente y coherente]**. Las tablas en formato `tibble` tienen **.bg-purple_light[4 ventajas principales]**

```{r echo = FALSE,  out.width = "30%", fig.align = "center"}
knitr::include_graphics("./img/tibble.svg")
``` 

---

# Mejorando los data.frame: .orange[TIBBLE]


*  Muestran **.bg-purple_light[metainformaci√≥n de las variables]**, y solo imprime por defecto las primeras filas.

```{r}
library(tibble)
tabla_tb <- tibble("x" = 1:50, "y" = rep(c("a", "b", "c", "d", "e"), 10),
                   "logica" = rep(c(TRUE, FALSE), 25))
tabla_tb
```



---

# Mejorando los data.frame: .orange[TIBBLE]
 
Puedes **imprimir las filas y columnas** que quieras con `print()`

```{r}
print(tabla_tb, n = 12, width = Inf) #<<
```

---

# Mejorando los data.frame: .orange[TIBBLE]
 

* La funci√≥n `tibble()` **.bg-purple_light[construye las variables secuencialmente]**, pudiendo hacer uso en la propia definici√≥n de variables reci√©n definidas en dicha definici√≥n.

```{r error = TRUE}
# data.frame
data.frame("x1" = 1:3, "x2" = 4:6, "y" = x1 * x2)
```

```{r}
# tibble
tibble("x1" = 1:3, "x2" = 4:6, "y" = x1 * x2)
```


---

# Mejorando los data.frame: .orange[TIBBLE]
 
* Si accedes a una **.bg-purple_light[columna que no existe]** avisa con un **.bg-red[warning]**.

```{r}
tabla_df <- data.frame("x" = 1:50, "y" = rep(c("a", "b", "c", "d", "e"), 10),
                   "logica" = rep(c(TRUE, FALSE), 25))
```

.pull-left[

```{r warning = TRUE}
# data.frame
tabla_df$variable_inexistente
```

]

.pull-right[

```{r warning = TRUE}
# tibble
tabla_tb$variable_inexistente
```

]

---


# Mejorando los data.frame: .orange[TIBBLE]

* No solo no te cambiar√° el tipo de datos sino que **.bg-purple_light[no te cambiar√° el nombre de las variables]**.

.pull-left[

```{r}
data.frame(":)" = "emoticono",
           " " = "en blanco",
           "2000" = "n√∫mero")
```

]

.pull-right[

```{r}
tibble(":)" = "emoticono",
       " " = "en blanco",
       "2000" = "n√∫mero")
```

]

---


# Mejorando los data.frame: .orange[TIBBLE]

Si ya tienes un `data.frame` es altamente recomendable **.bg-purple_light[convertirlo a tibble]** con `as_tibble()` (del paquete `{dplyr}`)

```{r}
library(dplyr)
as_tibble(USArrests)
```

Puedes consultar **m√°s funcionalidades** de dichos datos en <https://tibble.tidyverse.org/>

---

# Mejorando los data.frame: .orange[TIBBLE]

Una de las ventajas es la funci√≥n `glimpse()`, que nos permite obtener el **.bg-purple_light[resumen de columnas]** (no es para tener un resumen de los datos sino para ver las variables que tenemos y su tipo).

```{r}
glimpse(tabla_tb)
```

---

# Mejorando los data.frame: .orange[TIBBLE]

Am√©n de poder convetir con `as_tibble()` podemos **.bg-purple_light[crearlos por filas]** (como copiar y pegar de una tabla en documento) en lugar de por columnas con `tribble()`

```{r}
datos <- tribble(
  ~colA, ~colB,
  "a",   1,
  "b",   2)
datos
```

&nbsp;

--

**.bg-green_light[CONSEJO]**: prueba adem√°s el paquete `{datapasta}`, que nos permite **.bg-purple_light[copiar y pegar tablas de p√°ginas web]**


---

name: ejercicios-tibble

# Ejercicios

.panelset[
.panel[.panel-name[Ejercicios]


* üìù **Ejercicio 1**: carga del paquete `{datasets}` el conjunto de datos `airquality` (contiene variables de la calidad del aire de la ciudad de Nueva York desde mayo hasta septiembre de 1973). ¬øEs el conjunto de datos airquality de tipo tibble? En caso negativo, convi√©rtelo a `tibble`.

* üìù **Ejercicio 2**: obt√©n el nombre de las variables y las dimensiones del conjunto de datos. ¬øCu√°ntas variables hay? ¬øCu√°ntos d√≠as se han medido?
 
* üìù **Ejercicio 3**:  modifica el c√≥digo inferior para que nos filtre solo los datos del mes de agosto.
 
```{r eval = FALSE}
# Filtramos filas
filtro_fila <- subset(., subset = Month < 6)
filtro_fila
```

]

.panel[.panel-name[Soluci√≥n ej. 1]

```{r}
library(datasets)
class(airquality) # no es data.frame

# Convertimos a tibble
airquality <- as_tibble(airquality)
class(airquality)
```

]

.panel[.panel-name[Soluci√≥n ej. 2]

```{r}
names(airquality)

dim(airquality)

# N√∫mero variables
ncol(airquality)

# N√∫mero d√≠as
nrow(airquality)
```

]


.panel[.panel-name[Soluci√≥n ej. 3]

```{r}
# Filtramos filas
filtro_fila <- subset(airquality, subset = Month == 8)
filtro_fila
```
]

]

---

# Ejercicios

.panelset[
.panel[.panel-name[Ejercicios]


* üìù **Ejercicio 4**: del conjunto selecciona aquellos datos que no sean ni de julio ni de agosto.

* üìù **Ejercicio 5**: modifica el siguiente c√≥digo para quedarte solo con las variable de ozono y temperatura.
 
```{r eval = FALSE}
filtro_col <- subset(.,  select = c("Ozone"))
filtro_col
```

* üìù **Ejercicio 6**:  selecciona los datos de temperatura y viento de agosto. Traduce a castellano el nombre de las columnas del conjunto filtrado.


* üìù **Ejercicio 7**: a√±ade a los datos originales una columna con la fecha completa (recuerda que es del a√±o 1973 todas las observaciones).

]

.panel[.panel-name[Soluci√≥n ej. 4]

```{r}
subset(airquality, subset = !(Month %in% c(7, 8)))
```

]

.panel[.panel-name[Soluci√≥n ej. 5]

```{r}
# Filtramos columnas
filtro_col <- subset(airquality,  select = c("Ozone", "Temp"))
filtro_col
```

]

.panel[.panel-name[Soluci√≥n ej. 6]

```{r}
datos <- subset(airquality, subset = Month == 8, select = c("Temp", "Wind"))
datos 

# Traducimos a castellano el nombre
names(datos) <- c("temperatura", "viento")
glimpse(datos)
```

]

.panel[.panel-name[Soluci√≥n ej. 7]

```{r}
nuevos_datos <- 
  tibble(airquality, "fecha" = as_date(glue("1973-{Month}-{Day}")))
nuevos_datos
```

]


]

---

# Ejercicios extras

.panelset[
.panel[.panel-name[Ejercicios extras]


* üìù **Ejercicio 8**: define un `tibble` con tres variables num√©ricas `a, b, c`, tal que la tercera sea el producto de las dos primeras `c = a * b`.

* üìù **Ejercicio 9**:  define un tibble con tres variables de nombres `variable`, `2`, `tercera` y `:)`, e intenta acceder a ellas.
 
* üìù **Ejercicio 10**:  obten de los paquetes `{dplyr}` y `{gapminder}` los conjuntos de datos `starwars` y `gapminder`. Comprueba el n√∫mero de variables, de registros e imprime los datos

]

.panel[.panel-name[Soluci√≥n ej. 8]

```{r}
tibble("a" = 1:4, "b" = 11:14, "c" = a * b)
```

]

.panel[.panel-name[Soluci√≥n ej. 9]

```{r}
datos <- tibble("variable" = 1, "2" = "a", "tercera" = 3, ":)" = "b")

# Accedemos
datos$variable
datos$`2`
datos$tercera
datos$`:)`
```

]

.panel[.panel-name[Soluci√≥n ej. 10]

```{r}
library(dplyr)
dim(starwars)

library(gapminder)
dim(gapminder)
```

]

]

---

class: inverse center middle
name: intro-estadistica

# Introducci√≥n a la ESTAD√çSTICA

---



# Introducci√≥n a la .orange[ESTAD√çSTICA]

```{r echo = FALSE,  out.width = "50%", fig.align = "center"}
knitr::include_graphics("./img/tellme.jpg")
``` 


---

# Introducci√≥n a la .orange[ESTAD√çSTICA]

.pull-left[

**.bg-purple_light[¬øQu√© es la estad√≠stica?]** Seg√∫n la RAE...

* **.bg-purple_light[Estudio de los datos]** cuantitativos de la poblaci√≥n, de los recursos naturales e industriales, del tr√°fico o de cualquier otra manifestaci√≥n de las sociedades

* **.bg-purple_light[Rama de la matem√°tica]** que utiliza grandes conjuntos de datos num√©ricos para obtener inferencias basadas en el c√°lculo de probabilidades.

]

.pull-right[

```{r echo = FALSE,  out.width = "90%", fig.align = "center"}
knitr::include_graphics("./img/perez_reverte.jpg")
``` 

]

---

# Introducci√≥n a la .orange[ESTAD√çSTICA]

.pull-left[

**.bg-purple_light[¬øQu√© es la estad√≠stica?]** Seg√∫n la RAE...

* **.bg-purple_light[Estudio de los datos]** cuantitativos de la poblaci√≥n, de los recursos naturales e industriales, del tr√°fico o de cualquier otra manifestaci√≥n de las sociedades

* **.bg-purple_light[Rama de la matem√°tica]** que utiliza grandes conjuntos de datos num√©ricos para obtener inferencias basadas en el c√°lculo de probabilidades.

]

.pull-right[

```{r echo = FALSE,  out.width = "51%", fig.align = "center"}
knitr::include_graphics("./img/perez_reverte.jpg")
``` 

]


> ¬´La estad√≠stica est√° caracterizada por una informaci√≥n acerca de un colectivo o universo, lo que constituye su objeto material; un modo propio de razonamiento, el m√©todo estad√≠stico, lo que constituye su objeto formal y unas previsiones de cara al futuro, lo que implica un ambiente de incertidumbre¬ª (Cabri√°, 1994). 

---

# Introducci√≥n a la .orange[ESTAD√çSTICA]

.pull-left[

La **.bg-purple_light[estad√≠stica]** como ciencia naci√≥ como una **.bg-purple_light[ciencia del Estado]**, de hecho nuestra palabra actual viene de dos palabras previas

* del t√©rmino (neo)latino ¬´statisticum collegium¬ª: consejo de Estado.
* del alem√°n **.bg-purple_light[¬´statistik¬ª]** (ciencia del Estado), t√©rmino introducido por G. Achenwall.

&nbsp;

En su origen fue una desarrollada como una mera **.bg-purple_light[herramienta para la administraci√≥n eficiente]** de la sociedad.

]

.pull-right[

```{r echo = FALSE,  out.width = "95%", fig.align = "left"}
knitr::include_graphics("./img/biblia.jpg")
``` 

]

---

# Introducci√≥n a la .orange[ESTAD√çSTICA]

.pull-left[

Los **.bg-purple_light[primeros usos]** documentados son de hecho para elaborar **.bg-purple_light[censos y de uso militar]** en Mesopotamia, China y Egipto, con el objetivo de tener un **.bg-purple_light[recuento y organizaci√≥n de recursos]**

* Cobrar **impuestos**
* Repartir **tierras**
* Reclutar **soldados**

&nbsp;

Seg√∫n Tuc√≠dides, conceptos como la **.bg-purple_light[moda]** ya exist√≠an en el siglo V a.C.: para asaltar la muralla de Platea, se usaba la estad√≠stica para el recuento de ladrillos de la muralla y aproximar su altura.

]


.pull-right[

```{r echo = FALSE,  out.width = "95%", fig.align = "left"}
knitr::include_graphics("./img/census.jpg")
``` 

]


---

# Introducci√≥n a la .orange[ESTAD√çSTICA]

El **.bg-purple_light[objetivo principal]** de la estad√≠stica, ayudada por la probabilidad, es **.bg-purple_light[analizar datos y fen√≥menos]** cuyo mecanismo subyacente suele ser un experimento aleatorio.

--

### Experimento .green[ALEATORIO]

Un experimento se puede clasificar principalmente en

* **.bg-purple_light[Determinista]**: con las mismas condiciones iniciales, se obtiene el mismo resultado. Por ejemplo, el movimiento parab√≥lico de un proyectil sin rozamiento.

* **.bg-purple_light[Aleatorio]**: con las mismas condiciones iniciales, se pueden obtener resultados diferentes. Por ejemplo, el tiempo entre clientes que entran en un establecimiento.

---

# Introducci√≥n a la .orange[ESTAD√çSTICA]


Un error muy habitual es interpretar lo ¬´aleatorio¬ª como **.bg-purple_light[equiprobable]**: un suceso aleatorio **.bg-red_light[NO IMPLICA]** que todas sus opciones tengan la misma probabilidad de suceder.

* **.bg-purple_light[Aleatorio]**: el resultado individual inmediato no se puede asegurar con total certeza (tenemos **.bg-orange[incertidumbre]**)

* **.bg-purple_light[Sucesos equiprobables]**: colecci√≥n de sucesos de una variable aleatoria cuya probabilidad de suceder es la misma para todos ellos.

--

**.bg-green_light[RECUERDA]**: un **dado trucado** sigue siendo aleatorio, igual de aleatorio que un dado sin trucar. No hay algo m√°s o menos aleatorio, solo **.bg-purple_light[diferentes distribuciones de probabilidad]** que modelizan los sucesos.

---

# .green[POBLACI√ìN] vs .orange[MUESTRA]

.pull-left[

**.bg-green_light[POBLACI√ìN]**

Una poblaci√≥n ser√° el conjunto total o **.bg-purple_light[colectivo de individuos factibles de estudiar]**, o de posibles elementos/eventos de los podr√≠amos tener observaciones (por ejemplo, 47 millones de espa√±oles). 

Es nuestro **.bg-purple_light[universo te√≥rico]**, y nuestro objetivo ser√° conocer algunas de las propiedades de esa poblaci√≥n.

&nbsp;

**.bg-green_light[INDIVIDUO]**

Cada uno de los elementos o eventos de la poblaci√≥n.

]

.pull-right[

**.bg-orange[MUESTRA (SAMPLE)]**

Dado que la **.bg-red_light[poblaci√≥n suele ser inaccesible]** en su totalidad (no podemos medir a TODA la poblaci√≥n), debemos realizar una **.bg-purple_light[selecci√≥n]** de un conjunto de individuos

Dicho subconjunto ser√° siempre de **.bg-purple_light[tama√±o finito n]**, de forma que la muestra sea de alguna manera **.bg-purple_light[¬´representativa¬ª]** de la poblaci√≥n (bien a lo largo de los individuos, bien a lo largo del tiempo). Un estudio estad√≠stico realizado sobre la totalidad de una poblaci√≥n se denomina censo. 


]

---

# .green[POBLACI√ìN] vs .orange[MUESTRA]


```{r echo = FALSE,  out.width = "55%", fig.align = "center"}
knitr::include_graphics("./img/poblacion_muestra.jpg")
``` 

---

# .green[CARACTERES] y .orange[MODALIDADES]


.pull-left[

* **.bg-purple_light[Caracteres (variables)]**: cada una de las **caracter√≠sticas o cualidades** que se podr√≠an medir o analizar para cada individuo de la poblaci√≥n (y de los que disponemos el valor para cada individuo de la muestra).

* **.bg-purple_light[Modalidades]**: conjunto de los **diferentes valores** que puede adoptar una caracter√≠stica o variable.


]

.pull-right[

Un **.bg-purple_light[ejemplo]** (poblaci√≥n de alumnos de UCM)

* **.bg-orange[Caracteres o variables]**:
  - sexo
  - edad
  - carrera
  - estatura

* **.bg-orange[Modalidades]**:
  - sexo: hombre/mujer.
  - edad: 18, 19, 20, 21, 22, ..., 98, 99, 100
  - carrera: mates, filolog√≠a, historia, etc.
  - estatura: intervalo [130cm, 200cm].
  
* **.bg-orange[Muestra]**: conjunto de 300 estudiantes seleccionados al azar.
]

---

# .orange[TIPOS] de variables

Imagina las siguientes variables:

* ¬øTienes hermanos?
* Resultado de la tirada de un dado
* Color de zapatillas
* Nivel de estudios
* N√∫mero de hermanos
* N√∫mero de pelos en la cabeza
* Resultado de un dado dividido entre 10
* Temperatura ¬∫C
* G√©nero
* Estatura o peso
* Religi√≥n


**.bg-purple_light[¬øCU√ÅL ES LA DIFERENCIA ENTRE ELLAS?]**

---


# .orange[TIPOS] de variables

.pull-left[

Imagina las siguientes variables:

* ¬øTienes hermanos?
* Resultado de la tirada de un dado
* Color de zapatillas
* Nivel de estudios
* N√∫mero de hermanos
* N√∫mero de pelos en la cabeza
* Resultado de un dado dividido entre 10
* Temperatura ¬∫C
* G√©nero
* Estatura o peso
* Religi√≥n


**.bg-purple_light[¬øCU√ÅL ES LA DIFERENCIA ENTRE ELLAS?]**

]

.pull-right[

* **.bg-purple_light[Cualitativas]**: representan **.bg-orange[cualidades o categor√≠as]** no cuantificables num√©ricamente (sexo, estado civil, etc).

  - **.bg-purple_light[Ordinales]**: admiten **jerarqu√≠a** (suspenso-aprobado-notable).
  - **.bg-purple_light[Nominales]**: no tienen asociada una jerarqu√≠a (sexo, religi√≥n, color, etc).


* **.bg-purple_light[Cuantitativas]**: caracter√≠stica **.bg-orange[cuantificable num√©ricamente]**.

  - **.bg-purple_light[Discretas]**: se pueden contar y enumerar (aunque sean infinitos) (n¬∫ granos de arena, n¬∫ hermanos, etc).
  - **.bg-purple_light[Continuas]**: adem√°s de tomar infinitos valores, entre dos valores cualesquiera hay a su vez infinitas opciones (estatura, peso, etc).


]

---

# .orange[DISCRETA] vs .green[CONTINUAS]

```{r echo = FALSE,  out.width = "76%", fig.align = "center"}
knitr::include_graphics("./img/discreta_continua.jpg")
``` 

---

# Resumiendo informaci√≥n: .orange[MOMENTOS]

En estad√≠stica los **.bg-purple_light[momentos]** ser√°n par√°metros calculados a partir de los datos que, mediante una f√≥rmula, **.bg-purple_light[resumen num√©ricamente]** algunas caracter√≠sticas de nuestros datos:

--

* Medidas de **.bg-purple_light[centralizaci√≥n]**: en torno a qu√© valores se **concentran** los datos.

--

* Medidas de **.bg-purple_light[dispersi√≥n]**: cuantifican la **dispersi√≥n respecto al centro**.

--

* Medidas de **.bg-purple_light[posici√≥n/localizaci√≥n]**: c√≥mo se **localizan** los datos, valores que nos permiten segmentar nuestros datos en conjuntos de partes iguales (mismo % de datos, los famosos percentiles).

--

* Medidas de **.bg-purple_light[forma]**: nos complementan la caracterizaci√≥n de la distribuci√≥n, por ejemplo, indic√°ndonos la **direcci√≥n** en la que se desv√≠an los datos.


---

# Medidas de .orange[CENTRALIZACI√ìN]

Las **.bg-purple_light[medidas de centralizaci√≥n]** nos informan de los valores en torno a los que se **concentra** nuestra variable, un **.bg-purple_light[¬´representante¬ª]** de nuestra variable.

--

* **.bg-purple_light[Media]** (aritm√©tica, sin ponderar): definida como la suma de valores, dividida entre el tama√±o muestral. **.bg-red_light[Solo para cuantitativas]**

--

* **.bg-purple_light[Mediana]**: si ordenamos los datos de menor a mayor, el valor central (por debajo el 50%, por encima el 50%). **.bg-red_light[Solo si existe jerarqu√≠a de orden]**.

--

* **.bg-purple_light[Moda]**: el **valor o valores m√°s repetidos** de nuestra variable, lo m√°s frecuente. **.bg-red_light[Amodal]**: todos se repiten por igual -> no hay moda.


---

# .orange[MEDIA] aritm√©tica

.pull-left[

Dada una muestra, la **.bg-purple_light[media (aritm√©tica) muestral]** $\overline{x}$ se define como la suma de todos los valores dividida por el tama√±o muestral.

$$\overline{x} = \frac{1}{N} \sum_{i=1}^{N} x_i$$

Tambi√©n se puede definir como el **.bg-purple_light[valor ¬´m√°s cercano¬ª a todos los datos]** a la vez, minimizando las distancias (al cuadrado) de los datos a dicho valor.

]

.pull-right[

```{r echo = FALSE,  out.width = "89%", fig.cap = "Extra√≠da de instagram.com/javieralvarezliebana", fig.align = "left"}
knitr::include_graphics("./img/media.jpg")
``` 


]


---

# .orange[ROBUSTEZ] de la media

```{r echo = FALSE,  out.width = "43%", fig.cap = "Extra√≠da de instagram.com/javieralvarezliebana", fig.align = "center"}
knitr::include_graphics("./img/robustez.jpg")
``` 

---


# .orange[MEDIANA]


.pull-left[

Dada una muestra, la **.bg-purple_light[mediana muestral]** se define como el valor que es mayor o igual que al menos el 50%, y menor igual que al menos el 50% de los datos

$$Me_{x} = \displaystyle \arg \min_{x_i} \left\lbrace F_i > 0.5 \right\rbrace$$

En caso de $F_i = 0.5$ en variables discretas, realizaremos la media de $x_i$ y $x_{i+1}$.

]

.pull-right[

```{r echo = FALSE,  out.width = "89%", fig.cap = "Extra√≠da de instagram.com/javieralvarezliebana", fig.align = "left"}
knitr::include_graphics("./img/mediana.jpg")
``` 


]


---

# .orange[MODA]


.pull-left[

Dada una muestra, la **.bg-purple_light[moda muestral]** se define como el valor o valores m√°s repetidos (en caso de que existan)

$$Mo_{x} = \displaystyle \arg \max_{x_i} f_i$$

Podr√≠amos tener distribuciones **unimodales**, **bimodales**, **trimodales**...incluso **amodales**

]

.pull-right[

```{r echo = FALSE,  out.width = "89%", fig.cap = "Extra√≠da de instagram.com/javieralvarezliebana", fig.align = "left"}
knitr::include_graphics("./img/moda.jpg")
``` 


]

---

# .orange[ROBUSTEZ]

**.bg-green_light[¬øCu√°l es cu√°l?]**

```{r echo = FALSE,  out.width = "70%", fig.align = "center"}
knitr::include_graphics("./img/ine_salarios.jpg")
``` 


---

# Medidas de .orange[DISPERSI√ìN]

```{r echo = FALSE,  out.width = "45%", fig.align = "center"}
knitr::include_graphics("./img/iker.jpg")
``` 

--

El cambio clim√°tico, un problema de dispersi√≥n

---

# Medidas de .orange[DISPERSI√ìN]

```{r echo = FALSE,  out.width = "70%", fig.align = "center"}
knitr::include_graphics("./img/fenom_extremos.jpg")
``` 

El cambio clim√°tico, un **.bg-purple_light[problema de dispersi√≥n]**

---

# Medidas de .orange[DISPERSI√ìN]

.pull-left[

Una primera idea podr√≠a ser **.bg-purple_light[medir la distancia de cada dato al centro]**, es decir, restar cada dato de la media, y despu√©s realizar su promedio.

$$\frac{1}{N} \sum_{i=1}^{N} \left(x_i - \overline{x} \right)$$

**.bg-red_light[¬øProblema?]**

]

.pull-right[

```{r echo = FALSE,  out.width = "99%", fig.align = "center"}
knitr::include_graphics("./img/distancia_var.jpg")
``` 

]

--

&nbsp;

Imagina que tenemos $X = \left\lbrace -5, -3, -1, 0, 1, 3, 5 \right\rbrace$: la media es 0, y el promedio de las distancias a la media tambi√©n ya que se **.bg-red_light[cancelan los signos]**.

**.bg-green_light[¬øSoluci√≥n?]**

---

# Medidas de .orange[DISPERSI√ìN]

En matem√°ticas suele ser **desaconsejable usar el valor absoluto** (dado que es una funci√≥n no derivable), as√≠ que lo que haremos ser√° calcula el **.bg-purple_light[promedio de las distancias al cuadrado]**


$$s_{x}^{2} = \frac{1}{N} \sum_{i=1}^{N} \left(x_i - \overline{x} \right)^2 = \overline{x^2} - \overline{x}^2$$

--

Esta medida de dispersi√≥n es lo que conocemos como **.bg-purple_light[VARIANZA muestral]**.

--

**.bg-red_light[CUIDADO]**: tanto `R` como el resto de software nos devolver√°n la cuasivarianza $S_{x}^{2}$ (promedio entre $N-1$, no entre $N$), ya que es el **estimador insesgado** de la varianza poblacional $\sigma_{x}^2$: asumimos que los estimadores casi nunca coincidir√°n con su valor te√≥rico pero si repetimos el experimento un n√∫mero suficiente de veces, su promedio si tender√° a √©l.

$${\rm E} [\overline{x}] = \mu, \quad {\rm E} [S_{x}^{}] = \sigma_{x}^{2}$$



---

# Medidas de .orange[DISPERSI√ìN]


**.bg-red_light[¬øProblema?]**

--

```{r echo = FALSE,  out.width = "70%", fig.align = "center"}
knitr::include_graphics("./img/albert_rivera.jpg")
``` 

Necesitamos una medida de dispersi√≥n en las **unidades de los datos**.

---

# Medidas de .orange[DISPERSI√ìN]


Para tener una **.bg-purple_light[medida de dispersi√≥n en las unidades]** de los datos calcularemos la **.bg-purple_light[desviaci√≥n t√≠pica]**, como la ra√≠z cuadrada de la varianza


$$s_{x} = \sqrt{s_{x}^{2}} = \sqrt{\frac{1}{N} \sum_{i=1}^{N} \left(x_i - \overline{x} \right)^2} = \sqrt{\overline{x^2} - \overline{x}^2}$$
--

Imaginemos entonces que tenemos dos conjuntos de datos: estaturas (de 165 a 175 cm) y di√°metros de n√∫cleos de c√©lulas (de 3 a 7 micr√≥metros). Si obtenemos una  desviaci√≥n t√≠pica de 1 cm y 1.5 micr√≥metros, **.bg-purple_light[¬øcu√°l es m√°s dispersa?]**

--

&nbsp;

¬ø**.bg-red_light[NO podemos comparar]** varianzas y desviaciones t√≠picas? 

---

# Medidas de .orange[DISPERSI√ìN]


```{r echo = FALSE,  out.width = "80%", fig.align = "center"}
knitr::include_graphics("./img/sorry.jpg")
``` 


**.bg-red_light[NO podemos comparar]** ni varianzas ni desviaciones t√≠picas: dependen de la magnitud y unidades de los datos.

---

# Medidas de .orange[DISPERSI√ìN]

Para tener una **.bg-purple_light[medida de dispersi√≥n adimensional]** que podamos comparar en distintos conjuntos de datos calcularemos el **.bg-purple_light[coeficiente de variaci√≥n]**, como la desv. t√≠pica entre el valor absoluto de la media


$$CV_{x} = \frac{s_{x}}{\left| \overline{x} \right|}$$

---

# Medidas de .orange[LOCALIZACI√ìN/POSICI√ìN]


Las **.bg-purple_light[medidas de posici√≥n]** nos **localizan** los datos: son **.bg-purple_light[valores que nos dividen]** un conjunto ordenado en un n√∫mero de tramos con el mismo tama√±o muestral. Ejemplo: la mediana es el percentil $P_{50}$, el decil $D_{5}$ y el cuartil $C_{2}$ o $q_2$.

* **.bg-purple_light[Percentil]**: valores $P_{\alpha}$ del conjunto ordenado que dejan por debajo, al menos, el $\alpha  \%$ de datos y el $(100-\alpha) \%$ por encima.   


* **.bg-purple_light[Decil]**: valores $D_{\alpha}$ del conjunto ordenado que dividen los datos en 10 partes iguales, que dejan por debajo, al menos, el $10*\alpha  \%$ de datos y el $(100-10*\alpha) \%$ por encima.   


* **.bg-purple_light[Cuartil]**: valores $C_{\alpha}$ o $q_{\alpha}$ del conjunto ordenado que dividen los datos en 4 partes iguales, que dejan por debajo, al menos, el $25*\alpha  \%$ de datos y el $(100-25*\alpha) \%$ por encima.   

---

class: inverse center middle
name: clase-3

# CLASE 3: Tidydata

&nbsp;


### [Estructuras de control](#estructuras-condicionales)

### [Tidydata](#tidydata)

### [Comunicando resultados](#rmd)

### [Caso pr√°ctico: datos de la OMS](#oms)


---

name: estructuras-condicionales

# Estructuras de control: .orange[IF-ELSE]


Una **.bg-purple_light[expresi√≥n de control]** ser√° un conjunto de √≥rdenes que nos permiten **.bg-purple_light[decidir el camino]** por el que queremos que avance nuestro c√≥digo:

* ¬øQu√© hacemos si sucede A?

* ¬øY si sucede B?

* ¬øTengo que programar X veces lo mismo si quiere que se repita?

&nbsp;

Si has programado en alg√∫n otro lenguaje, estar√°s familiarizado/a con **.bg-purple_light[estructuras condicionales]** como un `if (blabla) {...} else {...}` (que los usaremos a veces) o **.bg-purple_light[bucles]** `for/while` (que intentaremos evitarlos lo m√°ximo posible).

---

# Estructuras de control: .orange[IF]

Una de las estructuras de control m√°s famosas de cualquier lenguaje de programaci√≥n es la **.bg-purple_light[estructura condicional]** `if`

> SI las condiciones impuestas se cumplen (TRUE), ejecuta las √≥rdenes que tengamos dentro de la misma.

Por ejemplo, la estructura `if (x == 1) { c√≥digo A }` lo que har√° ser√° **.bg-purple_light[ejecutar el c√≥digo entre llaves]** pero **.bg-orange[SI Y SOLO SI]** la **.bg-purple_light[condici√≥n es cierta]** (en este caso, solo si `x` es igual 1). En **caso contrario, no hace nada**.

--

Definamos por ejemplo una variable sencilla, las edades de 8 personas y comprobemos cuales son menores de edad.

```{r}
edades <- c(14, 17, 24, 56, 31, 20, 87, 73)
edades < 18
```

---

# Estructuras de control: .orange[IF]


Recuerda que con las funciones `any()` y `all()` podemos saber si **.bg-purple_light[todos o alguno de los elementos]** de un vector cumplen una condici√≥n.

```{r}
any(edades < 18) # existe algun menor de edad
```

--

Con dichos elementos vamos a construir nuestra primera estructura condicional: queremos que, **.bg-purple_light[SI existe alg√∫n menor de edad, nos imprima un mensaje]**.

```{r}
if (any(edades < 18)) { 
  
  print("existe alguna persona mayor de edad")
  
}
```

---

# Estructuras de control: .orange[IF]

```{r eval = FALSE}
if (any(edades < 18)) { 
  
  print("existe alguna persona mayor de edad")
  
}
```


En caso de que **.bg-purple_light[no se cumplan las condiciones]** dentro del `if()` (FALSE), no suceder√° nada. 


```{r}
if (all(edades >= 18)) { 
  
  print("todas las personas son mayores de edad")
  
}
```

F√≠jate que en este caso **no hemos obtenido ning√∫n mensaje** porque la condici√≥n `all(edades >= 18)` no es cierta (no son todos mayores de 18 a√±os), as√≠ que **no ha ejecutado el c√≥digo**.

---

# Estructuras de control: .orange[IF-ELSE]

La estructura `if (condicion) { }` puede ser combinada con un `else { }`: cuando la **.bg-purple_light[condici√≥n no se cumpla]** (como en el √∫ltimo ejemplo), se **.bg-purple_light[ejecutar√° el c√≥digo alternativo]** que haya dentro del `else { }`, permiti√©ndonos decidir que sucede cuando S√ç se cumple y cuando NO se cumple.

--

Por ejemplo, la estructura `if (x == 1) { c√≥digo A } else { c√≥digo B }` ejecutar√° A si `x` es 1 y B en cualquier otro caso.

```{r}
if (all(edades >= 18)) { 
  
  print("todas las personas son mayores de edad")
  
} else { #<<
  
  print("existe alguna persona menor de edad")
}
```

---

# Estructuras de control: .orange[IF-ELSE]

Dicha estructura `if - else` puede **.bg-purple_light[anidarse]**: imagina que queremos realizar una acci√≥n si todos fuesen mayores de edad; en caso contrario, pero si todos los menores tienen 16 a√±os o m√°s, realizar otra acci√≥n; en caso contrario, otra acci√≥n

```{r}
if (all(edades >= 18)) { 
  
  print("todas las personas son mayores de edad")
  
} else if (all(edades >= 16)) {
  
  print("Existe alguna persona menor de edad pero todos con 16 a√±os o m√°s")
  
} else { print("Existe alguna persona menor de 16 a√±os") }
```

**.bg-green_light[CONSEJO]**: puedes **colapsar las estructuras de control** pulsando en la flecha que aparece a la izquierda de ellas en tu script.


---

# Estructuras de control: .orange[IFELSE()]


Esta estructura condicional puede ser **.bg-purple_light[vectorizada]**: reunir en una sola fila un n√∫mero elevado de estructuras de comparaci√≥n con la funci√≥n `ifelse()`, cuyos argumentos de entrada ser√°n

* la condici√≥n a evaluar
* lo que sucede cuando se cumple
* lo que sucede cuando no se cumple

Con el ejemplo de las edades, vamos a dejar el dato ausente si son menores de edad, y si son mayores de edad se queda como est√°.

```{r}
# NA si no cumple la condici√≥n, la edad si se cumple.
ifelse(edades >= 18, edades, NA) #<<
```

---

# Estructuras de control: .orange[IFELSE()]


Todas estas estructuras **.bg-purple_light[no solo sirven para datos num√©ricos]**. Vamos a definir un vector de nombres con algunos ausentes, y vamos a sustituir los ausentes por el texto `"nombre_desconocido"` (los que no sean ausentes, es decir los que `is.na()` devuelva FALSE, se quedan como est√°n).

```{r}
nombres <- c("Juan", "Mar√≠a", NA, NA, "Luc√≠a",
             "Carmen", "Javier", NA, "Carlos", 
             NA, "Gregorio", "Paloma")

# Si tiene ausente --> "nombre_desconocido"
# Si no tiene ausente --> nombres originales
nombres <-
  ifelse(is.na(nombres), "nombre_desconocido", nombres)
nombres
```

---

name: bucles

# Estructuras de control: .orange[BUCLES]

Aunque la mayor√≠a de veces son sustituibles por otras expresiones m√°s legibles y eficientes, es importante que conozcamos otra archiconocida expresion de control: **.bg-purple_light[los bucles]**.

* `for { }`: permite **.bg-purple_light[repetir el mismo c√≥digo]** un **.bg-orange[n√∫mero fijo y conocido]** de veces (normalmente en funci√≥n de un √≠ndice).

* `while { }`: permite **.bg-purple_light[repetir el mismo c√≥digo]** un **.bg-orange[n√∫mero indeterminado de veces]**, hasta que una **condici√≥n** dada se deje de cumplir.

---

# Estructuras de control: .orange[BUCLES FOR]

Un **.bg-purple_light[bucle for]** es una estructura que nos permite **.bg-purple_light[repetir]** un conjunto de √≥rdenes un **.bg-orange[n√∫mero finito y conocido]** de veces: dado un **conjunto de √≠ndices**, el bucle ir√° recorriendo cada uno de ellos.

Vamos a definir un vector `x`. Si quisi√©ramos el primer elemento al cuadrado escribir√≠amos `x[1]^2`; si quisi√©ramos el segundo elemento al cuadrado `x[2]^2`; si lo quisi√©ramos hacer en general, para el elemento i-√©simo, `x[i]^2`. Lo que haremos dentro del `for (indices) { √≥rdenes }` es indicarle que valores ir√° tomando `i` (**.bg-purple_light[vector de √≠ndices]**).

```{r}
x <- c(0, -7, 1, 4)
for (i in 1:4) { #<<
  
  print(x[i]^2) # √≥rdenes
  
}
```

---

# Estructuras de control: .orange[BUCLES FOR]

```{r eval = FALSE}
for (i in 1:4) { #<<
  print(x[i]^2) # √≥rdenes
}
```

Lo que tenemos dentro de los par√©ntesis `for ()` no es m√°s que la **.bg-purple_light[secuencia de n√∫meros]** que hemos aprendido a construir. Si quisi√©ramos que haga lo mismo pero excluyendo por ejemplo el segundo elemento bastar√≠a con definir los √≠ndices a recorrer como `c(1, 3, 4)`.

```{r}
for (i in c(1, 3, 4)) {
  
  print(x[i]^2) # que lo imprima
  
}
```

---

# Estructuras de control: .orange[BUCLES FOR]

Podemos definir tambi√©n una variable `y <- rep(0, 4)` (un **vector ¬´vac√≠o¬ª** lleno de ceros), y hacer que el **.bg-purple_light[elemento i-√©simo del vector]** se defina como `x[i]^2`

```{r}
y <- rep(0, 4)
for (i in 1:4) {
  
  y[i] <- x[i]^2
  
}
y
```

--

Lo anterior es equivalente a esto

```{r}
y <- x^2
y
```

---

# .orange[BUCLES] suelen ser .red[INEFICIENTES]


Haciendo uso del paquete `microbenchmark` podemos comprobar como los **.bg-purple_light[bucles son menos eficientes]** (de ah√≠ que la mayor√≠a de veces los intentemos evitar si existe otra alternativa)

```{r}
library(microbenchmark)
x <- 1:100
microbenchmark(x^2, 
               for (i in 1:100) { y[i] <- x[i]^2 },
               times = 1000)
```

---
 
# Estructuras de control: .orange[BUCLES FOR]


Veamos otro ejemplo **.bg-purple_light[combinando vectores num√©ricos y de caracteres]**: vamos a definir de nuevo un vector de edades y nombres, y vamos a recorrer cada uno imprimiento un mensaje por pantalla.

```{r}
nombres <- c("Javi", "Laura", "Carlos", "Luc√≠a", "Mar")
edades <- c(33, 51, 18, 43, 29)

# Recorremos cada uno de los 5 elementos e imprimimos un
# mensaje que depende de ese √≠ndice i
for (i in 1:5) { 
  
  print(glue("{nombres[i]} tiene {edades[i]} a√±os")) 
  
}
```

---

# Estructuras de control: .orange[BUCLES FOR]

F√≠jate que **.bg-purple_light[si no nos queremos preocupar de si a√±adimos otra persona]**, podemos hacer que el bucle empiece en 1 y termine en el **.bg-purple_light[√∫ltimo lugar]** (sea el que sea), usando `length()`.

```{r}
for (i in 1:length(nombres)) { 
  
  print(glue("{nombres[i]} tiene {edades[i]} a√±os")) 
  
}
```

---

# Estructuras de control: .orange[BUCLES FOR]

Aunque normalmente el conjunto que recorre el bucle suelen ser √≠ndices num√©ricos, podemos **.bg-purple_light[recorrer cualquier tipo de objeto]**, por ejemplo d√≠as e la semana

```{r}
library(stringr)
dias_semana <- c("lunes", "martes", "mi√©rcoles", "jueves",
                 "viernes", "s√°bado", "domingo")

for (dias in dias_semana) { # dias recorre los d√≠as de la semana
  
  print(str_to_upper(dias)) # Imprimimos en may√∫sculas el d√≠a
}
```

---

# Estructuras de control: .orange[BUCLES FOR]

Un √∫ltimo ejemplo: vamos a recorrer nuestro conjunto de datos `swiss` del paquete `{datasets}` y vamos a **pasar a dato ausente** todos los valores de fertilidad superiores a 80. Para ello recorreremos cada fila para despu√©s ejecutar un `if`.

```{r}
for (i in 1:nrow(swiss)) {
  
  # si cumple la condici√≥n dicha fila, ponemos ausente.
  if (swiss$Fertility[i] > 80) { 
    
    swiss$Fertility[i] <- NA
    
  }
}
```

--

Esto ser√≠a exactamente equivalente al `ifelse()` vectorizado que vimos en el tema anterior

```{r}
data("swiss") # lo cargamos de 0
swiss$Fertility <- ifelse(swiss$Fertility > 80, NA, swiss$Fertility)
```


---

# Estructuras de control: .orange[BUCLES WHILE]

Otra manera de dise√±ar un bucle es con la estructura `while { }`, que ejecutar√° el bucle un **.bg-purple_light[n√∫mero de veces a priori  desconocido]**, lo har√° hasta que la **.bg-purple_light[condici√≥n impuesta deje de ser cierta]**. Por ejemplo, vamos a inicializar una variable `ciclos <- 1`, y en cada paso aumentaremos una unidad, y no saldremos del bucle hasta que `ciclos > 4`

```{r}
ciclos <- 1

# Mientras el n√∫mero de ciclos sea inferior 4, imprime
while(ciclos <= 4) {
  
  print(paste("Todav√≠a no, vamos por el ciclo ", ciclos)) # Pegamos la frase al n√∫mero de ciclo por el que vayamos con paste
  ciclos <- ciclos + 1
  
}
```


---
  
# Estructuras de control: .orange[BUCLES WHILE]


¬øY qu√© sucede cuando la **.bg-purple_light[condici√≥n nunca llega a ser FALSE]**? Compru√©balo t√∫ mismo/a.

```{r eval = FALSE}
while (1 > 0) { # Nunca va a dejar de ser cierto
  
  print("Presiona ESC para salir del bucle")
  
}
```

&nbsp;

**.bg-red_light[CUIDADO]**: un bucle `while { }` puede ser muy peligroso sino se controla bien que el bucle acaba en alg√∫n momento.

---

# Estructuras de control: .orange[BUCLES WHILE]

Tenemos dos comandos reservados para poder **.bg-purple_light[abortar un bucle o avanzar forzosamente]**:

* `break`: os habilita para **.bg-purple_light[parar un bucle]** aunque no haya llegado al final de su conjunto de √≠ndices a recorrer (o se siga cumpliendo la condici√≥n).

```{r}
for(i in 1:10) {
  if (i == 3) {
    
    break # si i es 3, el bucle frena aqu√≠
    
  }
  print(i)
}
```

---

# Estructuras de control: .orange[BUCLES WHILE]

Tenemos dos comandos reservados para poder **.bg-purple_light[abortar un bucle o avanzar forzosamente]**:

* `next`: **.bg-purple_light[obliga al bucle a avanzar]** a la siguiente iteracci√≥n, abortando la iteraci√≥n actual en la que se encuentra. 

```{r}
for(i in 1:5) {
  if (i == 3) {
    
    next # si i es 3, pasar√° a la siguiente
    
  }
  print(i)
}
```

---



# Ejercicios

.panelset[
.panel[.panel-name[Ejercicios]


* üìù **Ejercicio 1**: modifica el c√≥digo inferior para imprimir un mensaje por pantalla si todos los datos del conjunto `airquality` son de meses que no sean enero.

```{r eval = FALSE}
# install.packages("dataset") # solo la primera vez
library(datasets) # paquete con los datos
mes <- airquality$Month

if (mes == 2) {
  
  print("Ning√∫n dato es del mes de enero")
  
}
```

]

.panel[.panel-name[Soluci√≥n ej. 1]

* üìù **Ejercicio 1**: modifica el c√≥digo inferior para imprimir un mensaje por pantalla si todos los datos del conjunto `airquality` son de meses que no sean enero.

```{r}
# install.packages("dataset") # solo la primera vez
library(datasets) # paquete con los datos
mes <- airquality$Month

if (all(mes != 1)) {
  
  print("Ning√∫n dato es del mes de enero")
  
}
```

]

]


---

# Ejercicios

.panelset[
.panel[.panel-name[Ejercicios]

* üìù **Ejercicio 2**: modifica el c√≥digo inferior para guardar en una variable llamada `temperatura_alta` un valor `TRUE` si alguno de los registros tiene una temperatura mayor a 90 (est√°n en Farenheit) y un `FALSE` en caso contrario.
 
```{r eval = FALSE}
temperatura <- airquality$Temp

if (temperatura == 100) {
  
  print("Alguno de los registros tiene temperatura superior a 90 Farenheit")
  
}
```

]

.panel[.panel-name[Soluci√≥n ej. 2]

* üìù **Ejercicio 2**: modifica el c√≥digo inferior para guardar en una variable llamada `temperatura_alta` un valor `TRUE` si alguno de los registros tiene una temperatura mayor a 90 (est√°n en Farenheit) y un `FALSE` en caso contrario.
 
```{r eval = FALSE}

# Opci√≥n 1
temperatura <- airquality$Temp
temperatura_alta <- FALSE
if (any(temperatura > 90)) {
  
   temperatura_alta <- TRUE
  
}

# Opci√≥n 2
temperatura_alta <- any(airquality$Temp > 90)
```


]

]

---


# Ejercicios

.panelset[
.panel[.panel-name[Ejercicios]

* üìù **Ejercicio 3**: modifica el c√≥digo inferior para dise√±ar un bucle `for` de 5 iteraciones que recorra los 5 primeros impares y les sume uno.

```{r eval = FALSE}
for (i in 1:5) {
  
  print(i)
}
```

* üìù **Ejercicio 4**: modifica el c√≥digo inferior para dise√±ar un bucle `while` que parta con una variable `conteo <- 1` y pare cuando llegue a 6.

```{r eval = FALSE}
conteo <- 1
while (conteo == 2) {
  
  print(conteo)
}
```

]

.panel[.panel-name[Soluci√≥n ej. 3]

* üìù **Ejercicio 3**: modifica el c√≥digo inferior para dise√±ar un bucle `for` de 5 iteraciones que recorra los 5 primeros impares y les sume uno.

```{r}
for (i in c(1, 3, 5, 7, 9)) {
  
  print(i + 1)
}
```

]

.panel[.panel-name[Soluci√≥n ej. 4]

* üìù **Ejercicio 4**: modifica el c√≥digo inferior para dise√±ar un bucle `while` que parta con una variable `conteo <- 1` y pare cuando llegue a 6.

```{r}
conteo <- 1
while (conteo < 6) {
  
  print(conteo)
  conteo <- conteo + 1
  
}
```

]

]

---

# Ejercicios

.panelset[
.panel[.panel-name[Ejercicios]

* üìù **Ejercicio 5**: dise√±a un bucle `for` de 200 iteraciones que, empezando en un valor inicial de 100 (euros), te sume 3‚Ç¨ (actualizando el valor) si el n√∫mero actual de la iteraci√≥n es par, y te reste 5‚Ç¨ si es impar (investiga la funci√≥n `%%`).

* üìù **Ejercicio 6**: dise√±a el anterior bucle pero guardando el dinero de cada iteraci√≥n en alguna variable
 

* üìù **Ejercicio 7**: dise√±a el bucle del ejercicio 5 pero parando cuando no nos quede dinero.

]

.panel[.panel-name[Sol. ej. 5]

Un n√∫mero par ser√° todo aquel n√∫mero que al dividir entre 2, la divisi√≥n es exacta, es decir, que su resto es nulo. Para calcular ese resto usaremos la funci√≥n `%%`.


```{r}
# dinero inicial
dinero <- 100

for (i in 1:200) {
  
  dinero <- ifelse(i %% 2 == 0, dinero + 3, dinero  - 5)
  
}
dinero
```

]

.panel[.panel-name[Sol. ej. 6]

```{r}
# vector inicial de importes
dinero <- rep(0, 201)
dinero[1] <- 100 # dinero inicial

# Bucle for
for (i in 2:201) {
  
  # si i es par o  impar
  dinero[i] <- ifelse(i %% 2 == 0, dinero[i - 1] + 3,
                      dinero[i - 1]  - 5)
  
}
dinero
```

]

.panel[.panel-name[Sol. ej. 7]

```{r}
dinero <- 100 # dinero inicial

# Bucle while
while (dinero > 0) {
  
  dinero <- ifelse(i %% 2 == 0, dinero + 3, dinero - 5)
  
}
dinero
```

]


]


---

name: tidydata

# Datos limpios: .orange[TIDY DATA]

.pull-left[

```{r echo = FALSE,  out.width = "99%", fig.align = "center"}
knitr::include_graphics("./img/tidyverrse_universe.jpg")
``` 

]

.pull-right[
```{r echo = FALSE,  out.width = "99%", fig.align = "center"}
knitr::include_graphics("./img/flow_tidyverse.jpg")
``` 
]

Universo de **.bg-purple_light[paquetes tidyverse]**: un conjunto de paquetes para un flujo de **trabajo eficiente, coherente y lexicogr√°ficamente** sencillo de entender.

---

# Datos limpios: .orange[TIDY DATA]

> Tidy datasets are all alike, but every messy dataset is messy in its own way (Hadley Wickham, Chief Scientist en RStudio)

Hasta ahora solo le hemos dado importancia al ¬´qu√©¬ª pero no al **.bg-purple_light[¬´c√≥mo¬ª manejamos los datos]**. La organizaci√≥n de nuestros datos es fundamental para que su **.bg-purple_light[preparaci√≥n y explotaci√≥n]** sea lo m√°s eficiente posible.

```{r echo = FALSE,  out.width = "60%", fig.align = "center", fig.cap = "Flujo deseable de datos seg√∫n Hadley Wickham, extra√≠da de https://r4ds.had.co.nz/wrangle-intro.html"}
knitr::include_graphics("./img/tidy_flow.jpg")
``` 


---

# Datos limpios: .orange[TIDY DATA]

El concepto **.bg-purple_light[tidy data]** fue introducido por **Hadley Wickham** (Wickham, 2014) como el primer paso de un flujo de trabajo eficiente. Para ello haremos uso del paquete `{tidyr}` (dentro de `{tidyverse}`) que nos proporciona herramientas eficientes y sencillaspara su manejo.

&nbsp;

Los **.bg-purple_light[conjuntos tidy u ordenados]** tienen tres objetivos

* **.bg-orange[Estandarizaci√≥n]** en su estructura para una depuraci√≥n y an√°lisis eficiente.
* **.bg-orange[Sencillez]** en su manipulaci√≥n.
* Listos para ser **.bg-orange[modelizados y visualizados]**.

&nbsp;

üìö Ver Wickham (2014) en **.bg-green_light[bibliograf√≠a]** en <https://github.com/dadosdelaplace/teaching/tree/main/data_mining/biblio>

---

# Datos limpios: .orange[TIDY Dblob/main/data_mining/biblio/tidy_data_wickham_2014.pdfbg-purple_light[datos ordenados o tidy data]** deben cumplir:

1. Cada **.bg-green_light[variable en una columna]**.

2. Cada **.bg-orange[observaci√≥n/individuo en una fila]** diferente.

3. Cada **.bg-green_light[celda con un √∫nico valor]**.

4. Cada **.bg-orange[conjunto en un tibble]** (tabla).

5. Si usamos m√∫ltiples tablas a la vez debemos tener una **.bg-green_light[columna com√∫n para poder cruzarlas]**.

]

.pull-right[

```{r echo = FALSE,  out.width = "85%", fig.align = "center"}
knitr::include_graphics("./img/tidy_def.jpg")
``` 

&nbsp;

```{r echo = FALSE,  out.width = "53%", fig.align = "center"}
knitr::include_graphics("./img/tidyr_1.jpg")
``` 


]


---

# Tuber√≠a .orange[PIPE]

En este entorno de trabajo tendremos un **.bg-purple_light[operador clave]**: el **.bg-purple_light[operador pipeline]** `%>%` (podemos usar el atajo con `ctrl+shift+M` o `command+shift+M`). Dicho operador lo debemos interpretar como una **.bg-purple_light[tuber√≠a]** que va pasando por los datos y los va transformando.


Por ejemplo, si tuvi√©semos tres funciones `first()`, `second()` y `third()`, la opci√≥n m√°s inmediata ser√≠a anidar las tres funciones tal que `third(second(first(x)))`, algo que dificulta la lectura posterior del c√≥digo

--

Con `%>%` podremos escribir (y leer) la concetanci√≥n de acciones como una **.bg-purple_light[tuber√≠a de izquierda a derecha]**:

```{r eval = FALSE}
first(x) %>% second(x) %>% third(x)
```

--

Dicho operador viene del paquete `{magrittr}`. Para **evitar esta dependencia** (cuantos menos paquetes tengamos que cargar, mejor), desde la versi√≥n 4.1.0 de R, disponemos de un pipeline nativo de R, el **operador** `|>` (disponible adem√°s fuera del entorno tidyverse).

---

# Tuber√≠a .orange[PIPE]

.pull-left[

```{r eval = FALSE}
datos %>%
  limpio(...) %>%
  selecciono(...) %>%
  filtro(...) %>%
  ordeno(...) %>%
  agrupo(...) %>%
  cuento(...) %>%
  resumo(...) %>% 
  pinto(...)
```

```{r eval = FALSE}
datos |>
  limpio(...) |>
  selecciono(...) |>
  filtro(...) |>
  ordeno(...) |>
  agrupo(...) |>
  cuento(...) |>
  resumo(...) |>
  pinto(...)
```

]

.pull-right[

```{r echo = FALSE,  out.width = "90%", fig.align = "center"}
knitr::include_graphics("./img/tuberia.jpg")
``` 

]

---

# Datos .orange[SUCIOS]: messy data

Por ejemplo, vamos a cargar la tabla `table4a` del paquete `{tidyr}` (que ya lo tenemos cargado del entorno `{tidyverse}`).

```{r echo = FALSE}
library(tidyverse)
```

```{r}
table4a
```

**.bg-purple_light[¬øQu√© falla?]**

---


# Datos .orange[SUCIOS]: messy data

.pull-left[

```{r echo = FALSE}
library(tidyverse)
```

```{r}
table4a
```

**.bg-purple_light[¬øQu√© falla?]**

]

.pull-right[


‚ùé Cada **.bg-green_light[variable en una columna]**.

‚ùé Cada **.bg-orange[observaci√≥n/individuo en una fila]** diferente.

‚ùé Cada **.bg-green_light[celda con un √∫nico valor]**.

]

Aunque la columna `$country` representa una variable, las otras columnas no: **.bg-purple_light[ambas son la misma variable]**, solo que medida en a√±os distintos (que deber√≠a ser a su vez otra variable), de forma que **.bg-purple_light[cada fila est√° representando dos observaciones]** (1999, 2000). Tenemos datos en los nombres de las columnas.


---

# Datos .orange[SUCIOS]: messy data


.pull-left[

Lo que haremos ser√° incluir una nueva columna llamada (por ejemplo) `year` que nos marque el a√±o y otra llamada `cases` que nos diga el valor de la variable de inter√©s en cada uno de esos a√±os.

]

.pull-right[

```{r echo = FALSE,  out.width = "65%", fig.align = "center"}
knitr::include_graphics("./img/table4a.jpg")
``` 


]

--

Con la funci√≥n `pivot_longer()` pivotaremos la tabla para pasarla a **formato long**:

```{r}
table4a %>%
  pivot_longer(cols = c("1999", "2000"), names_to = "year", values_to = "cases") #<<
```

---

# Datos .orange[SUCIOS]: messy data

.pull-left[

```{r eval = FALSE}
table4a %>%
  pivot_longer(cols = c("1999", "2000"),
               names_to = "year", 
               values_to = "cases") #<<
```

]

.pull-right[

```{r echo = FALSE,  out.width = "110%", fig.align = "center"}
knitr::include_graphics("./img/table4a_2.png")
``` 


]


* `cols`: el **.bg-purple_light[nombre de las columnas a pivotar]** (con comillas por ser n√∫meros y no caracteres).
* `names_to`: el **.bg-purple_light[nombre de la nueva columna]** a la mandamos los **.bg-purple_light[nombres]** de las columnas.
* `values_to`: el **.bg-purple_light[nombre de la nueva columna]** a la que vamos a mandar los **.bg-purple_light[datos]**.


---

# Datos .orange[SUCIOS]: messy data

Echa un vistazo a la tabla `{table4b}`

```{r}
table4b
```

**.bg-purple_light[TODO TUYO]**: ¬øes tidy o messy? ¬øC√≥mo convertirla a tidy data en caso de que no lo sea ya?


---

# Datos .orange[SUCIOS]: messy data

Echa un vistazo a la tabla `{relig_income}`

```{r}
relig_income
```

**.bg-purple_light[TODO TUYO]**: ¬øes tidy o messy? ¬øC√≥mo convertirla a tidy data en caso de que no lo sea ya?

---

# Datos .orange[SUCIOS]: messy data

Veamos un segundo tipo de dato sucio: vamos a cargar la tabla `table2` del paquete `{tidyr}` (que ya lo tenemos cargado del entorno `{tidyverse}`). **.bg-purple_light[¬øQu√© falla?]**


```{r}
table2
```


---

# Datos .orange[SUCIOS]: messy data

.pull-left[


```{r}
head(table2)
```

]

.pull-right[


```{r echo = FALSE,  out.width = "69%", fig.align = "center"}
knitr::include_graphics("./img/table2.jpg")
``` 
]


‚ùé Cada **.bg-orange[observaci√≥n/individuo en una fila]** diferente.


F√≠jate en las cuatro primeras filas: los registros con el mismo a√±o deber√≠an ser el mismo, es la misma informaci√≥n, **.bg-purple_light[deber√≠a estar en la misma fila]**, pero est√° dividada en dos. 

---


# Datos .orange[SUCIOS]: messy data

Lo que haremos ser√° lo opuesto a antes: con `pivot_wider()` ¬´ampliaremos¬ª la **.bg-purple_light[tabla a lo ancho]**, con menos filas pero con m√°s columnas.

```{r}
table2 %>%
  pivot_wider(names_from = type, values_from = count) #<<
```

* `names_from`: el **.bg-purple_light[nombre de la columna original]** de la que vamos a sacar las **.bg-purple_light[nuevas columnas]** que vamos a crear (`cases` y `population`).
* `values_from`: el **.bg-purple_light[nombre de la columna orignal]** de la que vamos a sacar los **.bg-purple_light[datos]**.


---

# Datos .orange[SUCIOS]: messy data


Por √∫ltimo veamos un tercer tipo de dato sucio: vamos a cargar la tabla `table3` del paquete `{tidyr}` (que ya lo tenemos cargado del entorno `{tidyverse}`). **.bg-purple_light[¬øQu√© falla?]**


```{r}
table3
```

--

‚ùé Cada **.bg-green_light[celda con un √∫nico valor]**.


---

# Datos .orange[SUCIOS]: messy data

Lo que haremos ser√° usar `separate()` para mandar **.bg-purple_light[cada valor a una columna diferente]**.

```{r}
table3 %>% separate(rate, into = c("cases", "pop")) #<<
```

* `into`: **.bg-purple_light[nombre de nuevas columnas]** donde separaremos valores.


```{r echo = FALSE,  out.width = "40%", fig.align = "center"}
knitr::include_graphics("./img/seperate.jpg")
``` 


---

# Datos .orange[SUCIOS]: messy data


Por defecto lo que hace es **.bg-purple_light[localizar como separador cualquier caracter que no sea alfa-num√©rico]**. Si queremos un caracter concreto para dividir podemos indic√°rselo expl√≠citamente. Si usas un separador que no est√° en los datos te devolver√° dichas columnas vac√≠as ya que no ha podido dividirlas.


```{r warning = TRUE}
table3 %>% separate(rate, into = c("cases", "population"), sep = ".")
```

---

# Datos .orange[SUCIOS]: messy data

De la misma manera que podemos separar columnas tambi√©n podemos **.bg-purple_light[unir columnas]**. Para ello vamos a usar la tabla `table5` del ya mencionado paquete.

```{r}
table5
```

---

# Datos .orange[SUCIOS]: messy data

.pull-left[

Con la funci√≥n `unite()` vamos a **.bg-purple_light[unir]** el siglo (en `century`) y el a√±o (en `year`), y al inicio le indicaremos como se llamar√° la nueva variable `year_ok`

```{r}
table5 %>%
  unite(col = year_ok,
        century, year, sep = "")
```

]

.pull-right[

```{r echo = FALSE,  out.width = "99%", fig.align = "center"}
knitr::include_graphics("./img/unite.jpg")
``` 

]


---

# Eliminando .orange[AUSENTES]

El paquete `{tidyr}` tambi√©n dispone de algunas herramientas √∫tiles para **.bg-purple_light[quitar ausentes]**

```{r}
datos <- tibble(x = c(1, 2, NA), y = c("a", NA, "b"))
datos
```

---

# Eliminando .orange[AUSENTES]


Con `drop_na()` podemos indicarle que nos **.bg-purple_light[elimine las filas con alg√∫n ausente]** en alguna de las variables (o especificarle la variable concreta).


.pull-left[

```{r}
datos %>% drop_na()
```

]


.pull-right[

```{r}
datos %>% drop_na(x)
```

]

---

# Eliminando .orange[AUSENTES]

A veces no querremos eliminarlos sino **.bg-purple_light[imputar por el valor previo/siguiente]**  con `fill()`

.pull-left[

```{r}
datos %>% fill(x)
datos %>% fill(x, .direction = c("up"))
```

]

.pull-right[

```{r}
datos %>% fill(y)
datos %>% fill(y, .direction = c("up"))
```

]


---

# Eliminando .orange[AUSENTES]

Los **.bg-purple_light[ausentes]** tambi√©n pueden ser **.bg-purple_light[eliminados al pivotar]** con `values_drop_na`.


```{r}
stocks <-
  tibble(qtr = 1:4,
         "2015" = c(1.88, 0.59, 0.35, NA),
         "2016" = c(NA, 0.92, 0.17, 2.66))
stocks
```

---

# Eliminando .orange[AUSENTES]

Los **.bg-purple_light[ausentes]** tambi√©n pueden ser **.bg-purple_light[eliminados al pivotar]** con `values_drop_na`.

```{r}
stocks %>%
  pivot_longer(cols = c("2015", "2016"), names_to = "year",
               values_to = "return", values_drop_na = TRUE)
```

---

# Reemplazando .orange[AUSENTES]

Otras veces querremos **.bg-purple_light[imputar los ausentes por un valor fijo]**, algo que podemos hacer con `replace_na()`

.pull-left[

```{r}
datos
```

]

.pull-right[

```{r}

datos %>%
  replace_na(list(x = -1,
                  y = "unknown"))
```

]

---


# Completando .orange[AUSENTES]

Por √∫ltimo, tambi√©n podemos **.bg-purple_light[crear todas las combinaciones posibles de variables]** (para completar datos ausentes que se hayan podido eliminar).


```{r}
stocks <- tibble(year = c(2015, 2015, 2015, 2015, 2016, 2016, 2016),
                 qtr = c(1, 2, 3, 4, 2, 3, 4),
                 return = c(1.88, 0.59, 0.35, NA, 0.92, 0.17, 2.66))
```

.pull-left[

```{r}
stocks
```

]

.pull-right[

```{r}
stocks %>% complete(year, qtr)
```

]

---

name: rmd

# .orange[COMUNICANDO] resultados: archivos .green[.Rmd] 


Una de las principales **.bg-purple_light[fortalezas]** de `R` es la facilidad para generar informes, libros, webs, **.bg-purple_light[apuntes y hasta diapositivas]** (este material por ejemplo).

&nbsp;

Para ello instalaremos antes el paquete `{rmarkdown}` que nos permitir√° generar documentos `.Rmd`

```{r eval = FALSE}
install.packages("rmarkdown")
```

---

# .orange[COMUNICANDO] resultados: archivos .green[.Rmd] 

¬øCu√°l son las **ventajas** de generarlos desde **.bg-purple_light[rmarkdown]**?

--

* Al hacerlo desde `RStudio`, puedes generar un informe o una presentaci√≥n **.bg-purple_light[sin salirte del entorno]** de programaci√≥n en el que est√°s trabajando

--

* Podr√°s analizar los datos, resumirlos y a la vez **.bg-purple_light[comunicarlos]**. 

--

* Permite **.bg-purple_light[integrar f√°cilmente c√≥digo]** `R`, de forma que no solo podremos integrar las salidas de nuestro trabajo sino tambi√©n el c√≥digo con el que lo hemos generado.

---

# ¬øQu√© es .orange[RMARKDOWN]? 


Una herramienta que nos permite crear de forma sencilla **documentos combinando**:

--

* **.bg-purple_light[Markdown]**: creado en 2004 por John Gruber, y de uso libre, es un ¬´lenguaje¬ª que nos permite crear contenido de una manera sencilla de escribir, y que en todo momento mantenga un dise√±o legible, con algunas de las ventajas de un HTML (si acostumbras a escribir en wordpress o blogs, seguramente hayas escrito de esta forma).

--

* **.bg-green_light[Matem√°ticas (latex)]**: herramienta (lenguaje en realidad) para escribir notaci√≥n matem√°tica como $x^2$ o $\sqrt{2}$ (si escribes notaci√≥n similar en editores de texto, seguramente sin saberlo est√©s usando ya latex).

--

* **.bg-purple_light[C√≥digo]** y salidas de `R`: podremos no solo mostrar el paso final sino el c√≥digo que has ido realizando, con **cajitas de c√≥digo** como las del manual.

--

* **.bg-green_light[Im√°genes y tablas]**.

--

* **.bg-purple_light[Estilos]** (css, js, etc).

---

# Creando nuestro .orange[PRIMER INFORME] 

.pull-left[

```{r echo = FALSE,  out.width = "80%", fig.align = "left", fig.cap = "Creando el primer fichero .rmd"}
knitr::include_graphics("./img/file_rmarkdown.jpg")
``` 


]

.pull-right[

Vamos a crear el **.bg-purple_light[primer fichero]** con extensi√≥n `.Rmd` (la extensi√≥n de los archivos R Markdown).

&nbsp;

Haz click en el bot√≥n `File << New File << R Markdown`.

]

---

# Creando nuestro .orange[PRIMER INFORME] 

.pull-left[

```{r echo = FALSE,  out.width = "80%", fig.align = "left", fig.cap = "Creando el primer fichero .rmd"}
knitr::include_graphics("./img/new_rmd.jpg")
``` 


]

.pull-right[

Tras hacerlo, nos aparecer√°n **.bg-purple_light[varias opciones]**de formatos de salida:

* archivo `.pdf`

* archivo `.html` (**.bg-purple_light[recomendable]**): documento din√°mico, permite la interacci√≥n con el usuario, como una ¬´p√°gina web¬ª)

* archivo `.doc` (nada recomendable)

De momento dejaremos marcado el **.bg-purple_light[formato HTML que viene por defecto]**, y escribiremos el t√≠tulo de nuestro documento. Tras ello tendremos nuestro archivo `.Rmd` (ya no es un script `.R` como los que hemos abierto hasta ahora)

]

---


# Creando nuestro .orange[PRIMER INFORME] 

Un fichero `.Rmd` se divide b√°sicamente en **.bg-purple_light[tres partes]**

1. **.bg-purple_light[Cabecera]**: la parte que tienes al inicio entre `---`.

2.  **.bg-purple_light[Texto]**: que podremos formatear y mejorar con **negritas** (escrito como `**negritas**`, con doble ast√©risco al inicio y final), _cursivas_ (`_cursivas_`, con barra baja al inicio y final) o destacar nombres de funciones o variables de `R` (con ``R`). Recuerda que puedes a√±adir adem√°s ecuaciones como $x^2$ (he escrito `$x^2$`, la ecuaci√≥n entre d√≥lares).

3. **.bg-purple_light[C√≥digo R]**.

---

# .orange[PRIMER INFORME]: .green[CABECERA]


La cabecera est√°n en formato `YAML`, y contiene los **.bg-purple_light[metadatos del documento]**: t√≠tulo, autor, fecha, estilos (si los tuvi√©semos), etc. Para probar, vamos a cambiar la cabecera que nos ha generado por defecto de la siguiente forma:

```{r eval = FALSE}
---
title: "Probando Probando"
author: "Se√±or/a X"
date: "11/7/2014"
output: html_document
---
```

Tras tunear nuestra cabecera borraremos todo lo que viene despu√©s para **.bg-purple_light[empezar desde cero]**.

```{r echo = FALSE,  out.width = "27%", fig.align = "left", fig.cap = "Fichero .Rmd vac√≠o, solo con la cabecera"}
knitr::include_graphics("./img/rmd_vacio.jpg")
``` 

---

# .orange[PRIMER INFORME]: .green[TEXTO]

Solo hay una cosa **.bg-purple_light[importante]** a tener en cuenta en este entorno: salvo que indiquemos lo contrario, **.bg-purple_light[TODO lo que vamos a escribir en el documento es texto]**. No c√≥digo R. Texto plano que podremos mejorar un poco con algun detalle, pero texto.

Vamos a empezar nuestro documento escribiendo por ejemplo la siguiente frase


```{r eval = FALSE}
Este material ha sido dise√±ado por el profesor Javier √Ålvarez Li√©bana,
docente en la Universidad Complutense de Madrid
```

---

# .orange[PRIMER INFORME]: .green[TEXTO]


.pull-left[

```{r echo = FALSE,  out.width = "99%", fig.align = "left", fig.cap = "Primer informe html"}
knitr::include_graphics("./img/html_con_texto.jpg")
``` 

]

.pull-right[

Una vez que hemos escrito el texto vamos a **.bg-purple_light[guardar el archivo .Rmd]** haciendo click en el bot√≥n `Guardar` (yo he llamado al archivo `primer_rmarkdown.Rmd`). Tras guardar el documento, **.bg-purple_light[¬´tejeremos¬ª nuestro documento]** haciendo click en el bot√≥n `Knit`.

Al ¬´tejer¬ª se nos habr√° generado (seguramente en una ventana al margen) un archivo .html, que podemos incluso **.bg-purple_light[abrir en nuestro navegador]**. Hemos creado nuestro primer informe, obviamente vac√≠o de momento. 


]



---

# .orange[PRIMER INFORME]: .green[TEXTO]


.pull-left[

```{r echo = FALSE,  out.width = "99%", fig.align = "left", fig.cap = "Tuneando nuestro primer informe html"}
knitr::include_graphics("./img/rmd_con_formato.jpg")
``` 

]

.pull-right[

Vamos a **.bg-purple_light[mejorar]** un poco el texto haciendo lo siguiente:

* Vamos a a√±adir **.bg-purple_light[negrita]** al nombre (poniendo `**` al inicio y al final).

* Vamos a√±adir _cursiva_ a la palabra `material` (poniendo `_` al inicio y al final).

*  Vamos a√±adir un enlace `https://www.ucm.es`, asoci√°ndolo al nombre de la Universidad. Para ello el t√≠tulo lo ponemos entre corchetes y justo detr√°s el enlace entre par√©ntesis `[¬´Universidad Complutense de Madrid¬ª](https://www.ucm.es)`

]

---


# .orange[PRIMER INFORME]: .green[CHUNKS] de R

Para a√±adir **.bg-purple_light[c√≥digo R]** debemos crear nuestras **.bg-purple_light[cajas de c√≥digo]** llamadas **.bg-orange[chunks]**: altos en el camino en nuestro texto markdown donde podremos incluir **c√≥digo**. Para incluir uno deber√° de ir encabezado de la siguiente forma.

```{r echo = FALSE,  out.width = "90%", fig.align = "left", fig.cap = "Encabezado/final del chunk"}
knitr::include_graphics("./img/chunk_1.jpg")
``` 

---

# .orange[PRIMER INFORME]: .green[CHUNKS] de R


Dentro de dicha **.bg-purple_light[cajita]** (que tiene ahora **otro color** en el documento) escribiremos **.bg-purple_light[c√≥digo R]**, como lo ven√≠amos haciendo hasta ahora. Vamos por ejemplo a **.bg-purple_light[definir dos variables]** y su suma de la siguiente manera, escribiendo dicho c√≥digo en nuestro `.Rmd` (dentro de ese chunk)

.pull-left[

```{r}
# C√≥digo R
x <- 1
y <- 2
x + y
```

]

.pull-right[

```{r echo = FALSE,  out.width = "99%", fig.align = "left", fig.cap = "Primer chunk con c√≥digo"}
knitr::include_graphics("./img/rmd_3.jpg")
``` 

]

---

# .orange[PRIMER INFORME]: .green[CHUNKS] de R

.pull-left[

```{r}
# C√≥digo R
x <- 1
y <- 2
x + y
```

]

.pull-right[

```{r echo = FALSE,  out.width = "70%", fig.align = "left", fig.cap = "Primer chunk con c√≥digo"}
knitr::include_graphics("./img/rmd_3.jpg")
``` 

]

Como ves dentro de esos _chunks_ puedes **.bg-purple_light[comentar c√≥digo]** con `#` (ahora veremos que hace `#` fuera de esas cajas de c√≥digo). Tras hacerlo tejemos de nuevo y obtenemos ahora un documento que tiene una caja de c√≥digo y su salida.

```{r echo = FALSE,  out.width = "40%", fig.align = "left", fig.cap = "Salida del html con el primer chunk"}
knitr::include_graphics("./img/html_rmd_3.jpg")
``` 



---

# .orange[PRIMER INFORME]: .green[CHUNKS] de R


Somos capaces de **.bg-purple_light[escribir en un mismo documento texto]** con cierto formato, **.bg-purple_light[c√≥digo R y la salida]** del resultado, permiti√©ndonos generar informes (ya veremos como incluir gr√°ficas). De hecho, lo m√°s pr√°ctico para **.bg-purple_light[tomar apuntes de R]** es ir anotando en un archivo `.Rmd`.

Los chunks pueden tener un **.bg-purple_light[nombre o etiqueta]**, de forma que podamos referenciarlos de nuevo para no repetir c√≥digo.

```{r echo = FALSE,  out.width = "40%", fig.align = "left", fig.cap = "Etiquetando un chunk y recicl√°ndolo"}
knitr::include_graphics("./img/chunk_repe_tag.jpg")
``` 



---

# .orange[PRIMER INFORME]: .green[ORGANIZANDO]

Con todo incluido en el documento podemos **.bg-purple_light[dividirlo en secciones y subsecciones]**. Para ello usaremos la sintaxis de markdown, poniendo **.bg-purple_light[almohadillas]**: una `#` para secciones, `##` para subsecciones, `###` para subsubsecciones, etc. Por ejemplo, vamos a

* Hacer una secci√≥n principal que sea `# Primer informe`
* Tras ello a√±adiremos la parte de texto.
* Creamos una subsecci√≥n que se titule `## Chunks de c√≥digo` donde incluiremos los dos chunks que tenemos hasta ahora.


.pull-left[

```{r echo = FALSE,  out.width = "80%", fig.align = "right", fig.cap = "Secciones en el rmd"}
knitr::include_graphics("./img/secciones_rmd.jpg")
``` 


]

.pull-right[

```{r echo = FALSE,  out.width = "80%", fig.align = "left", fig.cap = "Secciones en el html"}
knitr::include_graphics("./img/secciones_html.jpg")
``` 


]

---


# .orange[PRIMER INFORME]: .green[ORGANIZANDO]

Adem√°s podemos incluir tras el t√≠tulo (y entre llaves `{}`) **.bg-purple_light[etiquetas]** (con `{#etiqueta}`) para luego **.bg-purple_light[referenciar dichas secciones]** en el documento.

.pull-left[

```{r echo = FALSE,  out.width = "75%", fig.align = "left", fig.cap = "Referencias a secciones y subsecciones"}
knitr::include_graphics("./img/ref_rmd.jpg")
``` 

]

.pull-right[

Tambi√©n podemos organizar nuestro c√≥digo **.bg-purple_light[creando listas]**, usando `*` como √≠tems.

```{r echo = FALSE,  out.width = "85%", fig.align = "left", fig.cap = "Creando listas con √≠tems"}
knitr::include_graphics("./img/items_rmd.jpg")
``` 

]

---

# .orange[PRIMER INFORME]: .green[PERSONALIZAR]

En cada chunk aparece una **.bg-purple_light[bot√≥n de play]**: puls√°ndolo podemos tener la **ejecuci√≥n y salida** de cada chunk en nuestro `.Rmd`, sin tener que esperar a ¬´tejer¬ª (con Knit) todo el documento para ver lo que vamos ejecutando.


.pull-left[

```{r echo = FALSE,  out.width = "99%", fig.align = "left", fig.cap = "Pulsando al bot√≥n play"}
knitr::include_graphics("./img/play_chunk.jpg")
```

]

.pull-right[

```{r echo = FALSE,  out.width = "99%", fig.align = "left", fig.cap = "Chunk ejecutado in-line"}
knitr::include_graphics("./img/chunk_ejecutado.jpg")
```

]

---

# .orange[PRIMER INFORME]: .green[PERSONALIZAR]


Adem√°s podemos **.bg-purple_light[incluir c√≥digo R dentro de la l√≠nea de texto]** (en lugar de mostrar el texto x ejecuta el c√≥digo R mostrando la variable).



.pull-left[

```{r echo = FALSE,  out.width = "99%", fig.align = "left", fig.cap = "C√≥digo R inline"}
knitr::include_graphics("./img/codigo_inline_rmd.jpg")
```

]

.pull-right[

```{r echo = FALSE,  out.width = "99%", fig.align = "left", fig.cap = "Salida del c√≥digo in-line"}
knitr::include_graphics("./img/codigo_inline_html.jpg")
```

]

---

# .orange[PRIMER INFORME]: .green[PERSONALIZAR]


Los chunk podemos **.bg-purple_light[personalizar su salida]** con algunas opciones, pas√°ndolos como argumentos dentro de las llaves ({r etiqueta, ...}).

* `include = FALSE`: **.bg-green_light[ejecuta c√≥digo]** pero **.bg-red_light[no se muestra (ni resultados)]** en la salida.

* `echo = FALSE`: **.bg-green_light[ejecuta c√≥digo]** y se **.bg-green_light[muestra resultado]** pero **.bg-red_light[no el c√≥digo]** en la salida.

* `eval = FALSE`: se **.bg-green_light[muestra el c√≥digo]** pero **.bg-red_light[no se ejecuta]** en la salida final.

* `message = FALSE`: se **.bg-green_light[ejecuta el c√≥digo]** pero **.bg-red_light[no se muestran mensajes]** de salida que tendr√≠amos en consola.

* `warning = FALSE`: **.bg-green_light[ejecuta c√≥digo]** pero **.bg-red_light[no se muestran warning]**.

* `error = TRUE`: se **.bg-green_light[ejecuta el c√≥digo]** pero permite ejecutar el c√≥digo **.bg-green_light[con errores]** mostrando los mensajes de error.
 
--

Estas opciones podemos aplicarlas chunk a chunk o fijar los par√°metros de forma global con `knitr::opts_chunk$set()` (dentro de un chunk), pas√°ndole como argumentos dichas opciones (por ejemplo, `knitr::opts_chunk$set(echo = FALSE)`).

---

# .orange[PRIMER INFORME]: .green[VARIABLES/ECUACIONES]

Por √∫ltimo en este primer documento vamos a a√±adir una subsecci√≥n `## Variables y ecuaciones` donde a√±adiremos un chunk asignando la suma `x + y` a una variable `z`, escribiendo antes en texto el nombre de la variable y la **.bg-purple_light[f√≥rmula]** ($z = x + y$ entre d√≥lares).


.pull-left[

```{r echo = FALSE,  out.width = "90%", fig.align = "left", fig.cap = "A√±adiendo variables en el .rmd"}
knitr::include_graphics("./img/variables_rmd.jpg")
``` 

]

.pull-right[

```{r echo = FALSE,  out.width = "110%", fig.align = "left", fig.cap = "A√±adiendo variables en el .rmd"}
knitr::include_graphics("./img/variables_html.jpg")
``` 

]


---

name: oms

# .orange[CASO PR√ÅCTICO]: datos de la OMS

Instala el paquete `{tidyr}` y usa el conjunto `who` contenido en √©l mismo (sobre casos de tuberculosis). Lee la ayuda `? who` para detalles de los datos.  

```{r}
# install.packages("tidyr")
library(tidyr)
who
```

---

class: inverse center middle
name: clase-4

# CLASE 4: introducci√≥n a la miner√≠a (SEMMA)

&nbsp;

### [Introducci√≥n al aprendizaje estad√≠stico](#learning)

### [Sesgo vs varianza](#sesgo-varianza)

### [Introducci√≥n a la miner√≠a de datos (SEMMA)](#data-mining)

### [Muestreo (sample)](#sample)


---

name: learning

```{r echo = FALSE,  out.width = "80%", fig.align = "center"}
knitr::include_graphics("./img/ml_maths.jpg")
``` 


---

# .orange[CIENCIA DE DATOS]


**.bg-purple_light[¬øQu√© es la ciencia de datos]** ¬øQu√© incluye? La conocida como **.bg-purple_light[Data Science (Ciencia de Datos)]** es un campo muy extenso en el que, seg√∫n algunos autores, se podr√≠a incluir (o intersecar con) campos como la **Miner√≠a de Datos**, el **Machine Learning** o el **Big Data**


```{r echo = FALSE,  out.width = "40%", fig.align = "center"}
knitr::include_graphics("./img/stats_IA.jpg")
``` 

üìö Ver definiciones en **.bg-green_light[Fern√°ndez-Casal et al. (2021)]** en <https://rubenfcasal.github.io/aprendizaje_estadistico>

---

# .orange[APRENDIZAJE] estad√≠stico

Uno de los conceptos clave es la idea de **.bg-purple_light[aprendizaje estad√≠stico]**: formularemos modelos que buscan **.bg-purple_light[aprender]** de los datos (teniendo en cuenta la incertidumbre subyacente), mejorando los resultados si **.bg-purple_light[aumentamos la calidad de la informaci√≥n]** (!= aumentar su tama√±o).

&nbsp;

--

En ese aprendizaje normalmente realizaremos una **.bg-purple_light[partici√≥n preliminar de los datos]**:

- **.bg-purple_light[Entrenamiento]**: conjunto del que modelo **.bg-orange[aprender√° para su construcci√≥n]** (por ej., 70%).

--

- **.bg-purple_light[Validaci√≥n]**: conjunto que usaremos para **.bg-orange[evaluar nuestras decisiones]** (el modelo no ha podido aprender de √©l) y poder afinar los hiperpar√°metros (por ej., 20%).

--

- **.bg-purple_light[Test]**: conjunto final que nos proporcionar√° una **.bg-orange[evaluaci√≥n insesgada]** (por ej., 10%).

üìö Ver explicaci√≥n detallada en <https://mlu-explain.github.io/train-test-validation/>

---


# .orange[APRENDIZAJE] estad√≠stico

.pull-left[

Veamos un ejemplo: imagina que queremos construir un m√©todo que nos permita **.bg-purple_light[clasificar]** si un animal es un **.bg-purple_light[gato o perro]** en funci√≥n de dos variables: **suavidad** y **peso**.

En concreto el aprendizaje ser√° **.bg-purple_light[supervisado]** (s√© a priori en mi dataset cu√°l es gato o perro, veremos m√°s adelante qu√© es el aprendizaje supervisado y el no supervisado).

]

.pull-right[

```{r echo = FALSE,  out.width = "85%", fig.align = "left"}
knitr::include_graphics("./img/dogs_cats.jpg")
``` 

]

üìö Ver explicaci√≥n en <https://mlu-explain.github.io/train-test-validation/>


---

# .orange[APRENDIZAJE] estad√≠stico


```{r echo = FALSE,  out.width = "45%", fig.align = "center"}
knitr::include_graphics("./img/train_valid_test.jpg")
``` 

.pull-left[


- **.bg-orange[Conjunto train]**: datos que el **modelo conocer√°** para **.bg-purple_light[aprender patrones]**, siendo lo m√°s representativo de mi conjunto global (para evitar la propagaci√≥n de sesgos)

]

.pull-right[

```{r echo = FALSE,  out.width = "55%", fig.align = "center"}
knitr::include_graphics("./img/train_dataset.jpg")
``` 

]

---

# .orange[APRENDIZAJE] estad√≠stico

.pull-left[

El aprendizaje no solo depender√° de los datos, tambi√©n de **.bg-purple_light[nuestras decisiones]**: cada decisi√≥n es un sesgo que acumulamos.

* un clasificador tonto (**.bg-green_light[dummy]**) que diga que todos son la moda (gatos)
* usar solo la variable suavidad
* usar solo la variable peso
* un clasificador que use ambas variables

**.bg-purple_light[¬øCu√°l elegir?]** Y si tuvi√©ramos m√°s variables, ¬øcon cu√°ntas?

&nbsp;

**.bg-green_light[Clasificador dummy]**: asigna la moda (cuali)/media (cuanti) o bien un valor al azar, sin asumir patr√≥n alguno en los datos.

]

.pull-right[


.pull-left[

```{r echo = FALSE,  out.width = "140%", fig.align = "center"}
knitr::include_graphics("./img/model_1.jpg")
``` 

```{r echo = FALSE,  out.width = "140%", fig.align = "center"}
knitr::include_graphics("./img/model_3.jpg")
``` 

]

.pull-right[

```{r echo = FALSE,  out.width = "150%", fig.align = "center"}
knitr::include_graphics("./img/model_2.jpg")
``` 

```{r echo = FALSE,  out.width = "150%", fig.align = "center"}
knitr::include_graphics("./img/model_4.jpg")
``` 

]

]

---

# .orange[APRENDIZAJE] estad√≠stico


```{r echo = FALSE,  out.width = "45%", fig.align = "center"}
knitr::include_graphics("./img/train_valid_test.jpg")
``` 


.pull-left[


- **.bg-orange[Conjunto validation]**: datos que el modelo **no ha conocido** para aprender pero que usaremos para **.bg-purple_light[afinar y calibrar nuestras decisiones]**, de forma que sea **.bg-purple_light[independiente del entrenamiento]**

]

.pull-right[

```{r echo = FALSE,  out.width = "99%", fig.align = "center"}
knitr::include_graphics("./img/validation_dataset.jpg")
``` 

]

---

# .orange[APRENDIZAJE] estad√≠stico


```{r echo = FALSE,  out.width = "45%", fig.align = "center"}
knitr::include_graphics("./img/train_valid_test.jpg")
``` 


.pull-left[


- **.bg-orange[Conjunto test]**: datos que el **modelo no ha conocido**

‚ùé ni para aprender

‚ùé ni para afinar hiperpar√°metros/decisiones

Es un modelo que SOLO ser√° usado para una **.bg-purple_light[evaluaci√≥n final]** (insesgada): **.bg-red_light[NUNCA se usar√° en el proceso]**, solo cuando ya se ha terminado (simulando un cliente final).

]

.pull-right[

```{r echo = FALSE,  out.width = "99%", fig.align = "center"}
knitr::include_graphics("./img/test_dataset.jpg")
``` 

]


---

# .orange[APRENDIZAJE] estad√≠stico


.pull-left[


Si te fijas en este ejemplo, la **.bg-purple_light[m√©trica (tasa de bien clasificados)]** es superior en el conjunto de test que en el conjunto de validaci√≥n. **.bg-red_light[¬øEs malo? ¬øExtra√±o?]**

]

.pull-right[

```{r echo = FALSE,  out.width = "97%", fig.align = "center"}
knitr::include_graphics("./img/test_vs_validation.jpg")
``` 

]

--

No, no es ni malo ni extra√±o. Es m√°s, es un s√≠ntoma de que el conjunto de test no est√° sesgado a ninguna otra de las particiones

**.bg-green_light[RECUERDA]**: el √©xito del conjunto test **.bg-purple_light[NO es algo a optimizar]**, es simplemente una **.bg-purple_light[estimaci√≥n de c√≥mo funcionar√°]** nuestro modelo en datos reales.


---

name: sesgo-varianza

# Sobreajuste. .green[SESGO] vs .orange[VARIANZA]

En el campo del aprendizaje estad√≠stico (y por tanto en la miner√≠a de datos) ser√° recurrente un t√©rmino a evitar: **.bg-purple_light[sobrejauste]**.


&nbsp;

üìö Ver bibliograf√≠a en 

* ¬´The bias-variance tradeoff¬ª: <https://mlu-explain.github.io/bias-variance/>

* ¬´Understanding the bias-variance tradeoff¬ª:  <https://towardsdatascience.com/understanding-the-bias-variance-tradeoff-165e6942b229>

* ¬´Bias‚Äìvariance tradeoff¬ª: <https://daviddalpiaz.github.io/r4sl/biasvariance-tradeoff.html>

* ¬´Understanding the Bias-Variance Tradeoff¬ª: <https://scott.fortmann-roe.com/docs/BiasVariance.html>

---


# Sobreajuste. .green[SESGO] vs .orange[VARIANZA]


En el campo del aprendizaje estad√≠stico (y por tanto en la miner√≠a de datos) ser√° recurrente un t√©rmino a evitar: **.bg-purple_light[sobrejauste]**.

```{r echo = FALSE,  out.width = "80%", fig.align = "center"}
knitr::include_graphics("./img/bustamante.jpg")
``` 

---

# Sobreajuste. .green[SESGO] vs .orange[VARIANZA]

Imagina que tenemos los siguientes ingredientes

* **.bg-purple_light[Modelo real]** $f(X)$ donde $X$ ser√°n los datos, con $\hat{f}(X)$ las estimaciones.

--

* **.bg-purple_light[Output real]** que llamaremos $Y = f(X) + \varepsilon$ ($\varepsilon$ ser√° el **.bg-orange[ruido existente]**)

--

* **.bg-purple_light[Output estimada]** que llamaremos $\hat{Y}$, definido como $\hat{Y} = \hat{f}(X)$

--

* **.bg-purple_light[Error]** tras aplicar el modelo que llamaremos $E(x, f)$, y que podr√≠amos definir como la **.bg-purple_light[media de las equivocaciones al cuadrado]**

--

$$Error := E(x, f) := {\rm E} \left[ \left(realidad - estimado\right)^2 \right] = {\rm E} \left[ \left(Y - \hat{Y}\right)^2 \right] = {\rm E}\left[\left(Y - \hat{f}(X)\right)^2  \right]$$

&nbsp;

--

¬øC√≥mo podemos **.bg-purple_light[descomponer el error]**?

---


# Sobreajuste. .green[SESGO] vs .orange[VARIANZA]


* **Paso 1**: a√±adir y restar ${\rm E} \left[ \hat{Y} \right]$ dentro del par√©ntesis.

$$E(x, f) := {\rm E}\left[\left(Y - \hat{f}(X)\right)^2  \right] = {\rm E}\left[\left(\left(Y - {\rm E} \left[ \hat{Y} \right] \right) + \left( {\rm E} \left[ \hat{Y} \right] - \hat{f}(X)\right)^2 \right)  \right] $$

--

* **Paso 2**: resolver $(a-c+c-b)^2 = ((a-c)+(c-b))^2 = (a-c)^2 + (c-b)^2 - 2*(a-c)(c-b)$ 

$$E(x, f) := \left(Y - {\rm E} \left[ \hat{Y} \right] \right)^2  + {\rm E}\left[ \left( {\rm E} \left[ \hat{Y} \right] - \hat{f}(X)\right)^2 \right] + 2 {\rm E} \left[\left(Y - {\rm E} \left[ \hat{Y} \right] \right) \left( {\rm E} \left[ \hat{Y} \right] - \hat{f}(X)\right) \right] $$
--

* **Paso 3**: identificar t√©rminos

$$E(x, f) := {\rm E}\left[\left(Y - \hat{f}(X)\right)^2  \right] = sesgo^2 + varianza + ruido$$

---


# Sobreajuste. .green[SESGO] vs .orange[VARIANZA]


* **.bg-red_light[Sesgo (bias)]** ser√° igual a $\left(Y - {\rm E} \left[ \hat{Y} \right] \right)^2$ (diferencia media entre la predicci√≥n media del modelo y el valor correcto a predecir).

--

* **.bg-green_light[Varianza (variance)]** ser√° igual a ${\rm E}\left[ \left( {\rm E} \left[ \hat{Y} \right] - \hat{f}(X)\right)^2 \right]$ (la  dispersi√≥n/variaci√≥n entre las predicci√≥n individuales y la predicci√≥n media).

--

* **.bg-orange[Ruido]**: error aleatorio **irreducible** $\varepsilon$ (la componente aleatoria del modelo no determin√≠stico) de media nula.

--

&nbsp;

El **.bg-red_light[sesgo]** ser√° por tanto lo que nos **.bg-red_light[equivocamos/desviamos de forma sistem√°tica]** y la **.bg-green_light[varianza]** del modelo ser√° la **.bg-green_light[dispersi√≥n entre las predicciones]** de un mismo valor, como si repitieramos el modelo con distintas muestras aleatorias obtenidas de la misma poblaci√≥n. 

---

# Sobreajuste. .green[SESGO] vs .orange[VARIANZA]

```{r echo = FALSE,  out.width = "40%", fig.align = "center", fig.cap = "Extra√≠da de https://scott.fortmann-roe.com/docs/BiasVariance.html"}
knitr::include_graphics("./img/bias_variance.jpg")
``` 

---

# Sobreajuste. .green[SESGO] vs .orange[VARIANZA]



.pull-left[

* **.bg-red_light[Bajoajuste (underfitting)]**: modelos **muy simples** proporcionan un **.bg-red_light[sesgo muy grande]**, y poca varianza ya que la predicci√≥n siempre ser√° muy parecida (errores altos en train).

* **.bg-green_light[Sobreajuste (overfitting)]**: modelos **muy complicados**  proporcionan un **.bg-green_light[sesgo bajo]** pero al ser tan complejas proporcionar√°n una **.bg-green_light[mayor varianza]** para cada intento (errores altos en test).

]

.pull-right[

```{r echo = FALSE,  out.width = "99%", fig.align = "center", fig.cap = "Extra√≠da de https://mlu-explain.github.io/bias-variance/"}
knitr::include_graphics("./img/bias_varianc_tradeoff.jpg")
``` 

Lo deseable ser√° encontrar ese **.bg-purple_light[punto √≥ptimo de equilibrio]** en el que el error ser√° m√≠nimo.

]

---

# Sobreajuste. .green[SESGO] vs .orange[VARIANZA]

.pull-left[

```{r echo = FALSE,  out.width = "99%", fig.align = "center", fig.cap = "Extra√≠da de https://mlu-explain.github.io/bias-variance/"}
knitr::include_graphics("./img/train_test_underfitting.jpg")
``` 

]

.pull-right[

```{r echo = FALSE,  out.width = "99%", fig.align = "center", fig.cap = "Extra√≠da de https://mlu-explain.github.io/bias-variance/"}
knitr::include_graphics("./img/simple_model.jpg")
``` 

]

---

# Sobreajuste. .green[SESGO] vs .orange[VARIANZA]

.pull-left[

```{r echo = FALSE,  out.width = "99%", fig.align = "center", fig.cap = "Extra√≠da de https://mlu-explain.github.io/bias-variance/"}
knitr::include_graphics("./img/train_test_overfitting.jpg")
``` 

]

.pull-right[

```{r echo = FALSE,  out.width = "99%", fig.align = "center", fig.cap = "Extra√≠da de https://mlu-explain.github.io/bias-variance/"}
knitr::include_graphics("./img/complex_model.jpg")
``` 

]


---

# Sobreajuste. .green[SESGO] vs .orange[VARIANZA]

```{r echo = FALSE,  out.width = "60%", fig.align = "center", fig.cap = "Extra√≠da de https://365datascience.com/tutorials/machine-learning-tutorials/overfitting-underfitting/"}
knitr::include_graphics("./img/overfitting.jpg")
``` 

Un **.bg-purple_light[modelo muy simple no captura los patrones]** subyancetes en los datos mientras que un **.bg-purple_light[modelo muy complejo solo memoriza]**, no aprende.


---

# Sobreajuste. .green[SESGO] vs .orange[VARIANZA]

```{r echo = FALSE,  out.width = "45%", fig.align = "center"}
knitr::include_graphics("./img/meme_overfitting.jpg")
``` 

---

# .green[SUPERVISADO] vs .orange[NO SUPERVISADO]

```{r echo = FALSE,  out.width = "47%", fig.align = "center"}
knitr::include_graphics("./img/non_supervised.jpg")
``` 


---

# .green[SUPERVISADO] vs .orange[NO SUPERVISADO]


.pull-left[

* **.bg-purple_light[Aprendizaje supervisado]**: tendremos dos tipos de variables, la **.bg-orange[variable dependiente (output/target)]** que se quiere predecir/clasificar (con su valor conocido en el conjunto de entrenamiento) y las **.bg-orange[variables independientes (inputs)]** o variables explicativas, que contienen la informaci√≥n disponible.

&nbsp;

Todo lo que veremos en esta asignatura entra dentro de la idea de **aprendizaje supervisado**

]


.pull-right[


```{r echo = FALSE,  out.width = "110%", fig.align = "center", fig.cap = "Extra√≠da de https://realpython.com/knn-python/basics-of-machine-learning"}
knitr::include_graphics("./img/esquema_supervised.jpg")
``` 


]

---

# .green[SUPERVISADO] vs .orange[NO SUPERVISADO]


.pull-left[


* **.bg-purple_light[Aprendizaje no supervisado]**: no existe la distinci√≥n entre target y variables explicativas ya que **.bg-orange[no tenemos etiquetados los datos]**, no sabemos a priori la respuesta correcta. El aprendizaje no supervisado buscar√° **.bg-orange[similitudes/diferencias]**.

]


.pull-right[

```{r echo = FALSE,  out.width = "110%", fig.align = "center", fig.cap = "Extra√≠da de https://realpython.com/knn-python/basics-of-machine-learning"}
knitr::include_graphics("./img/esquema_nonsupervised.jpg")
``` 


]


---

# .green[CLASIFICACI√ìN] vs .orange[PREDICCI√ìN]

Dos opciones dependiendo de la **.bg-purple_light[naturaleza de la variable objetivo]** (output/target):

* **.bg-purple_light[Predicci√≥n]**: la variable objetivo es una variable **.bg-purple_light[cuantitativa continua]** (por ejemplo, precio, glucosa, etc), y la etiqueta del conjunto de entrenamiento tomar√° un **valor continuo**, a partir de una (unidimensional) o varias variables (multidimensional).

* **.bg-purple_light[Clasificaci√≥n]**: la variable objetivo es una variable **.bg-purple_light[cualitativa]** (por ejemplo, especie de flor, ausencia/presencia de enfermedad, si/no, etc) o **.bg-purple_light[cuantitativa discreta]** (por ejemplo, n√∫mero de accidentes). La etiqueta tomar√° un valor dentro del conjunto de **modalidades permitidas**, pudiendo ser binaria (si/no) o multiclase (A, B, C, D).

&nbsp;

De aqu√≠ en adelante $Y$ ser√° nuestra variable objetivo (cdentro de un rango o de un grupo de modalidades $G = \left\lbrace 1, 2, \ldots,k \right\rbrace$), y el conjunto $\left(X_1, \ldots, X_p \right)$ ser√°n las variables predictoras.


üìö Ver ¬´The elements of Statistical Learning¬ª (Hastie et al., 2008): <https://github.com/dadosdelaplace/teaching/blob/main/data_mining/biblio/datamining_hastieetal_2008.pdf>


---

name: data-mining

# .orange[DATA MINING]: ¬øqu√© es?

No hay una definici√≥n √∫nica o formal pero podemos ayudarnos de las definiciones dadas por algunos de los m√°ximos gigantes tecnol√≥gicos.

--

Seg√∫n **.bg-purple_light[IBM]**...

> La miner√≠a de datos es una forma innovadora de obtener informaci√≥n comercial valiosa mediante el an√°lisis de los datos contenidos en la base de datos de la empresa (IBM)

--

&nbsp;

Seg√∫n **.bg-purple_light[Microsoft]**...

> La miner√≠a de datos es el proceso de detectar informaci√≥n procesable de grandes conjuntos de datos para deducir los patrones y tendencias que existen. Normalmente,
estos patrones no se pueden detectar mediante la exploraci√≥n tradicional de los datos
porque las relaciones son demasiado complejas o hay demasiados datos (Microsoft)

---

# .orange[DATA MINING]: ¬øqu√© es?

.pull-left[

La miner√≠a de datos tiene como objetivo  **.bg-purple_light[descubrir patrones]** de forma autom√°tica o semiautom√°tica, patrones que a simple vista (o con estad√≠stica b√°sica) no podemos aflorar, bien por contar con **.bg-orange[grandes conjuntos de datos]**, bien por existir **.bg-green_light[relaciones muy complejas]**.

&nbsp;

No solo comprende la exploraci√≥n y el modelado, sino tambi√©n la **.bg-purple_light[evaluaci√≥n]** y la **.bg-purple_light[transformaci√≥n de la informaci√≥n]** para su uso posterior.

]

.pull-right[

```{r echo = FALSE,  out.width = "90%", fig.align = "left", fig.cap = "Extra√≠da de https://www.masterdatascienceucm.com"}
knitr::include_graphics("./img/proceso-mineria-de-datos.png.webp")
``` 


El **gran tama√±o muestral** suele hacer inviable la aplicaci√≥n de t√©cnicas de inferencia cl√°sica (problemas de potencia).

]

---

# .orange[DATA MINING]: ejemplos de uso


* **.bg-purple_light[Clasificaci√≥n de vuelos]**: usando, entre otras, variables de tr√°fico de aereo, tipolog√≠a de vuelo, variables meteorol√≥gicas, las aerol√≠neas pueden calcular la probabilidad de retraso en un vuelo.

* **.bg-purple_light[Marketing y ventas]**: conocer el perfil de p√∫blico objetivo para enfocar campa√±as personalizadas, en funci√≥n de patrones en su comportamiento, y predecir futuras bajas.

* **.bg-purple_light[Miner√≠a de textos]**: extracci√≥n de patrones en textos para clasificar, por ejemplo, noticias (detecci√≥n de Fake News).

* **.bg-purple_light[Supermercados]**: pueden analizar el conjunto de compras masivas que hacen sus clientes, para identificar asociaciones de productos o las ofertas que mejor han funcionado.

* **.bg-purple_light[Predicci√≥n de enfermedades]**: haciendo uso de diferente variables m√©dicas y de h√°bitos de salud se puede predecir la probabilidad de aparici√≥n de ciertas enfermedades, as√≠ como encontrar factores explicativos que nos puedan ayudar a su prevenci√≥n.


---

# Metodolog√≠a .orange[SEMMA]

Existen distintas metodolog√≠as/esquemas dentro de la miner√≠a de datos como la CRISP-DM (desarrollada por IBM) la
**.bg-purple_light[metodolog√≠a SEMMA]** (desarrollada por SAS), que usaremos parcialmente en esta asignatura. En esta metodolog√≠a SEMMA no siempre intervienen todas las fases del proceso y, adem√°s, las fases pueden repetirse y el
orden de las mismas modificarse.

.pull-left[


* **.bg-purple_light[SAMPLE (muestreo)]**: am√©n de las particiones train-validate-train, si la base de datos es demasiado grande, ser√° necesario tomar una **.bg-purple_light[submuestra representativa]** para poder ser procesada computacionalmente.

]

.pull-right[

```{r echo = FALSE,  out.width = "82%", fig.align = "left"}
knitr::include_graphics("./img/SEMMA.JPG")
``` 

]

---

# Metodolog√≠a .orange[SEMMA]

En esta metodolog√≠a SEMMA no siempre intervienen todas las fases del proceso y, adem√°s, las fases pueden repetirse y el
orden de las mismas modificarse.

.pull-left[


* **.bg-purple_light[EXPLORE (explorar)]**: antes de tomar decisiones deberemos **.bg-purple_light[explorar, visualizar y entender]** los datos que tenemos, para poder detectar posibles tendencias, inconsistencias, datos ausentes o anomal√≠as.

]

.pull-right[

```{r echo = FALSE,  out.width = "95%", fig.align = "left"}
knitr::include_graphics("./img/SEMMA.JPG")
``` 

]

---

# Metodolog√≠a .orange[SEMMA]

En esta metodolog√≠a SEMMA no siempre intervienen todas las fases del proceso y, adem√°s, las fases pueden repetirse y el
orden de las mismas modificarse.

.pull-left[

* **.bg-purple_light[MODIFY (modificar)]**: para preparar los datos de forma adecuada a los modelos, a veces es necesario realizar una **.bg-purple_light[transformaci√≥n]** previa de los mismos.

]

.pull-right[

```{r echo = FALSE,  out.width = "95%", fig.align = "left"}
knitr::include_graphics("./img/SEMMA.JPG")
``` 

]

---

# Metodolog√≠a .orange[SEMMA]


En esta metodolog√≠a SEMMA no siempre intervienen todas las fases del proceso y, adem√°s, las fases pueden repetirse y el
orden de las mismas modificarse.

.pull-left[

* **.bg-purple_light[MODEL (modelizar)]**: aplicaci√≥n de los **.bg-purple_light[modelos y t√©cnicas estad√≠sticas]** en el conjunto del entrenamiento para predecir la variable objetivo (regresi√≥n, knn, √°rboles de decisi√≥n, redes neuronales, etc).

]

.pull-right[

```{r echo = FALSE,  out.width = "95%", fig.align = "left"}
knitr::include_graphics("./img/SEMMA.JPG")
``` 

]

---

# Metodolog√≠a .orange[SEMMA]


En esta metodolog√≠a SEMMA no siempre intervienen todas las fases del proceso y, adem√°s, las fases pueden repetirse y el
orden de las mismas modificarse.

.pull-left[

* **.bg-purple_light[ASSESS (evaluar)]**: comprobar y **.bg-purple_light[evaluar nuestras decisiones]** para decidir los mejores par√°metros haciendo uso del conjunto de validaci√≥n. Es habitual tener que volver a la fase de modelizaci√≥n, para plantear correcciones en el modelado. Finalmente, al final del camino, se proveer√° de la calidad del modelo en el conjunto test.

]

.pull-right[

```{r echo = FALSE,  out.width = "95%", fig.align = "left"}
knitr::include_graphics("./img/SEMMA.JPG")
``` 

]


---

name: sample

# Primera fase SEMMA: .orange[MUESTREO]

Como hemos comentado, **.bg-purple_light[ANTES]** de las posibles particiones train-validaci√≥n-test que necesitemos, si la base de datos es **.bg-purple_light[demasiado grande]**, ser√° necesario tomar una **.bg-purple_light[submuestra]** (representativa) para poder ser procesada de forma eficiente.

--

.pull-left[

* **.bg-purple_light[No aleatorio]** (por cuotas) en base a **.bg-orange[condiciones]** sobre los registros (`filter()`)

* **.bg-purple_light[No aleatorio]** (intencional/discreccional) en base a **.bg-orange[posici√≥n]** (`slice`)

* **.bg-purple_light[Aleatorio]** **.bg-orange[simple]**  (`slice_sample()`)

* **.bg-purple_light[Aleatorio]** **.bg-orange[estratificado]** (`group_by()` + `slice_sample()`)

]

.pull-right[

```{r echo = FALSE,  out.width = "99%", fig.align = "left"}
knitr::include_graphics("./img/sample.jpg")
``` 


]

üìö Ver otros tipos de muestreo <https://www.unir.net/ingenieria/revista/tipos-de-muestreo/>

---

# Introducci√≥n a .orange[TIDYVERSE]


.pull-left[

```{r echo = FALSE,  out.width = "89%", fig.align = "center"}
knitr::include_graphics("./img/tidyverrse_universe.jpg")
``` 

Tambi√©n tenemos los paquetes `{purrr}` y `{lubridate}` para el manejo de **listas** y **fechas**, `{readxl}` para importar archivos **.xls y .xlsx**, `{haven}` para importar archivos **SPSS, Stata y SAS**, `{httr}` para importar **desde web** y `{rvest}` para **web scraping**.


]

.pull-right[

* `{tibble}`: **.bg-purple_light[optimizando data.frame]**.

* `{tidyr}`: **.bg-purple_light[limpiar datos]**.

* `{readr}`: **.bg-purple_light[carga r√°pida]** de datos rectangulares (formatos .csv, .tsv, etc). 

* `{dplyr}`: gram√°tica para **.bg-purple_light[depuraci√≥n de datos]** para facilitar su procesamiento.

* `{stringr}`: manejo de **.bg-purple_light[textos]**. 

* `{forcast}` manejo de **.bg-purple_light[cualitativas]**.

* `{ggplot2}`: una gram√°tica para la **.bg-purple_light[visualizaci√≥n de datos]**.

* `{tidymodels}`: una gram√°tica para la **.bg-purple_light[modelizaci√≥n y predicci√≥n]**.


]


Puedes ver su **documentaci√≥n completa** en <https://www.tidyverse.org/>.



---

# Introducci√≥n a .orange[TIDYVERSE]


```{r dplyr, echo = FALSE,  out.width = "60%", fig.align = "center", fig.cap = "Cheet sheet de las opciones del paquete dplyr"}
knitr::include_graphics("./img/dplyr.png")
``` 

El paquete vamos a usar para **.bg-purple_light[depurar y muestrear los datos]** ser√° el paquete `{dplyr}`, una gram√°tica para la manipulaci√≥n de datos.

---

# No aleatorio por condiciones: .orange[FILTER]

El conocido como **.bg-purple_light[muestreo no aleatorio por cuotas]** se basa en seleccionar (filtrar) individuos (registros) concretos que cumplan condiciones concretas.

.pull-left[

```{r eval = FALSE}
datos %>%
  filtro(condicion)
```

]

.pull-right[

```{r eval = FALSE}
starwars %>%
  filter(condicion)
```

]


--

Comparadores habituales:

* `==, !=` igual/distinto que
* `>, <` mayor/menor que
* `>=, <=` mayor/menor o igual que
* `%in%` los valores pertenecen a un listado
* `!is.na()` los valores no son ausentes (mejor usar `drop_na()`)
* `between(variable, val1, val2)`: si los valores (normalmente continuos) est√°n dentro de un rango.

---

# No aleatorio por condiciones: .orange[FILTER]

.pull-left[

```{r eval = FALSE}
datos %>%
  filtro(condicion)
```

]

.pull-right[

```{r eval = FALSE}
starwars %>%
  filter(condicion)
```

]

&nbsp;

```{r echo = FALSE,  out.width = "80%", fig.align = "center", fig.cap = "Tablas de verdad de operadores l√≥gicos"}
knitr::include_graphics("./img/tablas_verdad.jpg")
``` 

---

# No aleatorio por condiciones: .orange[FILTER]

Dicha funci√≥n `filter()` tambi√©n la usaremos cuando queramos **.bg-purple_light[depurar los datos]** en nuestra fase exploratoria.

.pull-left[

```{r eval = FALSE}
datos %>%
  filtro(condicion)
```

]

.pull-right[

```{r eval = FALSE}
starwars %>%
  filter(condicion)
```

]

--

Por ejemplo, vamos a **filtrar** aquellos personajes con **.bg-purple_light[ojos marrones]**.

```{r}
starwars %>%
  filter(eye_color == "brown") #<<
```

---

# .orange[VISUALIZAR] operaciones con datos


En la web <https://tidydatatutor.com/> podemos visualizar el flujo de datos d las transformaciones que podemos hacer con `dplyr`

```{r filter1, echo = FALSE,  out.width = "90%", fig.align = "center", fig.cap = "Flujo de https://tidydatatutor.com/"}
knitr::include_graphics("./img/filter1.jpg")
``` 

]

---

# No aleatorio por condiciones: .orange[FILTER]


De la misma manera podemos **filtrar** los personajes que **.bg-purple_light[no tienen ojos marrones]** (en realidad estamos eliminando filas de alguna manera).


```{r}
starwars %>% filter(eye_color != "brown")
```

---

# No aleatorio por condiciones: .orange[FILTER]

Al ser una variable discreta, ser√≠a bastante l√≥gico comprobar si toma alg√∫n valor **.bg-purple_light[dentro de una lista permitida]**  (por ejemplo, personjes con ojos marrones o azules).


```{r}
starwars %>% filter(eye_color %in% c("brown", "blue"))
```

---

# No aleatorio por condiciones: .orange[FILTER]

Cuando es una variable continua el inter√©s podr√≠a estar en comprobar si la variable toma valores **.bg-purple_light[dentro de un intervalo continuo]**.


.pull-left[

```{r eval = FALSE}
starwars %>%
  filter(between(height, 120, 160))
```

```{r echo = FALSE}
# con estatura entre 120 y 160 cm
starwars %>%
  select(name, height, mass, eye_color) %>%
  filter(between(height, 120, 160)) %>%
  slice(1:5)
```

]

.pull-right[

```{r filter3, echo = FALSE,  out.width = "160%", fig.align = "center", fig.cap = "Flujo de https://tidydatatutor.com/"}
knitr::include_graphics("./img/filter3.jpg")
``` 

]


---


# No aleatorio por condiciones: .orange[FILTER]


Las condiciones tambi√©n se pueden **.bg-purple_light[concatenar]**, pudiendo en pocas l√≠neas realizar un filtro complejo. Por ejemplo, podemos filtrar los personajes con **.bg-purple_light[ojos marrones Y ADEM√ÅS NO humanos]**, o **.bg-purple_light[con m√°s de 60 a√±os]**.

.pull-left[

```{r eval = FALSE}
starwars %>%
  filter((eye_color == "brown" &
            species != "Human") |
           birth_year > 60)
```

]

.pull-right[

```{r filter5, echo = FALSE,  out.width = "100%", fig.align = "center", fig.cap = "Flujo de https://tidydatatutor.com/"}
knitr::include_graphics("./img/filter5.jpg")
``` 


]

---

# Ejercicios (filter)

.panelset[
.panel[.panel-name[Ejercicios]


* üìù **Ejercicio 1**: selecciona del conjunto de `starwars` solo los personajes que sean humanos (`species == "Human"`)

* üìù **Ejercicio 2**: selecciona del conjunto de `starwars` solo los personajes cuyo peso est√© entre 65 y 90 kg.

* üìù **Ejercicio 3**: selecciona del conjunto de `starwars` los personajes con ojos marrones o rojos.

* üìù **Ejercicio 4**: selecciona del conjunto de `starwars` los personajes no humanos, hombres y que midan m√°s de 170 cm, o los personajes con ojos marrones o rojos.

* üìù **Ejercicio 5**: selecciona aquellos personajes de `starwars` que hayan pilotado m√°s de 2 naves.

]

.panel[.panel-name[Sol. Ej. 1]

```{r}
starwars %>%
  filter(species == "Human")
```

]

.panel[.panel-name[Sol. Ej. 2]

```{r}
starwars %>%
  filter(between(mass, 65, 90))
```

]

.panel[.panel-name[Sol. Ej. 3]

```{r}
starwars %>%
  filter(eye_color %in% c("brown", "red"))
```

]

.panel[.panel-name[Sol. Ej. 4]

```{r}
starwars %>%
  filter((species != "Human" & sex == "Male" & height > 170) |
           eye_color %in% c("brown", "red"))
```

]

.panel[.panel-name[Sol. Ej. 5]

```{r}
library(purrr) # ya est√° en tidyverse per por si
starwars$n_starships <- starwars$starships %>% map_int(length)
starwars %>% filter(n_starships > 2)
```

```{r echo = FALSE}
starwars <- dplyr::starwars
```

]

]

---

# Ejercicio extra


Veamos un ejercicio extra para comprobar la **potencia y flexibilidad** de `{tidyverse}`, pudiendo hacer muchas cosas en dos l√≠neas de c√≥digo.

&nbsp;

* üìù **Ejercicio extra**: selecciona aquellos personajes de `starwars` que hayan salido en la pel√≠cula de la saga "El ataque de los clones" (en ingl√©s, "Attack of the Clones"). Busca informaci√≥n de la funci√≥n `str_detect()` del paquete `stringr`. Consejo: prueba antes las funciones que vayas a usar con alg√∫n vector de prueba para poder comprobar su funcionamiento.

---


# No aleatorio por posici√≥n: .orange[SLICE]

El conocido como **.bg-purple_light[muestreo no aleatorio intencional o discreccional]** se basa en seleccionar (filtrar) individuos (registros) concretos por su posici√≥n, elementos ¬´a dedo¬ª.

.pull-left[

```{r eval = FALSE}
datos %>%
  rebanada(posicion)
```

]

.pull-right[

```{r eval = FALSE}
starwars %>%
  slice(posicion)
```

]

--

Normalmente filtraremos registros por alguna condici√≥n pero a veces nos puede interesar, por ejemplo, sacar las primeras n filas. Para podemos crear **.bg-purple_light[rebanadas de los datos]**, seleccionando filas por su posici√≥n con `slice()`.

```{r}
starwars %>% slice(1) #<<
```

---

# No aleatorio por posici√≥n: .orange[SLICE]

.pull-left[

```{r eval = FALSE}
datos %>%
  rebanada(posicion)
```

]

.pull-right[

```{r eval = FALSE}
starwars %>%
  slice(posicion)
```

]


Recuerda que todo lo que podemos hacer con un n√∫mero (vector de longitud 1) podemos hacerlo con un vector de √≠ndices, as√≠ que podemos **.bg-purple_light[extraer varias rebanadas]**, a la vez.

```{r}
# filas de la 1 a la 5
starwars %>% slice(1:5)
```

---

# No aleatorio por posici√≥n: .orange[SLICE]

Tambi√©n podr√≠amos usar una **.bg-purple_light[secuencia de √≠ndices]** a extraer.

```{r}
# filas 1, 2, 10, 13, 27
starwars %>% slice(c(1, 2, 10, 13, 27))
```


---

# No aleatorio por posici√≥n: .orange[SLICE]


Disponemos adem√°s de opciones por defecto de operaciones habituales

* `slice_head(n = ...)`: extraer las n **.bg-purple_light[primeras filas]**.


```{r}
# las 2 primeras filas
starwars %>% slice_head(n = 2)
```

---


# No aleatorio por posici√≥n: .orange[SLICE]

* `slice_tail(n = ...)`: extraer las n **.bg-purple_light[√∫ltimas filas]**.

```{r}
# los 3 √∫ltimas filas
starwars %>% slice_tail(n = 3) 
```

---

# No aleatorio por posici√≥n: .orange[SLICE]


* `slice_min(var, n = ...)` y `slice_max(var, n = ...)`: extrae las n filas con **.bg-purple_light[menor/mayor de una variable]** (si hay empate, mostrar√° todas salvo que `with_ties = FALSE`). 

.pull-left[

```{r eval = FALSE}
# los 3 m√°s bajitos
starwars %>% slice_min(height, n = 3) 
```

```{r echo = FALSE}
# los 3 m√°s bajitos
starwars %>% slice_min(height, n = 3) %>% select(name:hair_color)
```

]

.pull-right[

```{r eval = FALSE}
# los 3 m√°s pesados
starwars %>% slice_max(mass, n = 3) 
```

```{r echo = FALSE}
# los 3 m√°s pesados
starwars %>% slice_max(mass, n = 3) %>% select(name:hair_color)
```

]

---

# Ejercicios (slice)

.panelset[
.panel[.panel-name[Ejercicios]


* üìù **Ejercicio 1**: selecciona solo los personajes que sean humanos y de ojos marrones.

* üìù **Ejercicio 2**: selecciona los 3 personajes m√°s mayores.

* üìù **Ejercicio 3**: selecciona los 5 personajes m√°s bajitos.



]

.panel[.panel-name[Sol. Ej. 1]

```{r}
# Podemos combinar varias acciones en pocas l√≠neas
starwars %>%
  filter(eye_color == "brown",
         species == "Human")
```

]

.panel[.panel-name[Sol. Ej. 2]


```{r}
starwars %>%
  slice_max(birth_year, n = 3)
```

]

.panel[.panel-name[Sol. Ej. 3]



```{r}
starwars %>%
  slice_min(height, n = 5)
```
]

]

---

# Ejercicio extra


Veamos un ejercicio extra para comprobar la **potencia y flexibilidad** de `{tidyverse}`, pudiendo hacer muchas cosas en dos l√≠neas de c√≥digo.

&nbsp;

* üìù **Ejercicio extra**: de los personajes que son humanos y miden m√°s de 160 cm, selecciona los 5 m√°s altos, y orden de mayor a menor peso. Devuelve la tabla.


---


# Aleatorio simple: .orange[SLICE_SAMPLE]

El conocido como **.bg-purple_light[muestreo aleatorio simple]** se basa en seleccionar individuos aleatoriamente, de forma que cada uno tenga las mismas probabilidades de ser seleccionado.

.pull-left[

```{r eval = FALSE}
datos %>%
  rebanada_aleatoria(n, probabilidades)
```

]

.pull-right[

```{r eval = FALSE}
starwars %>%
  slice_sample(n = ..., weight_by = ..., replace = ...)
```

]

--

Con`slice_sample(n = ...)` podemos extraer n **.bg-purple_light[registros aleatoriamente]** (a priori equiprobables).



```{r}
# 3 registros aleatorios
starwars %>% slice_sample(n = 3)
```

---

# Aleatorio simple: .orange[SLICE_SAMPLE]

Tambi√©n podremos indicarle la **.bg-purple_light[proporci√≥n]** de datos a samplear (en lugar del n√∫mero) y si queremos que sea con **.bg-purple_light[reemplazamiento]** (que se puedan repetir).

```{r}
# 5% de registros aleatorios
starwars %>% slice_sample(prop = 0.05, replace = TRUE)
```

---

# Aleatorio simple: .orange[SLICE_SAMPLE]

En `slice_sample()` podemos pasar un **.bg-purple_light[vector de probabilidades]** (no equiprobable). Vamos a forzar que sea muy improbable sacar una fila que no sean las dos primeras

```{r eval = FALSE}
starwars %>% slice_sample(n = 2, weight_by = c(0.495, 0.495, rep(0.01/85, 85)))
```

```{r echo = FALSE}
starwars %>% slice_sample(n = 2, weight_by = c(0.495, 0.495, rep(0.01/85, 85))) %>% select(name:gender)
```

```{r eval = FALSE}
starwars %>% slice_sample(n = 2, weight_by = c(0.495, 0.495, rep(0.01/85, 85)))
```

```{r echo = FALSE}
starwars %>% slice_sample(n = 2, weight_by = c(0.495, 0.495, rep(0.01/85, 85))) %>% select(name:gender)
```

---

# Aleatorio .orange[ESTRATIFICADO]

El conocido como **.bg-purple_light[muestreo aleatorio estratificado]** se basa en seleccionar (filtrar) individuos (registros) de forma que la selecci√≥na sea **.bg-purple_light[aleatoria PERO en diferentes estratos]**: crearemos grupos, de forma que **.bg-purple_light[muestreemos un porcentaje similar]** en cada estrato.

--

Para ello, antes del muestreo, usaremos una opci√≥n muy potente de tidyverse: con `group_by()` no modificaremos los datos sino **.bg-purple_light[modificaremos la acci√≥n posterior]**, realiz√°ndose en paralelo en cada grupo o estrato.

.pull-left[

```{r eval = FALSE}
datos %>%
  agrupar(var_grupo1, var_grupo2, ...) %>% 
  rebanada_aleatoria(n, probabilidades) %>% 
  desagrupar()
```

]

.pull-right[

```{r eval = FALSE}
starwars %>%
  group_by(var_grupo1, var_grupo2, ...) %>% 
  slice_sample(n = ..., weight_by = ...) %>% 
  ungroup()
```

]

---

# Aleatorio .orange[ESTRATIFICADO]

Cuando apliquemos `group_by()` es importante entender que **.bg-purple_light[NO MODIFICA los datos]**: nos crea una variable de grupo que **.bg-purple_light[modificar√° las acciones futuras]** que apliquemos, generando una especie de generar **m√∫ltiples subtablas**, y las operaciones aplicadas despu√©s se **.bg-purple_light[aplicar√°n a cada una por separado]**.

---

# Aleatorio .orange[ESTRATIFICADO]

.pull-left[

Por ejemplo, imagina que queremos saber el **.bg-purple_light[n√∫mero de registros por sexo]**: primero **.bg-purple_light[agruparemos]** por la variable `sex`, y despu√©s aplicaremos el **.bg-purple_light[conteo]** con `count()` (realiza la acci√≥n pedida en cada subtabla).

```{r}
starwars %>%
  group_by(sex) %>% #<< 
  count() %>%
  ungroup() #<<
```

**IMPORTANTE**: siempre que agrupes, acu√©rdate de desagrupar con `ungroup()`.

]


.pull-right[

```{r echo = FALSE,  out.width = "45%", fig.align = "center"}
knitr::include_graphics("./img/count_group_1.jpg")
``` 

```{r echo = FALSE,  out.width = "95%", fig.align = "center", fig.cap = "Flujo de https://tidydatatutor.com/"}
knitr::include_graphics("./img/count_group_2.jpg")
``` 


]

---

# Aleatorio .orange[ESTRATIFICADO]


.pull-left[

Podemos **.bg-purple_light[agrupar por variables]**, por ejemplo vamos a agrupar por `sex` y `gender`, y despu√©s aplicaremos `count()` (realiza la acci√≥n en cada subtabla).

```{r}
starwars %>%
  group_by(sex, gender) %>% #<< 
  count() %>%
  ungroup() #<<
```

**IMPORTANTE**: siempre que agrupes, acu√©rdate de desagrupar con `ungroup()`.

]

.pull-right[

```{r echo = FALSE,  out.width = "150%", fig.align = "center"}
knitr::include_graphics("./img/group_1.jpg")
``` 

```{r group-count, echo = FALSE,  out.width = "150%", fig.align = "center", fig.cap = "Flujo de https://tidydatatutor.com/"}
knitr::include_graphics("./img/group_count.jpg")
``` 

]

---

# Aleatorio .orange[ESTRATIFICADO]

El **.bg-purple_light[muestreo aleatorio estratificado]** lo podremos realizar con un `slice_sample()` pero antes aplicando un `group_by()` para **.bg-purple_light[seleccionar por estratos]**. 

¬øC√≥mo **.bg-purple_light[muestrear el 50%]** pero tener la **.bg-purple_light[misma proporci√≥n de hombres que de mujeres]** que en los datos originales?

--

Para el ejemplo, filtraremos solo los hombres y mujeres (76 registros)

```{r eval = FALSE}
starwars %>% filter(sex %in% c("female", "male"))
```

---


# Aleatorio .orange[ESTRATIFICADO]

¬øC√≥mo **.bg-purple_light[muestrear el 50%]** pero tener la **.bg-purple_light[misma proporci√≥n de hombres que de mujeres]** que en los datos originales?

F√≠jate que tenemos 38 filas (el 50% de los 76 registros, redondeando hacia abajo) pero...

```{r}
starwars %>%
  filter(sex %in% c("female", "male")) %>% 
  group_by(sex) %>%#<<
  slice_sample(prop = 0.5) %>% 
  ungroup()
```


---

# Aleatorio .orange[ESTRATIFICADO]

F√≠jate que seguimos teniendo 38 filas (el 50% de los 76 registros, redondeando hacia abajo) pero...

.pull-left[

```{r}
starwars %>%
  filter(sex %in% c("female", "male")) %>% 
  group_by(sex) %>%#<<
  slice_sample(prop = 0.5) %>% 
  ungroup() %>% 
  count(sex)
```

]

.pull-right[

```{r}
starwars %>%
  filter(sex %in% c("female", "male")) %>% 
  count(sex)
```

]

...**.bg-purple_light[asegurando una proporci√≥n similar]** de hombres que de mujeres que en la muestra original

---

# .orange[CONTAR]: group_by() + count()

Aunque lo veremos de nuevo en exploraci√≥n y depuraci√≥n, hemos visto ya como **.bg-purple_light[generar el resumen estad√≠stico]** m√°s sencillo: **.bg-purple_light[contar (frecuencias)]**

.pull-left[

```{r eval = FALSE}
datos %>%
  contar(var1, var2)
```

]

.pull-right[

```{r eval = FALSE}
starwars %>%
  count(var1, var2)
```

]

--

Cuando lo usamos en solitario, `count()` nos devolver√° simplemente el **.bg-purple_light[n√∫mero de registros]**

```{r}
starwars %>% count()
```

---

# .orange[CONTAR]: group_by() + count()

Sin embargo, cuando lo usamos pas√°ndole como **.bg-purple_light[argumento una o varias variables]**, `count()` nos cuenta lo que se conoce en estad√≠stica como **.bg-purple_light[frecuencias absolutas]**: el n√∫mero de elementos pertenecientes a cada una de las **modalidades**. En nuestro caso, la variable `sex` tiene 4 modalidades: `female, hermaphroditic, male, none`.

```{r}
starwars %>% count(sex)#<<
```

---

# .orange[CONTAR]: group_by() + count()


Adem√°s si pasamos **.bg-purple_light[varias variables]** nos calcula una **.bg-purple_light[tabla de contigencia]** con las frecuencias absolutas n-dimensionales

```{r}
starwars %>% count(sex, gender)
```

---


# .orange[CONTAR]: group_by() + count()

Adem√°s dentro del `count()` podemos a√±adir `sort = TRUE`, que nos devolver√° el conteo de frecuencias con los **.bg-purple_light[elementos m√°s frecuentes primero]** (sin necesidad de a√±adir un `arrange()` a la tabla de conteo generada).

```{r}
starwars %>%
  count(sex, sort = TRUE)
```

---

# Ejercicios (group_by() + count())

.panelset[
.panel[.panel-name[Ejercicios]


* üìù **Ejercicio 1**: calcula cu√°ntos personajes hay de cada especie de `starwars` haciendo uso de `group_by()` y `count()`. Determina el n√∫mero de especies distintas.

* üìù **Ejercicio 2**: calcula cu√°ntos personajes hay de cada sexo y g√©nero.

* üìù **Ejercicio 3**: tras eliminar ausentes en  `birth_year`, obt√©n la edad m√≠nima y m√°xima por sexo.

* üìù **Ejercicio 4**: obt√©n el personaje m√°s viejo por cada sexo.

* üìù **Ejercicio 5**: selecciona aleatoriamente el 60% de los registros de `starwars` pero manteniendo el reparto original entre humanos y no humanos (recuerda limpiar antes de ausentes, con `filter()` o `drop_na()`)

* üìù **Ejercicio 6**: selecciona aleatoriamente un personaje de cada sexo.

]

.panel[.panel-name[Sol. Ej. 1]

```{r}
starwars %>% 
  group_by(species) %>% 
  count() %>% 
  ungroup()
```

```{r}
starwars %>% 
  group_by(species) %>% 
  count() %>% 
  ungroup() %>%
  nrow()
```


]

.panel[.panel-name[Sol. Ej. 2]


```{r}
starwars %>%
  count(sex, gender)
```

```{r}
starwars %>%
  group_by(sex, gender) %>% 
  count() %>% 
  ungroup()
```

]

.panel[.panel-name[Sol. Ej. 3]

```{r}
starwars %>% 
  drop_na(birth_year) %>% 
  group_by(sex) %>% 
  slice_min(n = 1, birth_year) %>% 
  ungroup()

starwars %>% 
  drop_na(birth_year) %>% 
  group_by(sex) %>% 
  slice_max(n = 1, birth_year) %>% 
  ungroup()
```

]

.panel[.panel-name[Sol. Ej. 4]

```{r}
starwars %>% 
  group_by(sex) %>% 
  slice_max(n = 1, birth_year) %>% 
  ungroup()
```

]

.panel[.panel-name[Sol. Ej. 5]

```{r}
starwars %>% 
  drop_na(species) %>% 
  group_by(species == "Human") %>% 
  slice_sample(prop = 0.6) %>% 
  ungroup()
```


]

.panel[.panel-name[Sol. Ej. 6]

```{r}
starwars %>% 
  group_by(sex) %>% 
  slice_sample(n = 1) %>% 
  ungroup()
```

]

]

---

# Ejercicio extra

* üìù **Ejercicio extra**

  - Carga la tabla `billboard` del paquete `{tidyr}`.
  - Convierte el dataset a tidydata, ausentes incluidos (deber√≠as obtener 5307 filas y 5 columnas).
  - Extrae la lista de artistas distintos que aparecen en la tabla.
  - Determina el artista que aparece m√°s veces en la lista.
  - Determina el arista y canci√≥n que ha estado m√°s semanas en la lista.
  - Realiza un muestreo extrayendo solo los registros de Enrique Iglesias y The Backstreet Boys.
  - Realiza un muestreo extrayendo los 5 artistas cuya canci√≥n haya estado m√°s veces en el top5.
  - Realiza un muestreo aleatorio estratificado, extrayendo el 60% de los datos manteniendo la proporci√≥n de datos entre las distintas semanas.
  
  

---

class: inverse center middle
name: clase-5

# CLASE 5: primer algoritmo de clasificaci√≥n (knn)

&nbsp;

### [Depuraci√≥n tidyverse](#preproc)

### [Introducci√≥n a la clasificaci√≥n supervisada](#sup-class)

### [Clasificador Bayesiano](#bayes)

### [knn: algoritmo de los k-vecinos m√°s cercanos](#knn)



---

name: preproc

# .orange[ELIMINAR] duplicados: distinct()

Otra opci√≥n es **.bg-purple_light[eliminar filas duplicadas]** con `distinct()`, pas√°ndole como argumentos las variables. Por defecto, solo extrae las columnas en base a las cuales hemos eliminado duplicados. Si queremos que nos **mantenga todas** deberemos explicitarlo con `.keep_all = TRUE`.

.pull-left[

```{r}
# Elimina filas con igual (color_pelo, color_ojos)
starwars %>% distinct(hair_color, eye_color)
```

]

.pull-left[

```{r}
# Elimina filas con igual (color_pelo, color_ojos)
starwars %>% distinct(hair_color, eye_color, .keep_all = TRUE)
```

]
  
---

# .orange[SELECCIONAR] columnas:  select()

.pull-left[

```{r eval = FALSE}
datos %>%
  selecciono(col1, col2, ...)
```

]

.pull-right[

```{r eval = FALSE}
starwars %>%
  select(col1, col2, ...)
```

]

--

La opci√≥n m√°s sencilla para **.bg-purple_light[seleccionar variables]** es `select()`, dando como argumentos los nombres de columnas. Por ejemplo, vamos a seleccionar las variables `names` y `hair_color`

```{r}
starwars %>%
  select(name, hair_color) #<<
```


---

# .orange[SELECCIONAR] columnas:  select()

.pull-left[

```{r}
starwars %>% select(name, hair_color)
```

]

.pull-right[

```{r select1, echo = FALSE,  out.width = "140%", fig.align = "center", fig.cap = "Flujo de https://tidydatatutor.com/"}
knitr::include_graphics("./img/select1.jpg")
``` 

]

---

# .orange[SELECCIONAR] columnas:  select()


Como suced√≠a al filtrar, la funci√≥n `select()` es bastante versatil y nos permite:

* Seleccionar **.bg-purple_light[varias variables a la vez]** (concatenando sus nombres).

```{r}
starwars %>% select(name:skin_color)
```

---

# .orange[SELECCIONAR] columnas:  select()

* **.bg-purple_light[Deseleccionar]** columnas con `-`

```{r}
starwars %>% select(-c(mass:eye_color), -species, -c(films:starships))
```

---

# .orange[SELECCIONAR] columnas:  select()


* Seleccionar columnas que **.bg-purple_light[comiencen por un prefijo]** (`starts_with()`), **.bg-purple_light[terminen]** con un sufijo (`ends_with()`), **.bg-purple_light[contengan]** un texto (`contains()`) o cumplan una **.bg-purple_light[expresi√≥n regular]** (`matches()`)


```{r}
# nombre acaba en "color"
starwars %>% select(ends_with("color"))
```

---

# .orange[SELECCIONAR] columnas:  select()


* Seleccionar columnas que **.bg-purple_light[comiencen por un prefijo]** (`starts_with()`), **.bg-purple_light[terminen]** con un sufijo (`ends_with()`), **.bg-purple_light[contengan]** un texto (`contains()`) o cumplan una **.bg-purple_light[expresi√≥n regular]** (`matches()`)

```{r}
# empiezan por new_sp
who %>% select(country, year, starts_with("new_sp"))
```

---

# .orange[SELECCIONAR] columnas:  select()


* Seleccionar columnas que **.bg-purple_light[comiencen por un prefijo]** (`starts_with()`), **.bg-purple_light[terminen]** con un sufijo (`ends_with()`), **.bg-purple_light[contengan]** un texto (`contains()`) o cumplan una **.bg-purple_light[expresi√≥n regular]** (`matches()`)

```{r}
tb <- tibble("edad" = c(30, 35, 40),
             "color_ojos" = c("azul", "amarillo", "negro"),
             "pelo_color" = c("negro", "marr√≥n", "rubio"))
tb %>% select(contains("color"))
```


---

# .orange[SELECCIONAR] columnas:  select()

Incluso podemos seleccionar por rango num√©rico si tenemos variables conun prefijo y n√∫meros.

```{r}
billboard %>% select(num_range("wk", 10:15))
```

---

# .orange[SELECCIONAR] columnas:  select()

* Seleccionar columnas de un **.bg-purple_light[tipo]** haciendo uso de `where()`.


```{r}
# Solo columnas num√©ricas o de trexto
starwars %>% select(where(is.numeric) | where(is.character))
```

---

# .orange[RECOLOCAR] columnas: relocate()

F√≠jate que con `select()` podr√≠as adem√°s **.bg-purple_light[recolocar columnas]**, ind√≠candole el orden, ayud√°ndote tambi√©n de `everything()`

```{r}
starwars %>%  select(c(species, name, birth_year, everything()))
```

---

# .orange[RECOLOCAR] columnas: relocate()


.pull-left[

```{r eval = FALSE}
datos %>% 
  recolocar(col1, col2, .after = ...)
```

]

.pull-right[

```{r eval = FALSE}
starwars %>% 
  relocate(col1, col2, .after = ...)
```

]

--

Para facilitar la **.bg-purple_light[recolocaci√≥n]** tenemos una funci√≥n para ello, `relocate()`,  indic√°ndole en `.after` o `.before` detr√°s o delante de qu√© columnas queremos moverlas.

```{r}
starwars %>% relocate(species, .before = name)
```

---

# .orange[EXTRAER] columnas: pull()


.pull-left[

```{r eval = FALSE}
datos %>% 
  retirar(variable)
```

]

.pull-right[

```{r eval = FALSE}
starwars %>% 
  pull(variable)
```

]

--

.pull-left[

Si observas la salida de los `select()`, sigue siendo una tabla `tibble`, nos preserva la naturaleza de nuestros datos.

```{r}
starwars %>% select(name)
```

]

.pull-right[

A veces no querremos dicha estructura sino **.bg-purple_light[extraer literalmente la columna]**, algo que podemos hacer con `pull()`

```{r}
starwars %>% pull(name)
```

]

---

# .orange[RENOMBRAR] columnas: rename()


.pull-left[

```{r eval = FALSE}
datos %>% 
  renombrar(col1, col2)
```

]

.pull-right[

```{r eval = FALSE}
starwars %>% 
  rename(col1, col2)
```

]

--

A veces tambi√©n podemos querer **modificar la ¬´metainformaci√≥n¬ª** de los datos, **.bg-purple_light[renombrando columnas]**. Para ello usaremos la funci√≥n `rename()` poniendo primero el nombre nuevo y luego el antiguo.

```{r}
starwars %>% 
  rename(nombre = name, altura = height,  peso = mass)
```


---

# Ejercicios (columnas)

.panelset[
.panel[.panel-name[Ejercicios]


* üìù **Ejercicio 1**: filtra el conjunto de personajes y qu√©date solo con aquellos que en la variable `height` no tengan un dato ausente.

* üìù **Ejercicio 2**: con los datos obtenidos del filtro anterior, selecciona solo las variables `name`, `height`, as√≠ como todas aquellas variables que CONTENGAN la palabra `color` en su nombre.

* üìù **Ejercicio 3**: con los datos obtenidos del ejercicio anterior, traduce el nombre de las columnas a castellano

* üìù **Ejercicio 4**: con los datos obtenidos del ejercicio anterior, coloca la variable de color de pelo justo detr√°s de la variable de nombres.

* üìù **Ejercicio 5**: con los datos obtenidos del ejercicio, comprueba cu√°ntas modalidades √∫nicas hay en la variable de color de pelo.

]

.panel[.panel-name[Sol. Ej. 1]

**IMPORTANTE**: todo lo que hagas en la tabla original, si el resultado final no se lo asignas `<-` a otra variable, lo ver√°s en consola pero no se guardar√° en ning√∫n sitio. Lo que no guardes, no existe.


```{r}
starwars_NA <- starwars %>% drop_na(height)
starwars_NA 
```

]

.panel[.panel-name[Sol. Ej. 2]

```{r}
starwars %>%
  drop_na(height) %>%
  select(c(name, height, contains("color")))
```

]

.panel[.panel-name[Sol. Ej. 3]


```{r}
starwars %>%
  drop_na(height) %>%
  select(c(name, height, contains("color"))) %>%
  rename(nombre = name, altura = height,
         color_pelo = hair_color,
         color_piel = skin_color,
         color_ojos = eye_color)
```

]

.panel[.panel-name[Sol. Ej. 4]


```{r}
starwars %>%
  drop_na(height) %>%
  select(c(name, height, contains("color"))) %>%
  rename(nombre = name, altura = height,
         color_pelo = hair_color,
         color_piel = skin_color,
         color_ojos = eye_color) %>%
  relocate(color_pelo, .after = nombre)
```

]

.panel[.panel-name[Sol. Ej. 5]

```{r}
starwars %>%
  drop_na(height) %>%
  select(c(name, height, contains("color"))) %>%
  rename(nombre = name, altura = height, color_pelo = hair_color,
         color_piel = skin_color, color_ojos = eye_color) %>%
  relocate(color_pelo, .after = nombre) %>%
  distinct(color_pelo)
```

**IMPORTANTE**: recuerda que `distinct()` de mantener todas las columnas a√±adiendo `.keep_all = TRUE`.

]

]


---

# Ejercicio extra


Veamos un ejercicio extra para comprobar la **potencia y flexibilidad** de `{tidyverse}`, pudiendo hacer muchas cosas en dos l√≠neas de c√≥digo.

&nbsp;

* üìù **Ejercicio extra**: selecciona solo las variables `name` y aquellas que sean de tipo num√©rico y la variable `homeworld`, y selecciona solo los personajes que no sean humanos y que pesen entre 70 y 90 kg.  Tras ello elimina datos ausentes, y elimina duplicados con el mismo valor en `homeworld`. Tras ello, recoloca las variables para que el orden la primera columna sea `name` y la segunda `birth_year`. Para acabar, cambia el nombre  a castellano de las variables.


---

name: mutate


# .orange[MODIFICAR] columnas: mutate()


.pull-left[

```{r eval = FALSE}
datos %>%
  modificar(nueva_var = ...)
```

]

.pull-right[

```{r eval = FALSE}
starwars %>%
  mutate(nueva_var = ...)
```

]

--

En muchas ocasiones querremos **.bg-purple_light[modificar o crear  variables]**. Para ello tenemos la funci√≥n `mutate()`. Vamos a crear una **nueva variable** `height_m` con la altura en cent√≠metros.

```{r}
# altura en metros
starwars %>%
  mutate(height_m = height / 100) #<<
```

---

# .orange[MODIFICAR] columnas: mutate()


```{r eval = FALSE}
starwars %>% mutate(height_m = height / 100)
```

```{r mutate1, echo = FALSE,  out.width = "90%", fig.align = "center", fig.cap = "Flujo de https://tidydatatutor.com/"}
knitr::include_graphics("./img/mutate1.jpg")
``` 

---

# .orange[MODIFICAR] columnas: mutate()

Otra opci√≥n es **.bg-purple_light[quedarnos solo con las modificadas]** (por ejemplo, para ver si hace lo que debe) con `transmute()`

```{r}
starwars %>%
  transmute(height_m = height / 100) #<<
```

---


# .orange[MODIFICAR] columnas: mutate()

Tambi√©n se pueden aplicar **.bg-purple_light[funciones m√°s complejas]** o incluso **.bg-purple_light[funciones propias]** creadas por nosotros mismos (y varias a la vez).

```{r}
calculo_IMC <- function(peso, estatura, unidades = "metros") {
  
  estatura <- ifelse(unidades == "metros", estatura, estatura / 100)
  IMC <- peso / (estatura^2)
  
  return(IMC)
}
```

---

# .orange[MODIFICAR] columnas: mutate()

Tambi√©n se pueden aplicar **.bg-purple_light[funciones m√°s complejas]** o incluso **.bg-purple_light[funciones propias]** creadas por nosotros mismos (y varias a la vez).

```{r}
starwars %>%
  mutate(IMC = calculo_IMC(mass, height, unidades = "cent√≠metros"),
         height_m = height / 100) %>%
  relocate(IMC, height_m, .after = mass)
```

---

# .orange[MODIFICAR] columnas: mutate()

Tambi√©n podemos combinarlo con la funci√≥n `if_else()`, una modificaci√≥n dentro de `{tidyverse}` para hacer un `if-else` vectorizado, que nos puede ayudar a **.bg-purple_light[recategorizaciones sencillas]**.

```{r}
starwars %>%
  mutate(human = if_else(species == "Human", "Human", "Not Human")) %>% 
  relocate(human, .after = name)
```


---

# .orange[RECATEGORIZAR]: case_when()

Para **.bg-purple_light[recategorizaciones m√°s complejas]** tenemos a nuestra disposici√≥n `case_when()`. Supongamos por ejemplo que queremos crear una **categor√≠a en funci√≥n de su altura**.

* Si `height > 180` ‚Äì> ser√°n `"alto"`.
* Si `height <= 180` y `height > 120` ‚Äì> ser√°n `"bajo"`
* Si `height <= 120` y `height > 0` ‚Äì> ser√°n `"enano"`
* Si no se cumple lo anterior ‚Äì> ser√°n `"ausente"`

--

```{r}
starwars %>% mutate(height = case_when(height > 180 ~ "alto",
                                       height > 120 ~ "bajo",
                                       height > 0 ~ "enano",
                                       TRUE ~ "ausente"))
```

---

# .orange[RECATEGORIZAR]: case_when()

Las condiciones de `case_when()` pueden combinar varias variables, c√≥mo por ejemplo:

* Si pesan mucho o miden mucho --> `"large"`
* Si `species == "Droid"` --> `"robot"`
* En caso contrario --> `"other"`

```{r}
starwars %>%
  mutate(type =
           case_when(height > 200 | mass > 200 ~ "large",
                     species == "Droid" ~ "robot",
                     TRUE ~ "other"))
```

---

# Ejercicios (mutate)


.panelset[
.panel[.panel-name[Ejercicios]


* üìù **Ejercicio 1**: crea tres nuevas columnas que nos digan el n√∫mero de pel√≠culas en las que han salido, el n√∫mero de veh√≠culos y el n√∫mero d naves (pero haciendo uso de mutate()). 

* üìù **Ejercicio 2**: con las 3 columnas creadas, crea una nueva columna llamada `frequency` que nos ponga `almost_all` en personajes que salen en 5 o m√°s pel√≠culas, `many` en personajes que salen en m√°s de 2 pel√≠culas pero en menos de 5 y `some` en personajes que salen 1 o 2 pel√≠culas.

* üìù **Ejercicio 3**: elimina registros con datos ausentes en la variable `birth_year` y filtra solo los 20 personajes m√°s j√≥venes.

* üìù **Ejercicio 4**: selecciona solo las variables num√©ricas y de tipo texto. Define una nueva variable llamada `under_18` que nos recategorice la variable `birth_year`: `TRUE` si es menor de edad y `FALSE` en caso contrario

]

.panel[.panel-name[Sol. Ej. 1]

```{r}
starwars_nueva <- 
  starwars %>%
  mutate(n_films = films %>% map_int(length),
         n_vehicles = vehicles %>% map_int(length),
         n_starships = starships %>% map_int(length))
starwars_nueva
```

]

.panel[.panel-name[Sol. Ej. 2]

```{r}
starwars_nueva <-
  starwars_nueva %>%
  mutate(frequency =
           case_when(n_films >= 5 ~ "almost_all",
                     n_films > 2 ~ "many",
                     TRUE ~ "some"))
starwars_nueva
```

]

.panel[.panel-name[Sol. Ej. 3]

```{r}
starwars_nueva <-
  starwars_nueva %>%
  drop_na(birth_year) %>%
  slice_min(n = 20, birth_year)
starwars_nueva
```

]

.panel[.panel-name[Sol. Ej. 4]

```{r}
starwars_nueva <-
  starwars_nueva %>%
  select(where(is.numeric) | where(is.character)) %>%
  mutate(under_18 = birth_year < 18)
starwars_nueva
```


]

]


---


# Ejercicios (mutate)


.panelset[
.panel[.panel-name[Ejercicios]

* üìù **Ejercicio 5**: de la base de datos original, determina el n√∫mero de modalidades que toma la variable `species` (elimina antes registros con ausente en dicha variable). Despu√©s elimina duplicados por dicha variable, dejando el representante m√°s bajito.

* üìù **Ejercicio 6**: sobre la base de datos original, crea una nueva columna llamada `auburn` (cobrizo/caoba) que nos diga `TRUE` si el color de pelo contiene dicha palabra y `FALSE` en caso contrario.

* üìù **Ejercicio 7**: sobre la base de datos original, filtra solo aquellos personajes de la familia `"Skywalker"` o `"Antilles"`, selecciona solo las columnas de `name` y `specie`, y renombra a castellano.


]

.panel[.panel-name[Sol. Ej. 5]

```{r}
starwars %>%
  drop_na(species) %>%
  distinct(species)

starwars %>%
  drop_na(species) %>%
  arrange(height) %>%
  distinct(species, .keep_all = TRUE)
```

]

.panel[.panel-name[Sol. Ej. 6]

```{r}
starwars %>%
  drop_na(hair_color) %>%
  mutate(auburn = str_detect(hair_color, "auburn"))
```

]

.panel[.panel-name[Sol. Ej. 6]

```{r}
starwars %>%
  filter(str_detect(name, "Skywalker") |
           str_detect(name, "Antilles")) %>%
  select(name, species) %>%
  rename(nombre = name, especie = species)
```

]
]


---

name: sup-class

# Aprendizaje .green[SUPERVISADO]

.pull-left[

* **.bg-purple_light[Aprendizaje supervisado]**: tendremos dos tipos de variables, la **.bg-orange[variable dependiente (output/target)]** que se quiere predecir/clasificar (con su valor conocido en el conjunto de entrenamiento) y las **.bg-orange[variables independientes (inputs)]** o variables explicativas, que contienen la informaci√≥n disponible.

&nbsp;

Todo lo que veremos en esta asignatura entra dentro de la idea de **aprendizaje supervisado**

]


.pull-right[


```{r echo = FALSE,  out.width = "110%", fig.align = "center", fig.cap = "Extra√≠da de https://realpython.com/knn-python/basics-of-machine-learning"}
knitr::include_graphics("./img/esquema_supervised.jpg")
``` 


]

---

# Fundamentos de la .orange[CLASIFICACI√ìN]

Como dec√≠amos en diapositivas pasadas, un problema de **.bg-purple_light[clasificaci√≥n]** constar√° de los siguientes elementos

* Una **.bg-purple_light[variable objetivo]** $Y$ que ser√° **.bg-purple_light[cualitativa]** (o cuantitativa discreta recategorizada).

--

* Dicha variable objetivo podr√° tomar un **.bg-purple_light[n√∫mero finito C de categor√≠as]** denotadas como $G = \left\lbrace 1, 2, \ldots, C \right\rbrace$).

--

* El **.bg-purple_light[conjunto de variables predictoras]** ser√° denotada como $\left(X_1, \ldots, X_p \right)$ 

--

* Nuestros datos formar√°n una **.bg-purple_light[muestra conjunta]** de tama√±o $n$ denotada como $\left\lbrace \left(x_{i, 1},...,x_{i, p}, y_i \right) \right\rbrace_{i=1,\ldots,n}$

&nbsp;

--

Si $C = 2$ diremos que es un problema de **.bg-purple_light[clasificaci√≥n binaria]**


üìö Ver ¬´The elements of Statistical Learning¬ª (Hastie et al., 2008): <https://github.com/dadosdelaplace/teaching/blob/main/data_mining/biblio/datamining_hastieetal_2008.pdf>


---

# Objetivo de la .orange[CLASIFICACI√ìN]

Nuestro **.bg-purple_light[objetivo]** primario (no siempre) ser√° conseguir que la mayor parte de etiquetas predichas $\hat{y}_i$ coincidan con su categor√≠a real $y_i$, siendo la tasa de bien clasificados una de las m√©trias m√°s importantes (no la √∫nica).

&nbsp;

* **.bg-purple_light[Accuracy]** (tasa de bien clasificados): del total de datos de tu partici√≥n, la **.bg-purple_light[proporci√≥n o % de observaciones con una etiqueta correcta]** (al ser supervisado sabemos que est√° bien y que est√° mal).


$$ACC  = \frac{1}{n} \sum_{i=1}^{n} I(y_i = \hat{y}_i)$$

A veces nos fijaremos en su complementario, la **.bg-purple_light[tasa de mal clasificados]**, siendo esta la proporci√≥n de individuos mal clasificados.

---

# M√©tricas de .orange[CLASIFICACI√ìN BINARIA]

En la mayor√≠a de ocasiones nuestros problemas ser√°n de **.bg-purple_light[clasificaci√≥n binaria]** (podemos entender las categor√≠as como $G = \left\lbrace 0, 1\right\rbrace$), ya que todo problema de clasificac√≥n multiclase se puede reducir a un conjunto de problemas binarios. En ese caso tendremos adem√°s un **.bg-purple_light[conjunto de m√©tricas]** basadas en los conceptos de falso negativo/positivo y verdadero negativo/positivo

* **.bg-purple_light[Verdadero positivo (TP)]**: todos aquellos individuos con clasificaci√≥n positiva $\hat{y}_i = 1$ y que efectivamente as√≠ lo eran $y_i = 1$

* **.bg-purple_light[Falso positivo (FP)]**: todos aquellos individuos con clasificaci√≥n positiva $\hat{y}_i = 1$ pero que no lo eran $y_i = 0$

--

* **.bg-purple_light[Verdadero negativo (TN)]**: todos aquellos individuos con clasificaci√≥n negativa $\hat{y}_i = 0$ y que efectivamente as√≠ lo eran $y_i = 0$

* **.bg-purple_light[Falso negativo (FN)]**: todos aquellos individuos con clasificaci√≥n negativa $\hat{y}_i = 0$ pero que no lo eran $y_i = 1$

---


# M√©tricas de .orange[CLASIFICACI√ìN BINARIA]

.pull-left[

* **.bg-purple_light[Verdadero positivo (TP)]**: individuos con clasificaci√≥n positiva $\hat{y}_i = 1$ y que efectivamente as√≠ lo eran $y_i = 1$

* **.bg-purple_light[Falso positivo (FP)]**: individuos con clasificaci√≥n positiva $\hat{y}_i = 1$ pero que no lo eran $y_i = 0$

* **.bg-purple_light[Verdadero negativo (TN)]**: individuos con clasificaci√≥n negativa $\hat{y}_i = 0$ y que efectivamente as√≠ lo eran $y_i = 0$

* **.bg-purple_light[Falso negativo (FN)]**: individuos con clasificaci√≥n negativa $\hat{y}_i = 0$ pero que no lo eran $y_i = 1$

]

.pull-right[


```{r echo = FALSE,  out.width = "80%", fig.align = "left", fig.cap = "Tabla extra√≠da de wikipedia"}
knitr::include_graphics("./img/contigency_table.jpg")
``` 

]

En el futuro, en la fase de evaluaci√≥n (assess) hablaremos de una herramienta conocida como **.bg-purple_light[curva ROC]**.

---



# M√©tricas de .orange[CLASIFICACI√ìN BINARIA]

En base a dichos conceptos existen otras **.bg-purple_light[m√©tricas habituales]** a tener en cuenta:

* **.bg-purple_light[Accuracy (ACC)]**: definida en el caso binario como $ACC = \frac{TP + TN}{TP+TN+FP+FN} = \frac{TP + TN}{n}$

--

* **.bg-purple_light[Sensibilidad (TPR)]**: tambi√©n conocida como True Positive Rate o **.bg-purple_light[recall]**, es la proporci√≥n de positivos reales $y_i=1$ que han sido clasificadas como  positivo $\hat{y}_i = 1$, definida como $TPR = \frac{TP}{P}$ (**.bg-purple_light[probabilidad]** emp√≠rica de **.bg-purple_light[detectar correctamente los positivos]**). Su complementario se conoce como **False Negative Rate (FNR)**.

--

* **.bg-purple_light[Especificidad (TNR)]**: tambi√©n conocida como True Negative Rate, es la proporci√≥n de negativos reales $y_i=0$ que han sido clasificadas como negativos $\hat{y}_i = 0$, definida como $TNR = \frac{TN}{N}$ (**.bg-purple_light[probabilidad]** emp√≠rica de **.bg-purple_light[detectar correctamente los negativos]**). Su complementario se conoce como **False Positive Rate (FPR)**.

&nbsp;

Desde lo te√≥rico, ambas son maximizables de forma conjunta al 100% (aunque en la pr√°ctica, una mejora en una supondr√° un coste en la otra).

---


# M√©tricas de .orange[CLASIFICACI√ìN BINARIA]

Un ejemplo reciente son las **.bg-purple_light[pruebas de detecci√≥n de covid]**. En el caso de las pruebas PCR comercializadas en Espa√±a

* la **.bg-purple_light[sensibilidad]** era en torno al 80-90%. ¬øQu√© implica el 10-20% restante?

* la **.bg-purple_light[especificidad]** era en torno al 99%. ¬øQu√© implica el 1% restante?


--

&nbsp;

Otras m√©tricas habituales que pueden ayudarnos a tomar decisiones son la **.bg-purple_light[prevalencia]**, definida como  $P / (P + N)$ (la proporci√≥n de positivos en tu poblaci√≥n) y la conocida como **.bg-purple_light[precisi√≥n (PPV)]** o Positive Predictive Value, definida como $TP / PP$ (siendo $PP$ los positivos predichos, del total de clasificados como positivos cuantos son verdaderos positivos)


üìö Ver <https://www.aemps.gob.es/la-aemps/ultima-informacion-de-la-aemps-acerca-del-covid%E2%80%9119/informacion-general-sobre-tests-de-diagnostico-de-covid-19/>

---

name: bayes

# Clasificador .orange[BAYESIANO]

M√°s all√° de la comparaci√≥n que podamos hacer entre distintos m√©todos, ¬øexiste **.bg-purple_light[alg√∫n clasificador de referencia]** contra el que compararnos? La buena noticia es que s√≠ existe, la mala noticia es que en la mayor√≠a de casos no vamos a poder conocerlo.

--

&nbsp;

Dicho clasificador se conoce como **.bg-purple_light[clasificador Bayesiano]**, y es el **.bg-purple_light[clasificador √≥ptimo]** en el sentido de que nos devuelve como clase predicha aquella que sea m√°s probable, haciendo uso de la distribuci√≥n de probabilidad te√≥rica de nuestros datos (algo que normalmente no conoceremos).


$$\hat{y_i} = j \quad \text{si} \quad  P(Y = j | X = \left(x_{i,1}, \ldots, x_{i,p} \right) =  \max_{g \in G} P(Y = g | X = \left(x_{i,1}, \ldots, x_{i,p} \right)$$

&nbsp;

En el **.bg-purple_light[caso binario]**, se asignar√° la clase 1 si $P(Y = 1|X) > 0.5$, y la clase 0 en otro
caso.


---

# Clasificador .orange[BAYESIANO]

.pull-left[

F√≠jate que el criterio √≥ptimo no es seguramente el perfecto, ni el que mejor tasa de bien clasificados proporcione: es aquel que es capaz de entender los patrones de los datos. El **.bg-purple_light[clasificador Bayesiano solo es posible si conocemos la distribuci√≥n conjunta]** de probabilidad (algo que por desgracia, no suele ser).

]

.pull-right[


```{r echo = FALSE,  out.width = "99%", fig.align = "center", fig.cap = "Hastie et al. (2008)"}
knitr::include_graphics("./img/bayes_rule.jpg")
``` 

]

---


name: knn

# Algoritmo .orange[KNN]: k-vecinos m√°s cercanos

**.bg-purple_light[Motivaci√≥n]**: imagina que quieres dedicir si vas al cine para ver o no una pel√≠cula. **.bg-purple_light[¬øQu√© proceso seguir√≠as?]**


--

Parece l√≥gico que el proceso sea **.bg-purple_light[considerar opiniones]** de tu entorno y/o de las cr√≠ticas que puedas buscar en internet. **.bg-purple_light[¬øQu√© decisiones tomar√≠as? ¬øC√≥mo ¬´algoritmizar√≠as¬ª el proceso?]**

--

1. **.bg-purple_light[N√∫mero de vecinos]**: decidir el n√∫mero $k$ de opiniones (**.bg-purple_light[k-vecinos]**) que vas a tomar cuenta (no puedes preguntar a todo el mundo ni leer todas las cr√≠ticas, pero tampoco fiarte de una sola persona).

--

2. **.bg-purple_light[¬øQu√© es ¬´entorno cercano¬ª?]** Tendremos que decidir qui√©n entra y qui√©n no en nuestro entorno m√°s cercano. ¬øCu√°l es la definici√≥n de cercano? Deberemos definir el **.bg-purple_light[concepto de cercan√≠a con una distancia]** que nos permita decidir los **.bg-purple_light[k-vecinos m√°s cercanos]**

--

3. **.bg-purple_light[Ponderaci√≥n]**: deberemos por √∫ltimo decidir si **.bg-purple_light[todas las opiniones valen lo mismo o no]**. ¬øVale lo mismo la opini√≥n de alguien muy af√≠n a ti que la de Boyero (cr√≠tico de cine)? ¬øTe f√≠as igual
de todas ellas? Deberemos decidir si estas distancias son **.bg-purple_light[ponderadas]**.

---

# Algoritmo .orange[KNN]

Tu decisi√≥n final ser√° por tanto aquella **.bg-purple_light[opini√≥n mayoritaria (moda)]** de las opiniones de tus **.bg-purple_light[k-vecinos]** **.bg-orange[m√°s cercanos]**, una vez que dichas opiniones han sido o no **.bg-green_light[ponderadas]**: 

* **.bg-purple_light[Sin poderar]**: para cada  individuo, su clasificaci√≥n ser√° asignada como la **.bg-purple_light[moda de sus k-vecinos]** m√°s cercanos.

* **.bg-purple_light[Con ponderaci√≥n]**: para cada  individuo, su clasificaci√≥n ser√° asignada como la **.bg-purple_light[moda ponderada de sus k-vecinos]** m√°s cercanos, por ejemplo tomando como peso el inverso de la distancia (cu√°nto m√°s cerca, m√°s pesa).

--

Matem√°ticamente, dado un registro $x_i = (x_{i,1},\ldots,x_{i,p})$, un n√∫mero $k$ de vecinos y una m√©trica $d()$, la **.bg-purple_light[probabilidad de pertenencia]** de $y_i$ a la **.bg-purple_light[clase j]** ser√°

$$P(y_i = j | X = x_i) = \frac{1}{k} \sum_{l=1}^{k} w_l I(y_l = j)$$

donde $x_l$, con $l=1,...,k$, son los k-vecinos m√°s cercanos en funci√≥n de $d()$ y $w_l$ es el peso de v√©cino l-√©simo (pudiendo ser todos uno si no ponderamos, o $w_l = \frac{1}{d(x_i, x_l)}$)

---


# Algoritmo .orange[KNN]

En el caso de que tengamos un problema de **.bg-purple_light[clasificaci√≥n binaria]**, el problema ser√° mucho m√°s sencillo. Dado un registro $x_i = (x_{i,1},\ldots,x_{i,p})$, un n√∫mero $k$ de vecinos y una m√©trica $d()$, la **.bg-purple_light[probabilidad de ser 1]** de $y_i$ ser√°

$$P(y_i = 1 | X = x_i) = \frac{1}{k} \sum_{l=1}^{k} w_l I(y_l = 1)$$

y la **.bg-purple_light[probabilidad de ser 0]** de $y_i$ ser√° 
$P(y_i = 0 | X = x_i) = 1- P(y_i = 1 | X = x_i)$ (su complementario).

&nbsp;

La **.bg-purple_light[clase predicha]** ser√° aquella cuya probabilidad sea mayor.

---

# Decisiones KNN: .orange[K] vecinos

.pull-left[

* **.bg-purple_light[Pocos vecinos]**: regla de decisi√≥n extremadamente flexible, creando incluso ¬´islas¬ª de un solo individuo. **.bg-purple_light[Poco sesgo y enorme varianza]** (con un dato nuevo que tuvi√©ramos, ya cambiar√≠a todo).

* **.bg-purple_light[Muchos vecinos]**: regla de decisi√≥n extremadamente r√≠gida. **.bg-purple_light[Mucho sesgo y poca varianza]** (dado que aunque tengamos inputs nuevos, apenas cambiar√°)

]

.pull-right[

```{r echo = FALSE,  out.width = "70%", fig.align = "left"}
knitr::include_graphics("./img/knn_1.jpg")
``` 

```{r echo = FALSE,  out.width = "70%", fig.align = "left"}
knitr::include_graphics("./img/knn_todos.jpg")
``` 

]

Ser√° por tanto crucial **.bg-purple_light[probar un rango de vecinos lo suficientemente amplio]** como para encontrar lo √≥ptimo.

---

# Decisiones KNN: .orange[DISTANCIA]

Lo segundo a elegir ser√° la **.bg-purple_light[distancia]** con la que se decidir√° qu√© est√° **.bg-purple_light[cerca o lejos]**.Cuando tenemos **.bg-purple_light[variables num√©ricas]** tenemos dos opciones:

* **.bg-purple_light[Distancias geom√©tricas]**: miden distancias en un plano/espacio/espacio de dimensi√≥n p.

* **.bg-purple_light[Distancias probabil√≠sticas]**: miden distancias en base par√°metros estad√≠sticos como la media o la desviaci√≥n t√≠pica.

---

# Decisiones KNN: .orange[DISTANCIA]

En el caso de las **.bg-purple_light[distancias geom√©tricas]** la m√°s habitual es la conocida como **.bg-purple_light[distancia eucl√≠dea]**, la que usamos de forma habitual.


.pull-left[

En el plano, se define como

$$d(x, y) = \sqrt{(x_1 - y_1)^2 + (x_2 - y_2)^2}$$

En el caso general en el que tengamos $p$ predictoras num√©ricas se calcular√° como

$$d(x, y) = \sqrt{\displaystyle \sum_{j=1}^{p} (x_j - y_j)^2}$$

]

.pull-right[

```{r echo = FALSE,  out.width = "80%", fig.align = "left"}
knitr::include_graphics("./img/circulo_distancia_euclidea.jpg")
``` 

C√≠rculo eucl√≠deo: conjunto de puntos a la misma distancia del centro, haciendo uso de la distancia Eucl√≠dea (el radio).

]

---

# Decisiones KNN: .orange[DISTANCIA]


Existen otro tipo de distancias geom√©tricas como la **.bg-purple_light[distancia Manhattan]**, la distancia que usas cuando caminas por la calle (dado que no puedes atravesar manzanas), definida como

$$d(x, y) = \sqrt{\displaystyle \sum_{j=1}^{p} |x_j - y_j|}$$


Otra m√©trica es la **.bg-purple_light[distancia de Chebyshev]**
 $d(x, y) = \max_i \left(|x_i - y_i| \right)$

```{r echo = FALSE,  out.width = "40%", fig.align = "center"}
knitr::include_graphics("./img/minkowski.jpeg")
``` 


--

¬øC√≥mo se definir√≠an los c√≠rculos (lugares a la misma distancia de un centro) en dichas m√©tricas?

---

# Decisiones KNN: .orange[DISTANCIA]


Todas estas m√©tricas en realidad son casos particulares de las conocidas como **.bg-purple_light[distancias de Minkowski]**, definidas en funci√≥n de un par√°metro $r$

$$d(x, y) = \left(\displaystyle \sum_{j=1}^{p} |x_j - y_j|^r\right)^{1/r}$$

.pull-left[

```{r echo = FALSE,  out.width = "100%", fig.align = "left"}
knitr::include_graphics("./img/minkowski_1.jpg")
``` 

]


.pull-right[

```{r echo = FALSE,  out.width = "100%", fig.align = "left"}
knitr::include_graphics("./img/minkowski_2.jpg")
``` 

]

Cuando $p=1$ estamos ante la distancia Manhattan, cuando $p=2$ es la distancia Eucl√≠dea, cuando $p=\infty$ es la distancia de Chebyshev.

---

# .orange[PREPROCESAMIENTO] en KNN

En el caso en el que tengamos **.bg-purple_light[predictoras num√©ricas]** y que decidamos optar por una **.bg-purple_light[distancia geom√©trica]**, en un ejemplo bidimensional, si $x_1$ toma valores entre 10 000 y 100 000 y $x_2$ toma valores entre 0 y 0.001, a la hora de calcular las distancias en realidad la **.bg-purple_light[segunda variable no est√° participando]** en el aprendizaje (ya que es tan peque√±a que da igual lo que valga).

¬øQu√© **.bg-purple_light[preprocesamiento/depuraci√≥n]** de los datos deber√≠amos hacer para que eso no suceda?

--

Cuando usamos las distancias geom√©tricas debemos **.bg-purple_light[reescalar o estandarizar por rango]**, de forma que **.bg-purple_light[todas las variables est√©n en un rango com√∫n]** (por ejempo, $[0,1]$)

$$\tilde{x}_{i,j} = \frac{x_{i,j} - min(x_j)}{max(x_j) - min(x_j)}$$

--

&nbsp;

Adem√°s necesitamos **.bg-purple_light[tratar los datos ausentes]** (lo veremos en futuras clases, si imputarles un valor o si eliminarlos).

---

# Decisiones KNN: .orange[DISTANCIA]

En el caso de las **.bg-purple_light[distancias probabil√≠sticas]** la m√°s habitual es la conocida como **.bg-purple_light[distancia de Mahalanobis]**, que tiene en cuenta las caracter√≠sticas probabil√≠sticas de los datos. En el caso **.bg-purple_light[bidimensional (con variables independientes)]**

$$d(x, y) = \sqrt{\left(\frac{x_1 - y_1}{\sigma_1} \right)^2 + \left(\frac{x_2 - y_2}{\sigma_2} \right)^2}$$

--

En el caso **.bg-purple_light[multidimensional (con variables independientes)]**

$$d(x, y) = \sqrt{\displaystyle \sum_{j=1}^{p} \left(\frac{x_j - y_j}{\sigma_j} \right)^2 }$$

---

# Decisiones KNN: .orange[DISTANCIA]

En el caso general de tener un problema **.bg-purple_light[multidimensional (con variables dependientes)]**, la idea es promediar las observaciones por la **.bg-purple_light[matriz de varianzas y covarianzas]**

$$d(x, y) = \sqrt{\displaystyle \sum_{j=1}^{p} \left(x_j - y_j \right)^{T} \Sigma^{-1} \left(x_j - y_j \right) }$$

Donde $\Sigma^{-1}$ es la **.bg-purple_light[matriz de varianzas y covarianzas]** (matriz sim√©trica)

$$\Sigma = \begin{pmatrix} \sigma_{1}^2 & cov(x_1, x_2) & \ldots & cov(x_1, x_p) \\ cov(x_2, x_1) & \sigma_{2}^2 & \ldots & cov(x_2, x_p) \\ \vdots & \vdots & \ddots & \vdots \\ cov(x_p, x_1) & cov(x_p, x_2) & \ldots & \sigma_{p}^2 \end{pmatrix}$$

---

# .orange[PREPROCESAMIENTO] en KNN

En el caso en el que tengamos **.bg-purple_light[predictoras num√©ricas]** y que decidamos optar por una **.bg-purple_light[distancia probabil√≠stica]**,  ya no ser√° tan importante los valores en s√≠ literales sino las **.bg-purple_light[caracter√≠sticas probabil√≠sticas de nuestras variables]** 

¬øQu√© **.bg-purple_light[preprocesamiento/depuraci√≥n]** de los datos deber√≠amos hacer para que eso no suceda?

--

Cuando usamos las distancias probabil√≠sticas debemos **.bg-purple_light[normalizar o estandarizar por media/varianza)]**, de forma que **.bg-purple_light[todas las variables tengan media 0 y desv. t√≠pica 1]**

$$\tilde{x}_{i,j} = \frac{x_{i,j} - \overline{x}_j}{\sigma_j}$$

---

class: inverse center middle
name: clase-6

# CLASE 6: depuraci√≥n para KNN

&nbsp;


### [Factores](#factores)

### [Fase 1: muestreo](#sample-iris)

### [Fase 2: exploraci√≥n](#exploracion-iris)

### [Fase 3: modificaci√≥n/depuraci√≥n](#depuracion-iris)


---

# Primer conjunto: iris

Para empezar con la implementaci√≥n de nuestro primer **.bg-purple_light[algoritmo de clasificaci√≥n]** vamos a usar un conjunto simple y conocido: el iris.

```{r}
iris <- as_tibble(iris)
iris
```

---

# .orange[EXPLORACI√ìN] inicial

Dentro de esa metodolog√≠a SEMMMA hay una fase muy importante: la **.bg-purple_light[fase exploratoria]**. Aunque m√°s adelante podemos volver a realizarla, una vez realizado el muestro, lo conveniente ser√≠a una **.bg-purple_light[an√°lisis exploratorio previo]** a los datos en bruto.


--

* `View()`: el primer paso deber√≠a ser ver nuestra tabla para tener una idea preliminar de nuestros datos.

```{r eval = FALSE}
iris %>% View()
```

---

# .orange[EXPLORACI√ìN] inicial


* `glimpse()`: tambi√©n podemos ejecutar algunos comandos que nos permiten saber r√°pidamente el **.bg-purple_light[n√∫mero de registros y variables]** que tenemos, as√≠ como el **.bg-purple_light[tipo de variables]** que tenemos. En nuestro caso tenemos **.bg-purple_light[5 variables]**: 4 variables num√©ricas (cuantitativas continuas) y una **.bg-purple_light[variable categ√≥rica]** (de tipo factor).

```{r}
dim(iris)
iris %>% glimpse()
```

---

name: factores


# Variables cuali: .orange[FACTORES]

.pull-left[

Las variables cualitativas se conocen en `R` como **.bg-purple_light[factores]**. Y el paquete fundamental para tratarlos es `{forcats}` (del entorno `{tidyverse}`). 

]

.pull-right[

```{r echo = FALSE,  out.width = "100%", fig.align = "left"}
knitr::include_graphics("./img/factors.jpg")
``` 

]

---

# Variables cuali: .orange[FACTORES]

Este paquete nos permite fijar los **.bg-purple_light[niveles/modalidades]** (guardados internamente como `levels`) que toma una determinada variable categ√≥rica para que no puedan generarse errores. Adem√°s hace que su an√°lisis sea menos costoso computacionalmente a la hora de hacer b√∫squedas y comparativas, d√°ndoles un **.bg-purple_light[tratamiento diferente que a las cadena de texto normales]**.

--

Veamos un ejempo sencillo definiendo una variable `estado` que tome los valores `"sano"`, `"leve"` y `"grave"` de la siguiente manera.

```{r}
estado <-
  c("leve", "grave", "sano", "sano", "leve", "sano", "sano", "grave",
    "grave", "leve", "grave", "sano", "sano")
estado
```

La variable `estado` actualmente es de **.bg-purple_light[tipo texto]**, de tipo `chr`, algo que podemos comprobar con `class(estado)`.

```{r}
class(estado)
```

---

# Variables cuali: .orange[FACTORES]


Desde un punto de vista estad√≠stico y computacional, para `R` esta variable ahora mismo ser√≠a equivalente una variable de nombres. Pero estad√≠sticamente **.bg-purple_light[no es lo mismo una variable con nombres]** (que identifican muchas veces el registro) que una variable categ√≥rica como estado que **.bg-purple_light[solo puede tomar esos 3 niveles]**. ¬øC√≥mo **.bg-purple_light[convertir a factor]**? Haciendo uso de la funci√≥n `as_factor()` del paquete `{forcats}`.

--

```{r}
library(tidyverse)
estado_fct <- tibble(paciente = 1:length(estado),
                     estado = as_factor(estado))
estado_fct
```

---

# Variables cuali: .orange[FACTORES]


No solo ha cambiado la clase de la variable sino que ahora, debajo del valor guardado, nos aparece la frase `Levels: grave leve sano`: son las **.bg-purple_light[modalidades o niveles]** de nuestra cualitativa. Imagina que ese d√≠a en el hospital no tuvi√©semos a **nadie en estado grave**: aunque ese d√≠a nuestra variable no tome dicho valor, el estado `grave` es un **.bg-purple_light[nivel permitido en la base de datos]**, as√≠ que aunque lo eliminemos, por ser un factor, el nivel permanece (no lo tenemos ahora pero es un nivel permitido).


```{r}
estado_fct %>% 
  filter(estado %in% c("sano", "leve")) %>% 
  pull(estado)
```

---

# Variables cuali: .orange[FACTORES]


Con `factor()` podemos **.bg-purple_light[especificar expl√≠citamente]** los nombres de las modalidades, incluso si son nominales u **.bg-purple_light[ordinales]**

```{r}
estado_fct <-
  tibble(paciente = 1:length(estado),
         estado = factor(estado, ordered = TRUE))
estado_fct %>% pull(estado)
```

---

# Variables cuali: .orange[FACTORES]


Con  `levels = ...` podemos indicarle expl√≠citamente el **.bg-purple_light[orden de las modalidades]**

```{r}
estado_fct <-
  tibble(paciente = 1:length(estado),
         estado = factor(estado,
                         levels = c("sano", "leve", "grave"),
                         ordered = TRUE))
estado_fct %>% pull(estado)
```



---

# Variables cuali: .orange[FACTORES]


.pull-left[

Si queremos indicarle que **.bg-purple_light[elimine un nivel no usado]** en ese momento (y que queremos excluir de la definici√≥n) podemos hacerlo con `fct_drop()`

]


.pull-right[

```{r echo = FALSE,  out.width = "100%", fig.align = "left"}
knitr::include_graphics("./img/drop_factor.jpg")
``` 

]

```{r}
estado_fct %>% 
  filter(estado %in% c("sano", "leve")) %>% 
  mutate(estado = fct_drop(estado)) %>% 
  pull(estado)
```

---

# Variables cuali: .orange[FACTORES]

.pull-left[

Al igual que podemos eliminar niveles podemos **.bg-purple_light[ampliar los niveles existentes]** (aunque no existan datos de ese nivel en ese momento) con `fct_expand()`


]


.pull-right[

```{r echo = FALSE,  out.width = "100%", fig.align = "left"}
knitr::include_graphics("./img/factor_expand.jpg")
``` 

]

```{r}
estado_fct %>% 
  mutate(estado = fct_expand(estado, c("UCI", "fallecido"))) %>% 
  pull(estado)
```

---

# Variables cuali: .orange[FACTORES]

.pull-left[

Adem√°s con `fct_explicit_na()` podemos **.bg-purple_light[asignar un nivel a los valores]** para que sea incluido dicho nivel en los an√°lisis y visualizaciones.


]


.pull-right[

```{r echo = FALSE,  out.width = "100%", fig.align = "left"}
knitr::include_graphics("./img/factor_explicit.jpg")
``` 

]

```{r}
fct_explicit_na(factor(c("a", "b", NA)))
```

---

# Variables cuali: .orange[FACTORES]


Incluso una vez definidos podemos **.bg-purple_light[reordenar los n√≠veles]** con `fct_relevel()`


```{r}
estado_fct_expand <- 
  estado_fct %>% 
  mutate(estado = fct_expand(estado, c("UCI", "fallecido"))) %>% 
  pull(estado)

estado_fct_expand %>%
  fct_relevel(c("fallecido", "leve", "sano",
                "grave", "UCI"))
  
```


---

# Variables cuali: .orange[FACTORES]

.pull-left[

Esta forma de trabajar con variables cualitativas nos permite dar una **.bg-purple_light[definici√≥n te√≥rica]** de nuestra base de datos, pudiendo incluso contar valores que a√∫n no existen (pero que podr√≠an), haciendo uso de `fct_count()`

]


.pull-right[

```{r echo = FALSE,  out.width = "70%", fig.align = "left"}
knitr::include_graphics("./img/fct_count.jpg")
``` 

]

```{r}
estado_fct %>% 
  mutate(estado = fct_expand(estado, c("UCI", "fallecido"))) %>% 
  pull(estado) %>% 
  fct_count()
```


---

# Variables cuali: .orange[FACTORES]


Los n√≠veles tambi√©n podemos **.bg-purple_light[ordenarlos por frecuencia]** con `fct_infreq()`

```{r}
estado_fct %>% 
  mutate(estado = fct_infreq(estado)) %>% 
  pull(estado) %>% 
  fct_count()
```

---

# Variables cuali: .orange[FACTORES]


A veces querremos **.bg-purple_light[agrupar niveles]**, por ejemplo, no permitiendo niveles que **.bg-purple_light[no sucedan un m√≠nimo de veces]** con `fct_lump_min(.., min = ..)` (las observaciones que no lo cumplan ir√°n a un **nivel gen√©rico** llamado `Other`, aunque se puede cambiar con el argumento `other_level`). 

.pull-left[


```{r}
estado_fct %>% 
  pull(estado) %>% 
  fct_lump_min(min = 4)
```

]

.pull-right[

```{r}
estado_fct %>% 
  pull(estado) %>% 
  fct_lump_min(min = 4,
               other_level = "otros")
```

]

---

# Variables cuali: .orange[FACTORES]


Podemos hacer algo equivalente pero en funci√≥n de su **.bg-purple_light[frecuencia relativa]** con `fct_lump_prop()`.


```{r}
estado_fct %>% 
  pull(estado) %>% 
  fct_lump_prop(prop = 0.4,
                other_level = "otros")
```


---

# Variables cuali: .orange[FACTORES]

Con `fct_reorder()` podemos tambi√©n indicar que queremos **.bg-purple_light[ordenar los factores]** en funci√≥n de una funci√≥n aplicada a otra variable.


```{r}
starwars_factor <- 
  starwars %>% 
  drop_na(height, species) %>% 
  mutate(species =
           fct_lump_min(species, min = 3,
                        other_level = "Otras"))
```

.pull-left[

```{r}
starwars_factor %>% pull(species)
```

]

.pull-right[

```{r}
starwars_factor %>%
  mutate(species = fct_reorder(species, height, mean)) %>% 
  pull(species)
```

]


---

# Ejercicios (factores)


.panelset[
.panel[.panel-name[Ejercicios]

* üìù **Ejercicio 1**: dada la variable `meses` definida debajo (definida como un vector de caracteres), convierte dicha variable a factor (solo eso)

```{r}
meses <- c("Ene", "Feb", "Mar", "Abr")
```
  
* üìù **Ejercicio 2**:  dada la variable `meses` definida debajo convierte dicha variable a factor pero indicando los niveles de forma correcta.

```{r}
meses <- c(NA, "Abr", "Ene", "Oct", "Jul", "Ene", "Sep", NA, "Feb", "Dic",
           "Jul", "Mar", "Ene", "Mar", "Feb", "Abr", "May", "Oct", "Sep",  NA,
           "Dic", "Jul", "Nov", "Feb", "Oct", "Jun", "Sep", "Oct", "Oct", "Sep")
```

  
* üìù **Ejercicio 3**: cuenta cuantos valores hay de cada mes pero teniendo en cuenta que son factores (quiz√°s haya niveles sin ser usados y de los que deber√≠a obtener un 0).

]

.panel[.panel-name[Sol. ej. 1]

```{r}
meses <- c("Ene", "Feb", "Mar", "Abr")
meses_fct <- as_factor(meses)
meses_fct
```



]

.panel[.panel-name[Sol. ej. 2]

```{r}
meses <- c(NA, "Abr", "Ene", "Oct", "Jul", "Ene", "Sep", NA, "Feb", "Dic",
           "Jul", "Mar", "Ene", "Mar", "Feb", "Abr", "May", "Oct", "Sep",  NA,
           "Dic", "Jul", "Nov", "Feb", "Oct", "Jun", "Sep", "Oct", "Oct", "Sep")

# Orden de niveles correcto e incluimos agosto aunque no haya
meses_fct <-
  factor(meses,
         levels = c("Ene", "Feb", "Mar", "Abr", "May", "Jun", "Jul", "Ago", "Sep", "Oct", "Nov", "Dic"))
meses_fct
```

]

.panel[.panel-name[Sol. ej. 3]

```{r}
meses_fct %>% fct_count()
```

]

]

---

# Ejercicios (factores)


.panelset[
.panel[.panel-name[Ejercicios]

* üìù **Ejercicio 4**: dado que hay ausentes, indica que los ausentes sea un decimotercer nivel etiquetado como "ausente".

* üìù **Ejercicio 5**: elimina los niveles no usados.

* üìù **Ejercicio 6**: ordena los niveles por frecuencia de aparici√≥n.
  
* üìù **Ejercicio 7**:  agrupa niveles de forma que todo nivel que no aparezca al menos el 7% de las veces se agrupe en un nivel llamado "otros meses"
]

.panel[.panel-name[Sol. ej. 4]

```{r}
meses_fct <- 
  meses_fct %>%
  fct_explicit_na(na_level = "ausente")
meses_fct
```

]

.panel[.panel-name[Sol. ej. 4]

```{r}
meses_fct <- 
  meses_fct %>%
  fct_drop()
meses_fct
```

]

.panel[.panel-name[Sol. ej. 6]

```{r}
meses_fct %>% 
  fct_infreq()
```

]

.panel[.panel-name[Sol. ej. 7]

```{r}
meses_fct <-
  meses_fct %>% 
  fct_lump_prop(prop = 0.07, other_level = "otros")
meses_fct
```

]
]

---

name: exploracion-inicial

# .orange[EXPLORACI√ìN] inicial

* `skim()`: con el paquete `{skimr}` podemos realizar un **.bg-purple_light[primer an√°lisis num√©rico]** muy sencillo, haciendo uso de la funci√≥n `skim()`

```{r eval = FALSE}
library(skimr)
iris %>% skim()
```

---

# ¬øCu√°l es nuestra variable .orange[OBJETIVO]?

Una vez que hemos echado un vistazo a qu√© tenemos (de forma muy muy preliminar), lo primero a hacer en un **.bg-purple_light[problema de clasificaci√≥n]** es determinar **.bg-purple_light[cu√°l es nuestra variable objetivo]**: nuestra variable $Y$ que vamos a clasificar, y que debe ser categ√≥rica.

--

En este caso nuestra variable objetivo ser√° la **.bg-purple_light[variable Species]**: vamos a intentar clasificar las flores, siendo la variable objetivo una variable que puede tomar 3 categor√≠as (algo que podemos ver y resumir con `count()`).

```{r}
iris %>% count(Species)
```

En nuestro caso la variable objetivo est√° **.bg-purple_light[balanceada]**: tenemos proporciones similares para cada una de las modalidades.

---

name: sample-iris

# Fase 1: .orange[MUESTREO]

La primera fase de la **.bg-purple_light[metodolog√≠a SEMMA]** ser√° decidir si es necesario realizar un **.bg-purple_light[muestreo]** previo (una submuestra de la muestra). ¬øC√≥mo har√≠amos un **.bg-purple_light[muestro aleatorio estratificado del 50%]**, respetando la proporci√≥n de cada clase de la variable objetivo?

--

```{r}
iris_sample <-
  iris %>% group_by(Species) %>%
  slice_sample(prop = 0.5) %>% 
  ungroup()
iris_sample %>% count(Species)
```

En nuestro caso: ¬øes necesario? No parece dado que tenemos **.bg-purple_light[muy pocas observaciones]**, as√≠ que trabajaremos con la tabla iris original.

---

name: exploracion-iris

# Fase 2: .orange[EXPLORACI√ìN]

Como ya hemos comentado, una **.bg-purple_light[primera fase exploratoria]** la podemos realizar con `skim()` (del paquete `{skimr}`).

```{r eval = FALSE}
library(skimr)
iris %>% skim()
```

```{r echo = FALSE,  out.width = "75%", fig.align = "center"}
knitr::include_graphics("./img/skim.jpg")
``` 

---

# Fase 2: .orange[EXPLORACI√ìN]

* No parece que tengamos **.bg-purple_light[problemas de codificaci√≥n o rango]**: los valores parecen valores permitidos seg√∫n lo que representa la variable.

--

* No tenemos **.bg-purple_light[datos ausentes]** (no hace falta decidir que hacemos con ellos), ya que `complete_rate` sale en todas 1 (`n_missing` est√° a cero).

--

* A la vista de los peque√±os histogramas y los percentiles, no parece que tengamos **.bg-purple_light[excesivos valores at√≠picos (outliers)]** (al menos muy evidentes, adem√°s la mediana y media se parecen entre s√≠). Quiz√°s la **.bg-purple_light[variable con mayor dispersi√≥n]** sea `Petal.Length`.

--

* Todas las **.bg-purple_light[variables predictoras son num√©ricas]**: recordemos que para aplicar las m√©tricas que conocemos en el KNN **.bg-purple_light[necesitamos que sean num√©ricas]**. En caso contrario nos tocar√≠a **.bg-purple_light[recategorizar]**

---

# Fase 2: .orange[EXPLORACI√ìN]


Otra de las acciones clave ser√° analizar c√≥mo se **.bg-purple_light[comporta la variable objetivo en funci√≥n de los valores de cada variable]**. ¬øLa longitud del s√©palo media es similar en cada especie de planta? ¬øY la anchura del p√©talo? Con ello podremos tener una idea preliminar de la **.bg-purple_light[importancia de las variables]** en la clasificaci√≥n. Para ello combinaremos `group_by()` con `summarise()` (nos construye res√∫menes num√©ricos, con la funci√≥n que le pidamos).

--

```{r}
iris %>%
  group_by(Species) %>% 
  summarise("mean_long_sep" = mean(Sepal.Length)) %>% 
  ungroup()
```

---

# Fase 2: .orange[EXPLORACI√ìN]

Podemos hacer varias a la vez usando `across()`: le tendremos que indicar las variables a recorrer, y la funci√≥n a aplicar en todas ellas.

```{r}
iris %>%
  group_by(Species) %>%
  summarise(mean = across(Sepal.Length:Petal.Width, mean)) %>% 
  ungroup()
```

---

# Fase 2: .orange[EXPLORACI√ìN]

```{r}
iris %>%
  group_by(Species) %>%
  summarise(mean = across(Sepal.Length:Petal.Width, mean)) %>% 
  ungroup()
```

Si nos fijamos en cada una de ellas:

* Las **.bg-purple_light[variables relacionadas con el s√©palo]** no parece que cambien mucho de una especie a otra: seguramente **.bg-purple_light[no sean influyentes]** en nuestra clasificaci√≥n.

* Las **.bg-purple_light[variables relacionadas con el p√©talo]** si parecen ser determinantes ya que la especie setosa tiene valores muy peque√±os. Seguramente lo m√°s complicado sea clasificar entre versicolor y virginica (se diferencia muy ligeramente)


---

# Fase 2: .orange[EXPLORACI√ìN]


Otro de los aspectos a considerar antes de tomar decisiones ser√° **.bg-purple_light[analizar la relaci√≥n entre las variables]**, empezando por la posible relaci√≥n lineal, calculando la matriz de correlaciones con las herramientas de la librer√≠a `{corrr}`. **.bg-red_light[Importante]**: solo podemos pasarle las variables num√©ricas de la tabla.

```{r}
library(corrr)
correlate(iris %>% select(where(is.numeric)))
```

---

# Fase 2: .orange[EXPLORACI√ìN]


```{r}
library(corrr)
correlate(iris %>% select(where(is.numeric)))
```


La matriz de correlaciones ser√° **siempre sim√©trica** y en la diagonal siempre ser√° 1 (podemos indicarle que queremos que nos muestre con el argumento `diagonal = ...`)

---

# Fase 2: .orange[EXPLORACI√ìN]

La matriz de correlaciones ser√° **siempre sim√©trica** y en la diagonal siempre ser√° 1 (podemos indicarle que queremos que nos muestre con el argumento `diagonal = ...`)


```{r}
correlate(iris %>% select(where(is.numeric)), diagonal = "*")
```

---

# Fase 2: .orange[EXPLORACI√ìN]


Tambi√©n podemos mostrarla algo m√°s est√©tica **.bg-red_light[redondeando los valores]** con `fashion()`

```{r}
correlate(iris %>% select(where(is.numeric))) %>% fashion()
```

---

# Fase 2: .orange[EXPLORACI√ìN]


Incluso visualizarla con el paquete `{corrplot}`

.pull-left[

```{r eval = FALSE}
library(corrplot)
cor_matrix <-
  cor(iris %>% select(where(is.numeric)))
corrplot(cor_matrix)
```

]

.pull-right[


```{r echo = FALSE,  out.width = "100%", fig.align = "center"}
knitr::include_graphics("./img/corrplot_1.jpg")
``` 

]

---

# Fase 2: .orange[EXPLORACI√ìN]



.pull-left[

```{r eval = FALSE}
corrplot(cor_matrix, method = "number")
```

]

.pull-right[


```{r echo = FALSE,  out.width = "100%", fig.align = "center"}
knitr::include_graphics("./img/corrplot_2.jpg")
``` 

]

---


# Fase 2: .orange[EXPLORACI√ìN]



.pull-left[

```{r eval = FALSE}
corrplot(cor_matrix, method = "color")
```

]

.pull-right[


```{r echo = FALSE,  out.width = "100%", fig.align = "center"}
knitr::include_graphics("./img/corrplot_3.jpg")
``` 

]

---

# Fase 2: .orange[EXPLORACI√ìN]

.pull-left[

```{r eval = FALSE}
corrplot(cor_matrix, method = "ellipse")
```

]

.pull-right[


```{r echo = FALSE,  out.width = "100%", fig.align = "center"}
knitr::include_graphics("./img/corrplot_4.jpg")
``` 

]


---

# Fase 2: .orange[EXPLORACI√ìN]


En este caso tenemos dos variables muy correlacionadas: `Petal.Length` y `Petal.Width`, con una correlaci√≥n de casi 1, lo que nos indica que nos van a aportar **.bg-red_light[informaci√≥n redundante]** una de la otra, provocando **.bg-red_light[problemas de colinealidad]**.

--


Nuestro caso ideal ser√≠a aquel en el que todas fuesen independientes (o al menos incorreladas entre s√≠, sin dependencia lineal), para **.bg-purple_light[maximizar la informaci√≥n de los datos]**. Si dos variables nos aportan lo mismo, una seguramente sobre (ya que solo nos va a aportar ruido). Veremos m√°s adelante otras herramientas para cuantificar la dependencia (no solo lineal, y no solo de variables cuanti)

--

Tambi√©n aprenderemos a **.bg-purple_light[visualizar los datos]**, un paso CLAVE en el an√°lisis exploratorio y la depuraci√≥n, pero m√°s adelante.

---

class: inverse center middle
name: clase-7

# CLASE 7: modelizando KNN con tidymodels

&nbsp;

### [Depuraci√≥n iris](#depuracion-iris)

### [Tratamiento de outliers](#outliers)

### [Resumen knn](#knn-steps)

### [¬øQu√© es tidymodels?](#tidymodels)

---

name: depuracion-iris

# Fase 3: .orange[MODIFICACI√ìN/DEPURACI√ìN]

Con la informaci√≥n obtenida de la anterior fase, en la **.bg-purple_light[fase de modificaci√≥n o depuraci√≥n]** es donde tendremos que tomar decisiones para **.bg-purple_light[preparar nuestros datos]** de manera adecuada. Y para ello ser√° **.bg-purple_light[fundamental conocer el algoritmo]** que vamos a aplicar. ¬øQu√© necesitaremos en el caso del KNN?


*  **.bg-purple_light[Tipolog√≠a de las variables]**. ¬øTodas mis variables  **.bg-orange[predictoras son num√©ricas]** o debo? ¬øMi **.bg-orange[variable objetivo]** es categ√≥rica?


*  **.bg-purple_light[Codificaci√≥n de las variables]**. ¬øTodas mis variables tienen un **.bg-orange[rango coherente]** (por ejemplo, que una variable de peso no sea negativa)? ¬øEst√°n **.bg-orange[bien codificadas]**?


* **.bg-purple_light[At√≠picos y ausentes]**. ¬øTengo **.bg-orange[valores at√≠picos (outliers)]**? En caso afirmativo, ¬øc√≥mo tratarlos? Tras tratar at√≠picos, ¬øtengo **.bg-orange[datos ausentes]**?


* **.bg-purple_light[Selecci√≥n de variables]**. ¬øNecesito seleccionar variables? ¬øTengo alguna de varianza cero (es decir, sin informaci√≥n)? ¬øTengo **.bg-orange[problemas de dependencia o colinealidad]**? ¬øPuedo resumir mi info con un conjunto nuevo de variables incorreladas (componentes principales)?


---

# Fase 3: .orange[MODIFICACI√ìN/DEPURACI√ìN]


* **.bg-purple_light[Variables dummy]**. ¬øDebo **.bg-orange[recategorizar]** variables que no sean num√©ricas? Recuerda que el kNN de momento solo sabemos hacerlo con num√©ricas (en caso contrario, veremos como ¬´dummificar¬ª variables: crear 0-1 para tener n√∫meros)


* **.bg-purple_light[A√±adir info]**. ¬øDebo **.bg-orange[crear nuevas variables]** que nos aporte info extra?

* **.bg-purple_light[Normalizar variables]**. ¬øTengo ya mis variables preparadas (tras tratar lo anterior) para la m√©trica que vaya usar (**.bg-orange[estandarizadas]** por rango o **.bg-orange[tipificadas]** por media-varianza)?

  
---

name: outliers

# Tratamiento de .orange[OUTLIERS]

Una de las partes m√°s importantes de la fase de exploraci√≥n y modificaci√≥n es la **.bg-purple_light[detecci√≥n de outliers]**, pudiendo tener diferentes definiciones de valor at√≠pico:

* **.bg-purple_light[At√≠pico respecto a media]**: ser√° un dato muy alejado de la **.bg-purple_light[media de la variable]**. ¬øCu√°nto de alejado? Una definici√≥n habitual es definir un dato at√≠pico como aquel que se aleja de la media $k$ veces la desviaci√≥n t√≠pica (un valor habitual es $k = 2.5$).

$$x_i > \overline{x} + k* s_{j} \quad \text{ o bien } \quad x_i < \overline{x} - k *s_{j}$$

Dicha definici√≥n de at√≠pico solo tendr√° sentido cuando la **.bg-purple_light[media sea representativa]** de tu distribuci√≥n, es decir, siempre y cuando tengamos cierta simetr√≠a (ya que sino, la media al ser poco robusta se perturbar√° f√°cilmente).

---

# Tratamiento de .orange[OUTLIERS]

Para detectarlos usaremos el paquete `{outliers}` y su funci√≥n `scores()`, que nos dar√° en cada caso una **.bg-purple_light["puntuaci√≥n" de cada observaci√≥n]**. En caso de que queramos **.bg-purple_light[detectarlos respecto a la media]**, le indicaremos que `type = "z"`: nos devolver√° precisamente el valor $k$ (si aplicamos valor absoluto), ya que har√° cada observaci√≥n menos la media y la dividir√° entre la desviaci√≥n t√≠pica.


```{r}
library(outliers)
abs(scores(c(1, -1, 0, 5, 2, 1.5, 0.5, -0.3, 0, 2, 1.7, 0.2, -0.8), type = "z"))
```

De forma que podamos detectar muy f√°cil los outliers en funci√≥n de los estrictos que queramos ser con ese $k$. El tipo `type = "chisq"` nos hace algo parecido pero elevando las desviaciones al cuadrado y diviendo por la varianza.

---

# Tratamiento de .orange[OUTLIERS]

En el caso de nuestros datos, usaremos $k = 2.5$, y detectaremos aquellos datos que son outliers para luego pasarlos a un **.bg-purple_light[valor ausente]**.

```{r warning = FALSE}
iris_na_outliers <- 
  iris %>% 
  mutate(Sepal.Width =
           ifelse(abs(scores(Sepal.Width, type = "z")) > 2.5,
                  NA, Sepal.Width))
iris_na_outliers
```

---

# Tratamiento de .orange[OUTLIERS]

```{r}
iris_na_outliers %>% filter(is.na(Sepal.Width))
```

Tras ello tendremos **.bg-purple_light[dos opciones]**: **.bg-orange[eliminar]** dichas observaciones o **.bg-orange[imputar la media]** sin los ausentes (dado que los hemos detectado con la media)

```{r}
# opci√≥n 1
iris_outliers <-
  iris_na_outliers %>% 
  mutate(Sepal.Width =
           ifelse(is.na(Sepal.Width), mean(Sepal.Width, na.rm = TRUE), Sepal.Width))
```

```{r}
# opci√≥n 2
iris_outliers <- iris_na_outliers %>% drop_na(Sepal.Width)
```

---

# Tratamiento de .orange[OUTLIERS]

Si queremos hacer esto con varias variables a la vez, tendremos que usar de nuevo `across()`

```{r}
iris_na_outliers <-
  iris %>% 
  mutate(across(Sepal.Length:Petal.Width,
                function(x) { ifelse(abs(scores(x, type = "z")) > 2.5, NA, Sepal.Length) }))
```

--

Con `if_any()` dentro del `filter()` podemos mostrar todo los registros detectados como outlier en alguna variable.

```{r}
iris_na_outliers %>% filter(if_any(Sepal.Length:Petal.Width, is.na))
```

---

# Tratamiento de .orange[OUTLIERS]

Trassu detecci√≥n y an√°lisis podemos o imputarles a todos la media (de la variable en cuesti√≥n) o eliminarlos.

```{r}
# opci√≥n 1
iris_outliers <-
  iris_na_outliers %>% 
  mutate(across(Sepal.Length:Petal.Width,
                function(x) { ifelse(is.na(x), mean(x, na.rm = TRUE), x) }))
```


```{r}
# opci√≥n 2
iris_outliers <-
  iris_na_outliers %>% drop_na()
```

---

# Tratamiento de .orange[OUTLIERS]

* **.bg-purple_light[At√≠pico respecto a mediana]**: ser√° un dato muy alejado de la **.bg-purple_light[mediana de la variable]**. ¬øCu√°nto de alejado? Una definici√≥n habitual (conocido como **filtro de Hampel**) es definir un dato at√≠pico como aquel que se aleja de la mediana $k$ veces la mediana de las desviaciones absolutas (conocida como $MAD = Me \left(\left| x_i - Me_x \right| \right)$). Un valor habitual es $k = 3$.

$$x_i > Me_{x} + k*MAD\quad \text{ o bien } \quad x_i< Me_{x} - k*MAD$$

Para ello nos bastar√° usar `scores()` con `type = "mad"` (y nos devolver√° de nuevo ese $k$).

```{r}
abs(scores(c(1, -1, 0, 5, 2, 1.5, 0.5, -0.3, 0, 2, 1.7, 0.2, -0.8), type = "mad"))
```

El **.bg-purple_light[valor a imputar ser√≠a la mediana]**

---


# Tratamiento de .orange[OUTLIERS]


* **.bg-purple_light[At√≠pico respecto a percentiles]**: ser√° un dato muy alejado de los **.bg-purple_light[cuartiles de la variable]**. ¬øCu√°nto de alejado? Una definici√≥n habitual es definir un dato at√≠pico como aquel que se aleja de los cuartiles 1 y 3 (percentiles 25 y 75) $k$ veces el rango intercuart√≠lico ($IQR = Q_3 - Q_1$). Un valor habitual es $k = 1.5$).

$$x_i > Q_3 + k* IQR \quad \text{ o bien } \quad x_i < Q_1 - k*IQR$$

Para ello nos bastar√° usar `scores()` con `type = "iqr"` (y nos devolver√° de nuevo ese $k$, siendo $k = 0$ para lo que est√© dentro del IQR).

```{r}
abs(scores(c(1, -1, 0, 5, 2, 1.5, 0.5, -0.3, 0, 2, 1.7, 0.2, -0.8), type = "iqr"))
```

El **.bg-purple_light[valor a imputar ser√≠a la mediana]**

---

# Tratamiento de .orange[OUTLIERS]

Existen otros procedimientos **.bg-purple_light[basados en inferencia estad√≠stica]** (muchos de ellos en el paquete `{outliers}`)

* **.bg-purple_light[Tests de Grubbs y Dixon]**: ambos test nos permiten **.bg-purple_light[detectar si el valor m√°s alto (o bajo)]** de una varibale es un outlier, pudiendo detectar un solo outlier en cada iteraci√≥n (en caso de detectarlo, deber√≠amos tratarlo y volver a ejecutar el test)

$\mathcal{H}_0: \text{valor m√°s alto/bajo no es outlier}$

$\mathcal{H}_1: \text{ valor m√°s alto/bajo s√≠ es outlier}$


&nbsp;

El test de Dixon (basado en una ordenaci√≥n) suele funcionar mejor cuando tenemos poca muestra que el test de Grubbs (basado en la media).

üìö Ver m√°s documentaci√≥n de su funcionamiento en <https://www.itl.nist.gov/div898/handbook/eda/section3/eda35h1.htm> y <https://www.statisticshowto.com/dixons-q-test/>

---

# Tratamiento de .orange[OUTLIERS]

Por ejemplo, para el de Dixon existe `dixon.test()`

```{r}
x <- c(1, -1, 0, 5, 2, 1.5, 0.5, -0.3, 0, 2, 1.7, 0.2, -0.8)
dixon.test(x, opposite = TRUE) # valor m√°s bajo
```

```{r}
x <- c(1, -1, 0, 5, 2, 1.5, 0.5, -0.3, 0, 2, 1.7, 0.2, -0.8)
dixon.test(x, opposite = FALSE) # valor m√°s alto
```

---


# Tratamiento de .orange[OUTLIERS]

* **.bg-purple_light[Test de Rosner]**: al contrario que los anteriores, nos permite **.bg-purple_light[detectar varios outliers]** a la vez, especialmente dise√±ado para evitar que un valor at√≠pico nos perturbe tanto que nos enmascare otro (basado en la media). Podemos ejecutarlo con la funci√≥n `rosnerTest()` del paquete `{EnvStats}`.

&nbsp;

**.bg-red_light[IMPORTANTE]**: la detecci√≥n de outliers deber√° combinar el an√°lisis num√©rico y la visualizaci√≥n.

üìö Ver m√°s documentaci√≥n de su funcionamiento en <https://vsp.pnnl.gov/help/vsample/rosners_outlier_test.htm>


---

# Tratamiento de .orange[OUTLIERS]

En el caso de que tengamos **.bg-purple_light[variables categoricas (factores)]** la detecci√≥n m√°s inmediata ser√≠a haciendo uso de la tabla de frecuencias proporcionada por `fct_count()`


```{r}
datos <- tibble("estado" = c(rep("grave", 18), rep("sano", 10), "muerto", "UCI"))

datos <- 
  datos %>% mutate(estado = factor(estado, levels = c("sano", "grave", "UCI", "muerto"), ordered = TRUE))
datos$estado %>% fct_count() %>% mutate(f = 100 * n/sum(n))
```

---

# Tratamiento de .orange[OUTLIERS]

Con `fct_lump_prop()` podemos **.bg-purple_light[agrupar niveles que no aparezcan un m√≠nimo]** de veces, por ejemplo que representen menos del 5% de los datos, con `prop = 0.05`. Y ese nivel "otros" podremos **.bg-purple_light[asignarle la moda]** del resto de valores.

```{r}
datos <- 
  datos %>%
  mutate(estado = fct_lump_prop(estado, prop = 0.05,
                                other_level = "otros"))
datos
```

---

# Modificaci√≥n: .orange[reescalado/tipificaci√≥n]


Por √∫ltimo, antes de poder aplicar nuestra m√©trica necesitaremos **.bg-purple_light[reescalar por rango]** (para distancias geom√©tricas, con `rescale()` del paquete `{scales}`) o **.bg-purple_light[tipificar]** (para distancias probabil√≠sticas, con `scale()`)


```{r}
# Escalado
library(scales)
iris_final <- 
  iris_outliers %>% 
  mutate(across(Sepal.Length:Petal.Width, rescale))
```


```{r}
# Tipificado
iris_final <- 
  iris_outliers %>% 
  mutate(across(Sepal.Length:Petal.Width, scale))
```


---

name: knn-steps

# .orange[EXPLORACI√ìN] y .green[MODIFICACI√ìN]

* **.bg-purple_light[Muestreo]**:
  - ¬øHace falta? ¬øEstratificado? ¬øTenemos la variable objetivo balanceada?

* **.bg-purple_light[Exploraci√≥n]**:
  - Res√∫menes num√©ricos (¬øsimetr√≠a? ¬ødispersi√≥n? ¬øausentes? ¬øcodificaci√≥n?)
  - Dependencia entre variables (correlaci√≥n, dependencia, predictoras vs objetivo)
  - Visualizaci√≥n de datos (pendiente)

* **.bg-purple_light[Depuraci√≥n/modificaci√≥n]**:
  - An√°lisis de outliers (¬øse imputan? ¬øse mandan a NA? ¬øse eliminan?)
  - Tratamiento de ausentes (¬øse imputan? ¬øse eliminan?)
  - Selecci√≥n de variables (¬øcolinealidad? ¬øvarianza cero? ¬ønecesitamos tener solo num√©ricas?)
  - Recategorizar (dummy,cuanti a cuali, codificaci√≥n etc)
  - Estandarizar para m√©tricas (rango y media-varianza)
  - Crear nuevas variables
  
---

# Caso concreto: .orange[KNN EN IRIS]

* **.bg-purple_light[Muestreo]**:
  - **¬øHace falta?**  --> En el caso del `iris` no necesitamos hacerlo ya que tenemos pocas observaciones y adem√°s la variable objetivo est√° balanceada, algo que podemos comprobar f√°cil con `count()` (podemos usar `mutate()` para construir la tabla de frecuencias).
  
```{r}
iris %>%
  count(Species) %>%
  mutate(porc = 100 * n/sum(n))
```

---

# Caso concreto: .orange[KNN EN IRIS]

* **.bg-purple_light[Exploraci√≥n]**:
  - Res√∫menes num√©ricos (¬øsimetr√≠a? ¬ødispersi√≥n? ¬øausentes? ¬øcodificaci√≥n?)

.pull-left[

```{r eval = FALSE}
library(skimr)
iris %>% skim()
```

]

.pull-right[

```{r echo = FALSE,  out.width = "100%", fig.align = "center"}
knitr::include_graphics("./img/skim.jpg")
``` 

]

No parece que tengamos **.bg-purple_light[problemas de codificaci√≥n o rango]** y tampoco tenemos **.bg-purple_light[datos ausentes]** (`complete_rate` sale en todas 1). La **.bg-purple_light[variable con mayor dispersi√≥n]** es `Petal.Length`.

---

# Caso concreto: .orange[KNN EN IRIS]

* **.bg-purple_light[Exploraci√≥n]**:
  - Dependencia entre variables (correlaci√≥n, dependencia, **predictoras vs objetivo**)

```{r}
iris %>%
  group_by(Species) %>%
  summarise(mean = across(Sepal.Length:Petal.Width, mean)) %>% 
  ungroup()
```

Las **.bg-purple_light[variables relacionadas con el s√©palo]** no parece que cambien mucho de una especie a otra. Las **.bg-purple_light[variables relacionadas con el p√©talo]** si parecen ser determinantes ya que la especie setosa tiene valores muy peque√±os. Seguramente lo m√°s complicado sea clasificar entre versicolor y virginica (se diferencian muy ligeramente)

---

# Caso concreto: .orange[KNN EN IRIS]

* **.bg-purple_light[Exploraci√≥n]**:
  - Dependencia entre variables (**correlaci√≥n**, dependencia, predictoras vs objetivo)

```{r}
library(corrr)
library(corrplot)
correlate(iris %>% select(where(is.numeric)))
# corrplot(iris %>% %>% select(where(is.numeric)) %>% cor())
```

Parece que hay una **.bg-purple_light[alt√≠sima correlaci√≥n]** entre la anchura y la longitud del s√©palo (alguna habr√° que eliminar en la siguiente fase para evitar problemas de colinealidad)

---

# Caso concreto: .orange[KNN EN IRIS]

* **.bg-purple_light[Depuraci√≥n/modificaci√≥n]**:
  - **An√°lisis de outliers** --> en este caso a las dos primeras variables (muy sim√©tricas) detectaremos por la media, en las dos √∫ltimas por mediana y lo pasamos a ausente.

```{r}
iris_na_outliers <- 
  iris %>% 
  mutate(across(Sepal.Length:Sepal.Width,
                function(x) { ifelse(abs(scores(x, type = "z")) > 2.5, NA, x) }),
         across(Petal.Length:Petal.Width,
                function(x) { ifelse(abs(scores(x, type = "mad")) > 3, NA, x) }))
iris_na_outliers %>% 
  filter(if_any(Sepal.Length:Petal.Width, is.na))
```

---

# Caso concreto: .orange[KNN EN IRIS]

* **.bg-purple_light[Depuraci√≥n/modificaci√≥n]**:
  - Tratamiento de **ausentes** --> en este caso los imputaremos por media en las dos primeras y por mediana en las dos segundas.
  

```{r}
iris_outliers <- 
  iris_na_outliers %>% 
  mutate(across(Sepal.Length:Sepal.Width,
                function(x) { ifelse(is.na(x), mean(x, rm.na = TRUE), x) }),
         across(Petal.Length:Petal.Width,
                function(x) { ifelse(is.na(x), median(x, rm.na = TRUE), x) }))
```

---

# Caso concreto: .orange[KNN EN IRIS]

* **.bg-purple_light[Depuraci√≥n/modificaci√≥n]**:

  - Selecci√≥n de variables (¬øcolinealidad? ¬øvarianza cero? ¬ønecesitamos tener solo num√©ricas?) --> en este caso ya tenemos solo predictoras num√©ricas y no tenemos varianza cero (variables de constantes), as√≠ que solo necesitamos **.bg-purple_light[volver a mirar correlaci√≥n]**
  
  
```{r}
correlate(iris_outliers %>% select(where(is.numeric)))
```

Seguimos observando una alta correlaci√≥n entre `Petal.Length` y `Petal.Width`: eliminaremos la primera ya que es la que tiene una correlaci√≥n m√°s alta (en valor absoluto) con las dem√°s

```{r}
iris_colin <-
  iris_outliers %>% select(-Petal.Length)
```

---
  
# Caso concreto: .orange[KNN EN IRIS]

* **.bg-purple_light[Depuraci√≥n/modificaci√≥n]**:
  
  - **Recategorizar** --> no necesitamos hacerlo en este caso
  - Crear **nuevas variables** --> no necesitamos hacerlo en este caso
  - **Estandarizar** para m√©tricas --> vamos a usar distancias geom√©tricas as√≠ que habr√° que normalizar por rango.

```{r}
library(scales)
iris_final <-
  iris_colin %>% 
  mutate(across(c(everything(), -Species), rescale))
iris_final
```

  
---

# Caso concreto: .orange[KNN EN IRIS]

Este ser√≠a el **.bg-purple_light[c√≥digo completo de nuestra depuraci√≥n]**

```{r}
iris_final <-
  iris %>% 
  mutate(across(Sepal.Length:Sepal.Width,
                function(x) { ifelse(abs(scores(x, type = "z")) > 2.5,
                                     mean(x, rm.na = TRUE), x) }),
         across(Petal.Length:Petal.Width,
                function(x) { ifelse(abs(scores(x, type = "mad")) > 3,
                                     median(x, rm.na = TRUE), x) })) %>% 
  select(-Petal.Length) %>% mutate(across(c(everything(), -Species), rescale))
iris_final
```


---

name: tidymodels

# Modelando con .orange[TIDYMODELS]

Una vez que sabemos que proceso necesitamos aplicar a los datos, vamos a introducirnos en la idea del **.bg-purple_light[tidymodels]**: un marco de trabajo, bajo los principios de tidyverse, para aplicar **.bg-purple_light[modelos Machine Learning]**. Puedes ver documentaci√≥n en <https://www.tidymodels.org/>

.pull-left[

```{r eval = FALSE}
install.packages("tidymodels")
library(tidymodels)
```

```{r echo = FALSE}
library(tidymodels)
```

]

.pull-right[

```{r echo = FALSE,  out.width = "80%", fig.align = "left"}
knitr::include_graphics("./img/tidymodels.jpg")
``` 

]

---

# Modelando con .orange[TIDYMODELS]

En uno de los paquetes de `{tidymodels}`, el paquete `{rsample}`, nos proporciona **.bg-purple_light[herramientas para generar particiones]** de train-validaci√≥n-test al inicio de nuestro proceso.

--

&nbsp;

Usaremos la funci√≥n `initial_split()`, de forma estratificada por la variable objetivo con

* `strata = Species` indic√°ndole la variable por la que estratificar
* `prop = 0.7` indic√°ndole que el 70% ser√° train y el 30% test (de momento sin validaci√≥n).

```{r}
library(tidymodels)
iris_split <- initial_split(iris, strata = Species, prop = 0.7)
```

**.bg-red_light[IMPORTANTE]**: la partici√≥n deber√° hacer siempre DESPU√âS de un posible muestreo (si fuese necesario).



---

# Modelando con .orange[TIDYMODELS]

En `iris_split` no se **.bg-purple_light[ejecutado nada]**: solo est√°n guaradas las **.bg-purple_light[instrucciones]**.

.pull-left[

```{r}
iris_split
```

]

.pull-right[

```{r}
iris_train <- training(iris_split)
iris_test <- testing(iris_split)
```

]

--

Tras aplicar las instrucciones, comprobamos la estratificaci√≥n.

```{r}
iris_train %>% count(Species) %>% mutate(porc = n / sum(n))
```

---

# Modelando con .orange[TIDYMODELS]

La idea detr√°s de la filosof√≠a  de `{tidymodels}` es tratar por separado la **.bg-purple_light[depuraci√≥n]** de los datos, el **.bg-purple_light[modelo]** o paradigma de aprendizaje que se quiere aplicar, la **.bg-purple_light[optimizaci√≥n de los par√°metros]** de dicho modelo, el **ajuste**, la **evaluaci√≥n** y la **predicci√≥n** correspondiente.

El objetivo ser√° crear un **.bg-purple_light[flujo de trabajo flexible]**, con una filosof√≠a similar a la que hay detr√°s de cocinar un plato:

* **.bg-purple_light[Escribimos la receta]**: una lista de pasos e instrucciones.

* **.bg-purple_light[Preparamos los utensilios de cocina]**: en nuestro caso, el modelo.

* **.bg-purple_light[Cocinamos]**: con la receta + utensilios podemos **.bg-purple_light[cocinar el plato muchas veces]**, con **.bg-purple_light[distintos lotes de ingredientes (datos)]**.

Tambi√©n podemos aplicar una **.bg-purple_light[receta distinta a distintos ingredientes]**, o incluso **.bg-purple_light[combinar partes de dos recetas]**. 

---

# Modelando con .orange[TIDYMODELS]

El primer paso en nuestra receta ser√° indicarle en `recipe()` los **.bg-purple_light[datos]** y la **.bg-purple_light[¬´f√≥rmula¬ª]** de nuestro modelo (en nuestro caso le indicaremos que vamos la objetivo ser√° `Species` frente al resto de predictoras num√©ricas). La receta **.bg-purple_light[guardar√° los roles]**: 4 predictoras y 1 objetivo

```{r}
iris_rec <- recipe(data = iris_train, Species ~ .)
```

.pull-left[

```{r}
iris_rec
```

]

.pull-right[

```{r}
summary(iris_rec)
```

]


---

# Modelando con .orange[TIDYMODELS]

Una receta puede **.bg-purple_light[asignar varios roles]** a cada variable: una variable puede ser `predictor`, `outcome` o cualquier otro rol no predefinido.

* `update_role()`: **.bg-purple_light[modifica]** el rol (lo crea si no tiene, borra si lo ten√≠a).

```{r}
iris_rec <-
  recipe(data = iris_train, Species ~ .) %>% 
  update_role(starts_with("Sepal"), new_role = "sepal") %>% 
  update_role(starts_with("Petal"), new_role = "petal")
```

.pull-left[

```{r}
iris_rec
```

]

.pull-right[

```{r}
summary(iris_rec)
```

]

---

# Modelando con .orange[TIDYMODELS]

* `add_role()`: **.bg-purple_light[a√±ade]** un rol a una variable que ya tiene uno (no borra el ya existente)

```{r}
iris_rec <-
  iris_rec %>% 
  add_role(ends_with("Length"), new_role = "length") %>% 
  add_role(ends_with("Width"), new_role = "width")
```

.pull-left[

```{r}
iris_rec
```

]

.pull-right[

```{r}
summary(iris_rec)
```

]

---

# Modelando con .orange[TIDYMODELS]

* `remove_role()`: **.bg-purple_light[elimina]** un rol ya existente

```{r}
iris_rec <-
  iris_rec %>% remove_role(ends_with("Length"), old_role = "length") %>% 
  remove_role(ends_with("Width"), old_role = "width") %>% 
  remove_role(starts_with("Sepal"), old_role = "sepal") %>% 
  remove_role(starts_with("Petal"), old_role = "petal")
```

.pull-left[

```{r}
iris_rec
```

]

.pull-right[

```{r}
summary(iris_rec)
```

]

---

# Modelando con .orange[TIDYMODELS]

La idea es que las acciones que hagamos de depuraci√≥n podremos **.bg-purple_light[personalizarlas para cada tipo de rol]**. La idea es **.bg-purple_light[a√±adir pasos]** la `recipe()`, algo as√≠ como la receta escrita que tenemos guardada en un caj√≥n para preparar un plato: la receta por s√≠ sola no te cocina, simplemente es una lista de instrucciones, lista para cuando la necesites.

&nbsp;

Las funciones que empiezan por `step_...()` tienen **.bg-purple_light[implementadas muchas de las funcionalidades tidyverse]**: la diferencia al incluirlo en la receta es que se **.bg-purple_light[ejecutar√° en todas las particiones]** cada vez que dicha receta se aplique (pudi√©ndose aplicar a diferentes modelos).

* `step_arrange()`
* `step_filter()`
* `step_count()`
* `step_mutate()`
* `step_select()`

---

# Modelando con .orange[TIDYMODELS]

En nuestro caso, en la receta indicaremos la **.bg-purple_light[lista de acciones que hemos decidido]** en diapositivas anteriores (con `step_...()`)


```{r}
iris_rec <-
  recipe(data = iris_train, Species ~ .) %>%
  step_mutate(across(Sepal.Length:Sepal.Width,
                     function(x) { ifelse(abs(scores(x, type = "z")) > 2.5, mean(x, rm.na = TRUE), x) }),
              across(Petal.Length:Petal.Width,
                     function(x) { ifelse(abs(scores(x, type = "mad")) > 3, median(x, rm.na = TRUE), x) })) %>% 
  step_select(-Petal.Length) %>%
  step_mutate(across(c(everything(), -Species), rescale))
```


---

# Modelando con .orange[TIDYMODELS]


```{r}
iris_rec
```

---

# .orange[TIDYMODELS]: .green[RECIPE]

Lo hecho anteriormente es una traducci√≥n literal (con `step_...()`) de lo que sab√≠amos hacer con tidyverse. Pero adem√°s de todo eso tendremos **.bg-purple_light[muchas funciones concretas para facilitar]** la depuraci√≥n de nuestras variables (por roles).

--

Dado que el tratamiento de outliers lo estamos haciendo de manera distinta en las variables de s√©palo que en las de p√©talo, lo primero que haremos es **.bg-purple_light[asignar]** roles (sin eliminar el rol de predictor que ya tiene, as√≠ que lo haremos con `add_role()`)

```{r}
iris_rec <-
  recipe(data = iris_train, Species ~ .) %>%
  add_role(starts_with("Sepal"), new_role = "sepal") %>% 
  add_role(starts_with("Petal"), new_role = "petal")
```


---

# .orange[TIDYMODELS]: .green[RECIPE]

Tras ello **.bg-purple_light[detectaremos outliers]** (transformando a `NA`)

```{r}
iris_rec <-
  iris_rec %>% 
  step_mutate(across(starts_with("Sepal"), function(x) { ifelse(abs(scores(x, type = "z")) > 2.5, NA, x) }),
              across(starts_with("Petal"), function(x) { ifelse(abs(scores(x, type = "mad")) > 3, NA, x) }))
```

--

Y decidiremos c√≥mo **.bg-purple_light[tratar los ausentes]** (los existentes y los generados al detectar los outliers). Tenemos much√≠simas funciones para ello (ver `step_impute_...()`):

.pull-left[

* `step_impute_mean()`, `step_impute_median()` y `step_impute_mode()`: imputamos por media, mediana o moda.

* `step_impute_knn()`: usaremos un knn previo para imputar los ausentes.

]

.pull-right[

```{r}
iris_rec <-
  iris_rec %>% 
  step_impute_mean(has_role("sepal")) %>% 
  step_impute_median(has_role("petal"))
```

F√≠jate la **.bg-purple_light[utilidad de los roles]**: con `has_role()` podemos indicarle a qu√© variables aplicar la acci√≥n.

]

---

# .orange[TIDYMODELS]: .green[RECIPE]

Para tratar los **.bg-purple_light[problemas de colinealidad]** usaremos directamente `step_corr()`, al que le tendremos que pasar un umbral en `threshold`: se queda solo con una variable de todo par de variables cuya **.bg-purple_light[correlaci√≥n en valor absoluto supere el umbral]** (en este caso usaremos `all_numeric_predictors()` para considerar solo las predictoras num√©ricas)


```{r}
iris_rec <-
  iris_rec %>% 
  step_corr(all_numeric_predictors(), threshold = 0.9)
```


--

Por √∫ltimo, le indicaremos con `step_range()` que nos **.bg-purple_light[normalice por rango]** las variables predictoras que sean num√©ricas, y a√±adimos siempre un √∫ltimo **.bg-purple_light[filtro de cero varianza]** para que nos elimine las variables con varianza constante.


```{r}
iris_rec <-
  iris_rec %>%
  step_range(all_numeric_predictors()) %>% 
  step_zv(all_predictors())
```

---

# .orange[TIDYMODELS]: .green[RECIPE]


Esta ser√° por tanto nuestra **receta completa**:

```{r}
iris_rec <-
  # F√≥rmula y datos
  recipe(data = iris_train, Species ~ .) %>%
  # Roles
  add_role(starts_with("Sepal"), new_role = "sepal") %>% 
  add_role(starts_with("Petal"), new_role = "petal") %>% 
  # Detectar outliers
  step_mutate(across(starts_with("Sepal"), function(x) { ifelse(abs(scores(x, type = "z")) > 2.5, NA, x) }),
              across(starts_with("Petal"), function(x) { ifelse(abs(scores(x, type = "mad")) > 3, NA, x) })) %>% 
  # Imputar ausentes
  step_impute_mean(has_role("sepal")) %>% 
  step_impute_median(has_role("petal")) %>% 
  # Filtro de correlaci√≥n
  step_corr(all_numeric_predictors(), threshold = 0.9) %>% 
  # Normalizar por rango
  step_range(all_numeric_predictors()) %>% 
  # Filtro de cero varianza
  step_zv(all_predictors())
```

---

# .orange[TIDYMODELS]: .green[RECIPE]

```{r}
iris_rec
```

---

# .orange[TIDYMODELS]: .green[RECIPE]

Tras ¬´redactar¬ª la receta **.bg-purple_light[hornear la receta]** a unos datos, haciiendo uso de `bake()`, y en `new_data` le podemos indicar el dataset al que aplicaremos la receta (si `new_data = NULL`, se har√° con el conjunto de entrenamiento).

```{r}
bake(iris_rec %>% prep(), new_data = NULL)
```
  

---

# Fase 4: .orange[MODELIZACI√ìN]


Tras la receta vamos a **.bg-purple_light[definir el modelo en abstracto]**, sin pasarle a√∫n datos

* `nearest_neighbor()`: definimos el modelo KNN
  - `mode = ...`: puede ser **"classification"** o **"regression"**
  - `neighbors = ...`: n√∫mero k de vecinos.
  - `weight_func = ...`: m√©todo de ponderaci√≥n de distancias. Las diferentes opciones de las puedes ver en <https://epub.ub.uni-muenchen.de/1769/>
  - `dist_power = ...`: exponente a usar en nuestra familia de m√©tricas de Minkowski
  
* `set_engine("kknn")`: motor interno que usa para optimizar el modelo.
  
```{r}
knn_model <-
  nearest_neighbor(mode = "classification", neighbors = 10,
                   weight_func = "inv", dist_power = 2) %>%
  set_engine("kknn") # ¬´motor interno¬ª que realiza el ajuste
```


---

# Fase 4: .orange[MODELIZACI√ìN]


```{r}
knn_model <-
  nearest_neighbor(mode = "classification", neighbors = 10,
                   weight_func = "inv", dist_power = 2) %>%
  set_engine("kknn") # ¬´motor interno¬ª que realiza el ajuste
knn_model
```



---

# .orange[TIDYMODELS]: .green[FLUJO]


* Tenemos una **.bg-purple_light[receta]** para preprocesar los datos, una lista de instrucciones.
* Tenemos los **.bg-purple_light[utensilios de cocina]** (modelo).
* Tenemos los **.bg-purple_light[ingredientes (datos)]**

Todo ello lo **.bg-purple_light[juntaremos en un flujo de trabajo]** con `workflow()`

```{r}
iris_wflow <-
  workflow() %>% add_recipe(iris_rec) %>% add_model(knn_model)
iris_wflow
```


---

# .orange[TIDYMODELS]: .green[AJUSTE]

El siguiente paso, una vez que tenemos construido el flujo de trabajo, es **.bg-purple_light[aplicarlo al conjunto de entrenamiento]** con `fit(data = iris_train)` (es aqu√≠ donde el algoritmo aprender√° del conjunto de entrenamiento, aunque en el caso de knn deber√° calcular siempre la distancia de cada punto al resto)

```{r}
iris_knn_fit <- iris_wflow %>% fit(data = iris_train)
iris_knn_fit
```

---

# Fase 5: .orange[PREDICCI√ìN Y EVALUACI√ìN]


Tras realizar el ajuste, con `predict()` podremos **.bg-purple_light[obtener las predicciones]** de `Species` de nuestro **.bg-purple_light[conjunto de test]** (en este caso concreto del knn, lo que har√° ser√° calcular los vecinos de cada registro de test usando los registros de train)

```{r}
predict(iris_knn_fit, iris_test)
```

---

# Fase 5: .orange[PREDICCI√ìN Y EVALUACI√ìN]


Recuerda que el objetivo de estos algoritmos es **.bg-purple_light[estimar aquellas probabilidades de pertenencia]** te√≥ricas del clasificador Bayesiano (y que desconocemos), algo que podemos obtener a√±adiendo `type = "prob"`

```{r}
predict(iris_knn_fit, iris_test, type = "prob")
```

---

# Fase 5: .orange[PREDICCI√ìN Y EVALUACI√ìN]


En muchas ocasiones querremos tener una **.bg-purple_light[visi√≥n conjunta]**: ver la clasificaci√≥n realizada de cada registro pero tambi√©n ver los valores de cada registro, juntando en una sola tabla los datos originales y las predicciones con `augment()`

```{r}
prob_test <- augment(iris_knn_fit, iris_test)
prob_test
```

---

# Fase 5: .orange[PREDICCI√ìN Y EVALUACI√ìN]


La **.bg-purple_light[matriz confusi√≥n]** de verdaderos positivos y negativos, y falsos positivos y negativos, de la que saldr√°n todas las m√©tricas que usemos para **.bg-purple_light[evaluar nuestro modelo]** se podr√°n obtener con `conf_mat(truth = ..., estimate = ...)`, indic√°ndole la **.bg-purple_light[columna con la clase real]** y la **.bg-purple_light[columna con la clase predicha]** (que como ves le podemos cambiar el nombre si queremos, por defecto es `.pred_class`)

```{r}
conf_mat_test <- 
  prob_test %>%
  rename(pred_species = .pred_class) %>% 
  conf_mat(truth = Species, estimate = pred_species)
conf_mat_test
```

---

# Fase 5: .orange[PREDICCI√ìN Y EVALUACI√ìN]

Por √∫ltimo podemos  **.bg-purple_light[obtener la mayor√≠a de m√©tricas]** haciendo uso de `summary()`, aplicado a dicha matriz de confusi√≥n

```{r}
conf_mat_test %>% summary()
```

---

# Fase 5: .orange[PREDICCI√ìN Y EVALUACI√ìN]


```{r}
conf_mat_test %>%
  summary() %>%
  filter(.metric %in% c("accuracy", "sens", "spec"))
```

F√≠jate que aunque no sea un problema de clasificaci√≥n binaria nos proporciona m√©tricas como la sensibilidad y especificidad: lo que es, **.bg-purple_light[para cada clase, construir una matriz de confusi√≥n]** (ser setosa vs no serlo, ser virginica vs no serlo, ser versicolor vs no serlo), y devuelve la **.bg-purple_light[media de las tres sensibilidad o especificidades]**


---

class: inverse center middle
name: clase-8

# CLASE 8: profundizando en tidymodels

&nbsp;

### [Repaso knn en iris](#repaso-knn-iris)

### [Complicamos el asunto: hoteles](#knn-hoteles)

### [Fase 2: exploratorio](#fase2-hoteles)

### [Fase 3: modificaci√≥n](#fase3-hoteles)

### [Fase 4: modelizaci√≥n](#fase4-hoteles)

### [Fase 5: evaluaci√≥n](#fase5-hoteles)

---


# Fase 1: .orange[¬øMUESTREO?]

```{r}
iris %>%
  count(Species) %>%
  mutate(porc = 100 * n/sum(n))
```

En el caso del `iris` no necesitamos hacerlo ya que tenemos pocas observaciones y, adem√°s, la **.bg-purple_light[variable objetivo est√° balanceada]**

---

# Fase 2: .orange[EXPLORACI√ìN]

* **.bg-purple_light[Resumen num√©rico]**: ausentes, medidas de centralizaci√≥n, medidas de dispersi√≥n, problemas de codificaci√≥n, etc.

.pull-left[

```{r eval = FALSE}
library(skimr)
iris %>% skim()
```

]

.pull-right[

```{r echo = FALSE,  out.width = "100%", fig.align = "center"}
knitr::include_graphics("./img/skim.jpg")
``` 

]

---

# Fase 2: .orange[EXPLORACI√ìN]

* **.bg-purple_light[Dependencia]**: correlaci√≥n entre predictoras, **predictoras vs objetivo**

```{r}
iris %>%
  group_by(Species) %>% summarise(mean = across(where(is.numeric), mean)) %>% 
  ungroup()
```

```{r}
library(corrplot)
cor_matrix <- iris %>% select(where(is.numeric)) %>% cor()
cor_matrix
# corrplot(iris %>% %>% select(where(is.numeric)) %>% cor())
```

---

# .orange[PARTICIONES]

```{r}
# Partici√≥n 70-30% de train y test (solo instrucciones)
iris_split <- initial_split(iris, strata = Species, prop = 0.7)
iris_split

# Aplicamos partici√≥n (ejecuta instrucciones)
iris_train <- training(iris_split)
iris_test <- testing(iris_split)

# Comprobamos estratos
iris_train %>% count(Species) %>% mutate(porc = 100 * n / sum(n))
iris_test %>% count(Species) %>% mutate(porc = 100 * n / sum(n))
```

---

# Fase 3: .orange[MODIFICACI√ìN]


* **.bg-purple_light[Receta y roles]**: lo primero es **.bg-orange[definir la receta]** (indicando la partici√≥n de train y la objetivo vs todas) y los **.bg-orange[roles]** de las variables (permitiendo una depuraci√≥n personalizada)

```{r}
# Receta
iris_rec <-
  recipe(data = iris_train, Species ~ .) %>%
  # Roles
  add_role(starts_with("Sepal"), new_role = "sim√©trica") %>% 
  add_role(starts_with("Petal"), new_role = "no sim√©trica")
iris_rec
```

---

# Fase 3: .orange[MODIFICACI√ìN]


* **.bg-purple_light[Tipolog√≠a de las variables]** --> todas las predictoras son num√©ricas (no necesito recategorizar o dummys)

*  **.bg-purple_light[Codificaci√≥n de las variables]** --> todas mis variables tienen un **.bg-orange[rango coherente]**

* **.bg-purple_light[At√≠picos y ausentes]**. ¬øTengo **.bg-orange[valores at√≠picos (outliers)]**? 


```{r}
iris_rec <-
  iris_rec %>%
  # Detectar outliers
  step_mutate(across(starts_with("Sepal"),
                     function(x) { ifelse(abs(scores(x, type = "z")) > 2.5, NA, x) }),
              across(starts_with("Petal"),
                     function(x) { ifelse(abs(scores(x, type = "mad")) > 3, NA, x) }))
```

---

# Fase 3: .orange[MODIFICACI√ìN]


* **.bg-purple_light[Ausentes]**: ¬øtengo **.bg-orange[datos ausentes]**? ¬øC√≥mo los imputo?

```{r}
iris_rec <-
  iris_rec %>%
  # Imputar ausentes
  step_impute_mean(has_role("sim√©trica")) %>% 
  step_impute_median(has_role("no sim√©trica"))
```

* **.bg-purple_light[A√±adir info]** --> en este caso no necesito **crear nuevas variables** que nos aporte info extra

---

# Fase 3: .orange[MODIFICACI√ìN]

* **.bg-purple_light[Selecci√≥n de variables]**. ¬øNecesito seleccionar variables? ¬øTengo **.bg-orange[problemas de dependencia o colinealidad]**? ¬øTengo alguna de varianza cero (es decir, sin informaci√≥n)? 

* **.bg-purple_light[Normalizar variables]**. ¬øTengo ya mis variables preparadas (tras tratar lo anterior) para la m√©trica que vaya usar?


```{r}
iris_rec <-
  iris_rec %>%
  # Filtro de correlaci√≥n
  step_corr(all_numeric_predictors(), threshold = 0.9)%>% 
  # Filtro de cero varianza
  step_zv(all_predictors()) %>%
  # Normalizar por rango
  step_range(all_numeric_predictors())
```

---

# .orange[HORNEADO]

**.bg-purple_light[Horneamos la receta]** sobre las particiones para comprobar que la fase 3 se ha realizado correctamente

```{r}
bake(iris_rec %>% prep(), new_data = NULL)
bake(iris_rec %>% prep(), new_data = iris_test)
```

---

# Fase 4: .orange[MODELADO]

Definimos los **.bg-purple_light[par√°metros de nuestro modelo]**

```{r}
# Modelo knn
knn_model <-
  nearest_neighbor(mode = "classification", neighbors = 10,
                   weight_func = "inv", dist_power = 2) %>%
  set_engine("kknn") # el ¬´motor¬ª que realiza el ajuste
knn_model
```

---

# .orange[FLUJO Y AJUSTE]: receta (fase 3) + modelo (fase 4)

```{r}
# Flujo
iris_wflow <-
  workflow() %>%
  add_recipe(iris_rec) %>%
  add_model(knn_model)

# Ajuste
iris_knn_fit <- iris_wflow %>% fit(data = iris_train)
```

---

# Fase 5: .orange[PREDICCI√ìN/EVALUACI√ìN]

Usando `predict()` obtenemos las predicciones (usando el ajuste, y le proporcionamos un archivo a clasificar, en este caso test). Nos **.bg-purple_light[devuelve la clase predicha]** 

```{r}
# Predecir el conjunto test: devuelve la clase
predict(iris_knn_fit, iris_test)
```

---

# Fase 5: .orange[PREDICCI√ìN/EVALUACI√ìN]

Con `type = prob` obtenemos la **.bg-purple_light[probabilidad estimada de pertenencia]** a cada clase predicha (recuerda que nuestro objetivo es estimar las probabilidades de pertenencia te√≥ricas que nos dar√≠a el clasificador Bayesiano)

```{r}
# Predecir las probabilidades (las necesitamos para la ROC)
predict(iris_knn_fit, iris_test, type = "prob")
```


---

# Fase 5: .orange[PREDICCI√ìN/EVALUACI√ìN]

Con `augment()` podemos obtener **.bg-purple_light[predicciones y datos en una sola tabla]**

```{r}
# Incluir predicciones en tabla
prob_test <- augment(iris_knn_fit, iris_test)
prob_test
```


---

# Fase 5: .orange[PREDICCI√ìN/EVALUACI√ìN]

* **.bg-purple_light[Matriz de confusi√≥n]**: matriz con los valores enfrentando **.bg-orange[etiqueta real vs predicha]** (hay que pasarle la salida del `augment` e indicarle como `truth = ...` la clase real y como `estimate = ...` la clase predicha, que por defecto sale como `.pred_class`

```{r}
# Matriz de confusi√≥n: etiqueta real vs etiqueta predicha
conf_mat_test <-
  prob_test %>%
  conf_mat(truth = Species, estimate = .pred_class)
conf_mat_test 
```

---

# Fase 5: .orange[PREDICCI√ìN/EVALUACI√ìN]

* **.bg-purple_light[M√©tricas]**: las obtenemos haciendo un `summary()` a la matriz de confusi√≥n

```{r}
# M√©tricas en test
metricas <- conf_mat_test %>% summary()
metricas
```

---

# ¬øY AHORA?

¬øBasta con esto?

--

En realidad no: recuerda que nuestro objetivo es minimizar el error, y para saber si estamos en un modelo √≥ptimo, sobreajustado o bajoajustado, necesitamos **.bg-purple_light[ejecutar el paradigma de aprendizaje con diferentes par√°metros]**.

* Diferentes k (`neighbors = ...`),
                
* Diferentes m√©tricas (`dist_power = ...`) 

* Diferentes ponderaciones (`weight_func = ...`)

&nbsp;

Dicha evaluaci√≥n la deber√≠amos hacer en **.bg-purple_light[validaci√≥n]** pero vamos a pasar a un ejemplo m√°s complicado con m√°s filas para ello.

---

name: knn-hoteles


# Ejemplo real: .orange[HOTELES]

Vamos ir a **ejemplo real**, haciendo uso de un **.bg-purple_light[dataset de reservas de hotel]**

```{r}
hoteles_bruto <- read_csv(file = "./datos/hoteles.csv")
```

Los datos forman parte de un **.bg-purple_light[conjunto de reservas de hotel]** elaborado por Antonio et al., 2019 con 50 000 registros de reservas

üìö **Detalle de variables**: <https://linkinghub.elsevier.com/retrieve/pii/S2352340918315191>

---

# Ejemplo real: .orange[HOTELES]

Lo primero es conocer las variables.

```{r eval = FALSE}
glimpse(hoteles_bruto)
```
--

* `hotel`: tipo de hotel (urbano o resort)
* `lead_time`: n√∫mero de d√≠as entre la reserva y la estancia.
* `stays_in_weekend_nights, stays_in_week_nights`: noches en fin de semana y entre semana
* `adults`: n√∫mero de adultos
* `children`: ¬øla reserva tiene ni√±os?
* `meal`: r√©gimen de comidas
* `country`: pa√≠s de origen
* `market_segment`: segmento de mercado de la reserva
* `distribution_channel`: canal de distribuci√≥n de la oferta
* `is_repeated_guest`: ¬ørepite como hu√©sped?

---

# Ejemplo real: .orange[HOTELES]


Lo primero es conocer las variables.

```{r eval = FALSE}
glimpse(hoteles_bruto)
```


* `previous_cancellations`: cancelaciones previas
* `previous_bookings_not_canceled`: reservas previas (no canceladas)
* `reserved_room_type, assigned_room_type`: tipo de habitaci√≥n reservada/asignada
* `booking_changes`: cambios en la reserva
* `deposit_type`: tipo de dep√≥sito
* `days_in_waiting_list`: d√≠as en lista de espera
* `customer_type`: tipo de cliente
* `average_daily_rate`: tarifa media diaria
* `required_car_parking_spaces`: ¬øparking?
* `total_of_special_requests`: n√∫mero de requisitos especiales demandados
* `arrival_date`: fecha de llegada 


---

# Ejemplo real: .orange[HOTELES]


```{r eval = FALSE}
glimpse(hoteles_bruto)
```

El objetivo ser√° **.bg-purple_light[predecir si una reserva incluye ni√±os/as o no]**, por lo que `children` ser√° nuestra variable objetivo. Primer paso: conocer c√≥mo se **.bg-purple_light[distribuyen los niveles de la objetivo]** (es binaria)

```{r}
hoteles_bruto %>% 
  count(children) %>%
  mutate(porc = 100*n/sum(n))
```

---

name: fase2-hoteles

# Fases 1-2-3: .orange[HOTELES]

Examina los datos y apunta las **.bg-purple_light[decisiones que deber√≠amos adoptar]**:

&nbsp;

* ¬øNecesitamos **.bg-orange[muestreo]**? ¬øDe qu√© forma? ¬øPodremos permitirnos crear esta vez un dataset de **.bg-orange[validaci√≥n]**?

* ¬øDe qu√© **.bg-orange[tipo]** es cada variable? ¬øTenemos **.bg-orange[problemas de codificaci√≥n o rango]**?

* ¬øC√≥mo **.bg-orange[afectan las predictoras]** a los niveles de la variable objetivo?

* ¬øHay problemas de **.bg-orange[dependencia]** entre las variables?

* ¬øNecesitamos **.bg-orange[recategorizar]** las variables? ¬øTenemos variables de **.bg-orange[fecha]**?

* ¬øTenemos **.bg-orange[datos at√≠picos]**?  ¬øTenemos **.bg-orange[datos ausentes]**? ¬øC√≥mo imputarlos?

* ¬øTodas las variables son **.bg-orange[num√©ricas]** para poder aplicar la m√©trica?

&nbsp;

**.bg-purple_light[Filosof√≠a]**: las modificaciones ¬´estructurales¬ª las hacemos fuera de la receta (modificando la base de datos), las modificaciones m√°s concretas para un algoritmo dentro de la receta (sin modificar la base de datos).


---

# Factores

* **.bg-purple_light[Factores]**: lo primero que debemos decidir es si las variables de tipo texto son **.bg-purple_light[variables cualitativas]** (factores) o meros id's.

```{r}
hoteles_bruto %>% select(where(is.character)) %>% glimpse()
```

---

# Factores

Todas las variables de tipo texto representan **.bg-purple_light[categor√≠as de una cualitativa]** as√≠ que las convertimos todas ellas a factor.

--

```{r}
hoteles <- 
  hoteles_bruto %>%
  mutate(across(where(is.character), as_factor))
hoteles
```

---

# Factores

* **.bg-purple_light[Ordinales]**: ¬øexiste alguna variable que pueda ser ordinal?

--

La variable `meal` si sigue una jerarqu√≠a: `SC` (sin nada) < `BB` (Bed & Breakfast) < `HB` (Half board, media pensi√≥n) < `FB` (Full board, pensi√≥n completa). Adem√°s tenemos un nivel para los desconocidos llamado `Undefined`

```{r}
hoteles %>%
  count(meal) %>% 
  mutate(porc = 100*n/sum(n))
```

---

# Factores

* **.bg-purple_light[Ordinales]**: convertimos `meal` a cualitativa pero ordinal.

```{r}
hoteles <-
  hoteles %>%
  mutate(meal = factor(meal, levels = c("Undefined", "SC", "BB", "HB", "FB"),
                       ordered = TRUE))
```

--

Ahora podremos hacer **.bg-purple_light[operaciones asociadas a una jerarqu√≠a]** como comparar registros

```{r}
hoteles %>%
  group_by(meal < "HB") %>% #<<
  count() %>% 
  ungroup()
```



---

# Variable hotel

Una vez convertidas en cualitativas analicemos cada una de ellas. La variable `hotel` es **.bg-purple_light[binaria]**: urbanos vs resort (60% vs 40% aprox)

```{r}
hoteles %>%
  count(hotel, sort = TRUE) %>%
  mutate(porc = 100*n/sum(n))
```

---

# Variable hotel

Parece que cuando hay **.bg-purple_light[ni√±os en la reserva]** se opta ligeramente **.bg-purple_light[m√°s por los resort]**

```{r}
hoteles %>%
  group_by(hotel) %>% 
  count(children) %>%
  mutate(porc = 100*n/sum(n)) %>% 
  ungroup()
```

---


# Variable meal

La variable `meal` toma **.bg-purple_light[5 modalidades]**: quiz√°s para algunos algoritmos haga falta reagrupar niveles (por ejemplo `Undefined` con `SC`)

```{r}
hoteles %>%
  count(meal, sort = TRUE) %>%
  mutate(porc = 100*n/sum(n))
```




---

# Variable meal

Parece que **.bg-purple_light[cuando hay ni√±os]** en la reserva hay el **.bg-purple_light[doble de reservas con pensi√≥n completa]**: aunque haya pocos registros de `meal = "FB"` pueden ser determinantes. El 11% de la reservas sin ni√±os van sin nada, mientras que solo el 3% de las reservas con ni√±os.

.pull-left[

```{r}
hoteles %>%
  group_by(meal) %>% 
  count(children) %>% 
  mutate(porc = 100*n/sum(n)) %>% 
  ungroup()
```

]

.pull-right[

```{r}
hoteles %>%
  group_by(children) %>% 
  count(meal) %>% 
  mutate(porc = 100*n/sum(n)) %>% 
  ungroup()
```

]

---

# Variable country

La variable `country` toma **.bg-purple_light[155 modalidades]** pero tan solo **.bg-purple_light[21 modalidades aparecen en m√°s del 0.5% de registros]** (una de ellas es NULL): quiz√°s sea m√°s pr√°ctico reagrupar niveles de esos pa√≠ses (representan juntos aprox el 10% del total).

```{r}
hoteles %>%
  count(country, sort = TRUE) %>%
  mutate(porc = 100*n/sum(n), cumul = cumsum(porc))
```


---


# Variable country

Aunque hay pa√≠ses que representa muy poco de los datos, parece que **.bg-purple_light[algunos son m√°s propensos a reservas con ni√±os]**.

```{r}
hoteles %>%
  group_by(country) %>% count(children) %>% 
  mutate(porc_children = 100*n/sum(n)) %>% 
  ungroup()
```


---

# Variable market_segment

La variable `market_segment` toma **.bg-purple_light[7 modalidades]** aunque algunas representan menos del 1% del total.

```{r}
hoteles %>%
  count(market_segment, sort = TRUE) %>%
  mutate(porc = 100*n/sum(n), cumul = cumsum(porc))
```

---

# Variable market_segment

F√≠jate que aunque `market_segment = "Aviation"` representa muy pocos registros, el 100% son sin ni√±os (casi similar con `market_segment = "Corporate"` y `market_segment = "Groups"`)

```{r}
hoteles %>%
  group_by(market_segment) %>% 
  count(children) %>% 
  mutate(porc = 100*n/sum(n)) %>% 
  ungroup()
```


---

# Variable distribution_channel

La variable `distribution_channel` toma **.bg-purple_light[5 modalidades]**  pero solo **.bg-purple_light[3 de ellas agrupan ya m√°s del 99%]** de los registros.

```{r}
hoteles %>%
  count(distribution_channel, sort = TRUE) %>%
  mutate(porc = 100*n/sum(n),
         cumul = cumsum(porc))
```

---

# Variable distribution_channel

F√≠jate que de `distribution_channel = "Undefined"` y `distribution_channel = "GDS"` representan **.bg-purple_light[muy pocos registros]**, y todos con una sola modalidad en la objetivo (pero solo pesan el 0.2% de los datos)

```{r}
hoteles %>%
  group_by(distribution_channel) %>% 
  count(children) %>% 
  mutate(porc = 100*n/sum(n)) %>% 
  ungroup()
```


---

# Variable reserved_room_type

La variable `reserved_room_type` toma **.bg-purple_light[9 modalidades]** (no nos especifican si hay jerarqu√≠a) pero **.bg-purple_light[solo 5 de ellas tienen un peso superior al 1%]** de los registros.

```{r}
hoteles %>%
  count(reserved_room_type, sort = TRUE) %>%
  mutate(porc = 100*n/sum(n),
         cumul = cumsum(porc))
```

---

# Variable reserved_room_type

F√≠jate que `reserved_room_type` ser√° **.bg-purple_light[tremendamente importante]**: si la habitaci√≥n es de tipo F, el 47% viene con ni√±os (frente al 8% global), del 70% incluso si es de tipo C

```{r}
hoteles %>%
  group_by(reserved_room_type) %>% 
  count(children) %>% 
  mutate(porc = 100*n/sum(n)) %>% 
  ungroup()
```

---

# Variable assigned_room_type

La variable `assigned_room_type` toma **.bg-purple_light[10 modalidades]** (no nos especifican si hay jerarqu√≠a) pero solo 7 de ellas tienen un peso superior al 1% de los registros.

```{r}
hoteles %>%
  count(assigned_room_type, sort = TRUE) %>%
  mutate(porc = 100*n/sum(n),
         cumul = cumsum(porc))
```

Como suced√≠a antes `assigned_room_type` ser√° tremendamente importante

---

# Variable reserved_room_type vs assigned_room_type

Quiz√°s sea interesante, al margen del tipo de habitaci√≥n, ver que sucede cuando la **.bg-purple_light[asignada es distinta de la reservada]**. 

```{r}
hoteles %>%
  mutate(same_room = as.character(reserved_room_type) == as.character(assigned_room_type)) %>%
  group_by(same_room) %>% 
  count(children) %>% 
  mutate(porc = 100*n/sum(n)) %>% 
  ungroup()
```

No parece que influya significativamente

---

# Variable deposit_type

La variable `deposit_type` toma **.bg-purple_light[3 modalidades]** pero el 99.6% de los registros es la misma.

```{r}
hoteles %>%
  count(deposit_type, sort = TRUE) %>%
  mutate(porc = 100*n/sum(n), cumul = cumsum(porc))
```

---

# Variable deposit_type

Adem√°s de ser **.bg-purple_light[muy pocos]** los registros que no sean `No_Deposit`, pr√°cticamente su totalidad son **.bg-purple_light[sin ni√±os]** (clase ya mayoritaria en los datos).

```{r}
hoteles %>%
  group_by(deposit_type) %>% 
  count(children) %>% 
  mutate(porc = 100*n/sum(n)) %>% 
  ungroup()
```

---

# Variable deposit_type

La variable `customer_type` toma **.bg-purple_light[4 modalidades]** pero **.bg-purple_light[dos de ellas representan m√°s del 95%]** de los registros.

```{r}
hoteles %>%
  count(customer_type, sort = TRUE) %>%
  mutate(porc = 100*n/sum(n),
         cumul = cumsum(porc))
```

---

# Variable deposit_type

El 88% de las reservas con ni√±os son de tipo `"Transient"`

```{r}
hoteles %>%
  group_by(children) %>% 
  count(customer_type) %>% 
  mutate(porc = 100*n/sum(n)) %>% 
  ungroup()
```


---


# Variable required_car_parking_spaces

La variable `required_car_parking_spaces` es binaria (muy desbalanceada).

```{r}
hoteles %>%
  count(required_car_parking_spaces, sort = TRUE) %>%
  mutate(porc = 100*n/sum(n),
         cumul = cumsum(porc))
```

---

# Variable required_car_parking_spaces

El % de las reservas con ni√±os es el doble cuando hay parking solicitado.

```{r}
hoteles %>%
  group_by(children) %>% 
  count(required_car_parking_spaces) %>% 
  mutate(porc = 100*n/sum(n)) %>% 
  ungroup()
```

---

# Dependencia entre variables cualitativas

M√°s all√° del an√°lisis exploratorio num√©rico, podemos ejecutar un **.bg-purple_light[contraste de independencia]** (prueba $\chi^2$ de independencia) para tener mayor certeza de si la predictora es dependiente o no de la variable objetivo (si fuera independiente, no tendr√≠a sentido mantenerla)

```{r warning = FALSE}
chisq.test(hoteles$children, hoteles$hotel)
```

Si fijamos $\alpha = 0.05$ (nivel de significaci√≥n), si p-valor < 0.05 deber√≠amos rechazar la **.bg-purple_light[hip√≥tesis nula de independencia]** (bajo dicho nivel).

---

# Dependencia entre variables cualitativas


Podemos hacerlo con **.bg-purple_light[todas las variables a la vez]** enfrent√°ndola a la objetivo

```{r warning = FALSE}
chisq <-
  tibble("variable" = hoteles %>% select(where(is.factor)) %>% names(),
         "p_value" = hoteles %>% select(where(is.factor)) %>%
           map_dbl(.f = function(x) { chisq.test(hoteles$children, x)$p.value}))
chisq %>% arrange(desc(p_value))
```

---

# Dependencia entre variables cualitativas



```{r warning = FALSE}
chisq %>% filter(p_value > 0.05)
```

**.bg-purple_light[No hay evidencia suficiente para decir que existe predictora independiente de la objetivo]** (al 95% de confianza) seg√∫n la prueba de independencia realizada

---

# Resumen de las variables cuali

* `hotel` --> **.bg-purple_light[no hacer nada]**.

* `meal`: aunque haya pocos registros de `meal = "FB"`, parece que pueden ser determinantes --> **.bg-purple_light[reagrupar "Undefined" con "SC" y dejar "FB"]**.

* `country`: tan solo 21 de ellas aparecen en m√°s del 0.5% de registros (una de ellas es NULL) --> **.bg-purple_light[reagrupar niveles de pa√≠ses minoritarios]** (representan juntos aprox el 10% del total) qued√°ndonos con aquellos que superen en un m√≠nimo de representatividad (m√°s fino: incluir tambi√©n los que sean m√°s propensos que otros a reservas con ni√±os).

* `market_segment`:  algunas representan menos del 1% del total, aunque para `market_segment = "Aviation"` el 100% son sin ni√±os (casi similar con `market_segment = "Corporate"` y `market_segment = "Groups"`) --> **.bg-purple_light[agrupar los 3 junto con "complementary"]** (pesan muy poco estos √∫ltimos) en un `"others"`.

* `distribution_channel`: solo 3 de ellas agrupan ya m√°s del 99% de los registros --> **.bg-purple_light[reagrupar "Corporate" (98.9% no children), "GDS" (100%  no children) y "Undefined" (solo 1 dato)]** en `"others"` (aprox. el 7% de los datos).

---

# Resumen de las variables cuali


* `reserved_room_type`: solo 5 de ellas tienen un peso superior al 1% de los registros, si es de tipo **.bg-purple_light[C, H o L]** (juntas suman el 1.3% de los datos aprox.), con ni√±os superan el 70% --> **.bg-purple_light[reagrupamos las 3]** en un `"others"`

* `assigned_room_type`: con el mismo razonamiento que antes podemos **.bg-purple_light[reaagupar las categor√≠as H-I-K]** en `"others"` 

* `deposit_type`: el 99.6% de registros es la misma -->  muy poca varianza y adem√°s casi todos de esas clases minoritarias son de la clase mayoritaria de la  objetivo  --> **.bg-purple_light[eliminar]**

* `customer_type` --> **.bg-purple_light[reagrupar "Transient" y "others"]**

* `required_car_parking_spaces` --> **.bg-purple_light[no hacer nada]**


---

# Variables de tipo de fecha

Solo tenemos una `arrival_date`: ¬øqu√© parte de la fecha exactamente influye m√°s? ¬øEl a√±o? ¬øEl mes? ¬øEl d√≠a como n√∫mero en s√≠ o el d√≠a de la semana? Tras extraer info la eliminaremos.

```{r}
hoteles <- 
  hoteles %>% 
  mutate(m_arr = month(arrival_date), y_arr = year(arrival_date),
         wday_arr = wday(arrival_date))

hoteles %>% group_by(y_arr) %>% count(children) %>% 
  mutate(porc = 100*n/sum(n))
```

No parece que el a√±o influya mucho (veremos si influyen los d√≠as festivos en s√≠)

---

# Variables de tipo de fecha

Parece que los meses de julio, agosto y diciembre influye mucho al tener m√°s ni√±os --> podemos agrupar los meses en `"month_holy"` y `"month_no_holy"`

```{r}
hoteles %>%  group_by(m_arr) %>% count(children) %>% 
  mutate(porc = 100*n/sum(n))
```


---

# Variables de tipo de fecha

Parece que los viernes, s√°bados y domingos hay m√°s reservas con ni√±os --> podemos agrupar los meses en `"weekend"` y `"workday"`

```{r}
hoteles %>%  group_by(wday_arr) %>%  count(children) %>% 
  mutate(porc = 100*n/sum(n))
```

---

# Variables num√©ricas

* `lead_time`: variable con una alta concentraci√≥n a la izquierda (cola pesada a la derecha), con un m√°ximo de d√≠as muy elevado.

```{r}
hoteles %>% summarise(min_lead = min(lead_time), max_lead = max(lead_time))
```

--

Quizas no tenga sentido tanto n√∫mero de d√≠as entre la reserva y la estancia --> todo lo que **.bg-purple_light[supere 365, imputarle 366]** (representan adem√°s el 1.35% solo)

```{r}
hoteles %>% group_by(lead_time > 365) %>% count()
```

---

# Variables num√©ricas

* `stays_in_weekend_nights`: en realidad es una variable cualitativa m√°s que cuantitativa, y a partir de 2 noches en festivo representa menos de 1% --> podr√≠amos probar a **.bg-purple_light[dejarla tal cual o recategorizarla en 4 categor√≠as]** (ninguna - 1 - 2 - m√°s de 2)

```{r}
hoteles %>%
  count(stays_in_weekend_nights, sort = TRUE) %>% 
  mutate(porc = 100*n/sum(n), cumul = cumsum(porc))
```

---

# Variables num√©ricas

* `stays_in_week_nights`: en realidad es una variable cualitativa m√°s que cuantitativa, y a partir de 5 noches representa menos del 5% --> podr√≠amos probar a **.bg-purple_light[dejarla tal cual o recategorizarla en 7 categor√≠as]** (ninguna - 1 - 2 - 3 - 4 - 5 - m√°s de 5)

```{r}
hoteles %>%
  count(stays_in_week_nights, sort = TRUE) %>% 
  mutate(porc = 100*n/sum(n), cumul = cumsum(porc))
```

---

# Variables num√©ricas

* `adults`: en realidad es una variable cualitativa m√°s que cuantitativa --> podr√≠amos probar a **.bg-purple_light[dejarla tal cual o recategorizarla en 4 categor√≠as]** (ninguno - 1 - 2 - m√°s de 2)

```{r}
hoteles %>% count(adults, sort = TRUE) %>% 
  mutate(porc = 100*n/sum(n), cumul = cumsum(porc))
```

---

# Variables num√©ricas

* `is_repeated_guest`: en realidad es **.bg-purple_light[binaria]** --> hay que convertirla a cualitativa (factor)

```{r}
hoteles %>% count(is_repeated_guest, sort = TRUE) %>% mutate(porc = 100*n/sum(n))

hoteles %>% group_by(is_repeated_guest) %>% count(children) %>% 
  mutate(porc = 100*n/sum(n)) %>% ungroup()
```

---

# Variables num√©ricas

* `previous_cancellations`: el 99.238% son 0 (y la mayor√≠a de 1, sin ni√±os) --> **.bg-purple_light[eliminar]**

* `previous_bookings_not_canceled`: el 95.47% son 0, el 1.9% son 1 --> se podr√≠a probar a **.bg-purple_light[dejarla tal cual o recategorizar en 3 categor√≠as]**

```{r}
hoteles %>% count(previous_cancellations == 0, sort = TRUE)

hoteles %>% count(previous_bookings_not_canceled, sort = TRUE) %>%
  mutate(porc = 100*n/sum(n), cumul = cumsum(porc))
```


---

# Variables num√©ricas

* `booking_changes`: el 94.194% son 0 o 1 --> se podr√≠a probar a **.bg-purple_light[dejarla num√©rica o recategorizar en 3 categor√≠as]**

```{r}
hoteles %>% count(booking_changes, sort = TRUE) %>% 
  mutate(porc = 100*n/sum(n), cumul = cumsum(porc))
```

---

# Variables num√©ricas

* `days_in_waiting_list`: el 98% de los registros son 0 (y de los que no son casi todos no tienen ni√±os) --> **.bg-purple_light[eliminar variable]**

```{r}
hoteles %>% count(days_in_waiting_list, sort = TRUE) %>% 
  mutate(porc = 100*n/sum(n), cumul = cumsum(porc))
```

---

# Variables num√©ricas

* `average_daily_rate`: es la √∫nica num√©rica continua pero tiene **.bg-purple_light[valores negativos o cero]** (deber√≠an ser estrictamente positivo) --> el 2.33% tiene **.bg-purple_light[problemas de codificaci√≥n o rango]** que deberemos pasar a ausentes e imputarles un valores luego.

```{r}
hoteles %>% count(average_daily_rate <= 0) %>% mutate(porc = 100*n/sum(n))
```

---

# Variables num√©ricas

* `total_of_special_requests`: m√°s del 96% son 0-1-2 --> se podr√≠a **.bg-purple_light[dejar num√©rica o recategorizarla en 4 categor√≠as]**.

```{r}
hoteles %>% count(total_of_special_requests, sort = TRUE) %>% 
  mutate(porc = 100*n/sum(n), cumul = cumsum(porc))
```

---

# .orange[COLINEALIDAD]

Por √∫ltimo, nos falta comprobar los **.bg-purple_light[problemas de  colinealidad]** entre las predictoras num√©ricas. 

Podemos tratar las **.bg-orange[num√©ricas por separado]** (aunque tengamos muchas que en realidad hacen m√°s de cuali que de cuanti)

```{r}
library(corrr)
cor_matrix <- hoteles %>% select(where(is.numeric)) %>% cor() %>% round(2)
cor_matrix
```

---

# .orange[COLINEALIDAD]

```{r eval = FALSE}
cor_matrix %>%
  corrplot(method = "number", tl.cex = 0.55, number.cex = 0.7, type = "lower")
```

```{r echo = FALSE, out.width = "40%", fig.align = "center"}
knitr::include_graphics("./img/cor_hoteles.jpg")
``` 

No parece existir una correlaci√≥n elevada entre ninguna.

---

name: fase3-hoteles

# Fase 3: .orange[MODIFICACI√ìN]

Con lo observado en la fase de exploraci√≥n deberemos tomar **.bg-purple_light[dos tipos decisiones]**:

* las que afectan a la **.bg-orange[base de datos en general]**: pasar a factores, problemas de codificaci√≥n o rango, variables que no aportan, creaci√≥n de variables en general, etc

* las que afectan a un **.bg-orange[algoritmo en concreto]**: normalizaci√≥n para la m√©trica, recategorizaci√≥n, tratamiento de outliers/ausentes, dummyficaci√≥n, etc.

---

# Fase 1: .orange[MUESTREO]

Pero antes...¬øhace falta **.bg-purple_light[muestreo]**? Parece que s√≠ dado que tenemos muchas filas (al menos para hacer pruebas) --> muestreo **.bg-purple_light[estratificado]** (por ej., del 10%)

```{r}
hoteles_sample <-
  hoteles %>%
  group_by(children) %>% 
  slice_sample(prop = 0.10) %>%
  ungroup()

hoteles_sample %>%
  count(children) %>% 
  mutate(porc = 100*n/sum(n))
```

¬øHace falta algo m√°s?


---

# Fase 3: .orange[MODIFICACI√ìN] (fuera receta)

```{r}
# Muestreo del 10
hoteles_sample <-
  hoteles_bruto %>%
  group_by(children) %>% 
  slice_sample(prop = 0.10) %>%
  ungroup()

# Eli%minar variables
hoteles_sample <-
  hoteles_sample %>%
  select(-c(deposit_type, days_in_waiting_list, previous_cancellations))
```

---

# Fase 3: .orange[MODIFICACI√ìN] (fuera receta)

```{r}
# Convertir a cuali
hoteles_sample <-
  hoteles_sample %>% 
  mutate(across(where(is.character), as_factor)) %>%
  mutate(meal = factor(meal, levels = c("Undefined", "SC", "BB", "HB", "FB"),
                       ordered = TRUE))

# Modificaciones de variables existentes
hoteles_sample <-
  hoteles_sample %>% 
  mutate(lead_time = ifelse(lead_time > 365, 366, lead_time),
         average_daily_rate = ifelse(average_daily_rate <= 0, NA, average_daily_rate),
         is_repeated_guest = as_factor(is_repeated_guest))
```

---

# .orange[RECETA]: .green[PARTICI√ìN]

Primero dividimos en **.bg-purple_light[test y lo dem√°s]**, con `initial_split()`

```{r}
# Partici√≥n 10% de test
hoteles_split <- initial_split(hoteles_sample, strata = children, prop = 0.9)
hoteles_split

# Aplicamos partici√≥n
hoteles_train <- training(hoteles_split)
hoteles_test <- testing(hoteles_split)

# Comprobamos estratos
hoteles_train %>% count(children) %>% mutate(porc = 100 * n / sum(n))
hoteles_test %>% count(children) %>% mutate(porc = 100 * n / sum(n))
```

---

# .orange[RECETA]: .green[PARTICI√ìN]

Tras ello usamos `validation_split()` para **.bg-purple_light[dividir en train-validaci√≥n]** lo que ten√≠amos en `hoteles_train` (75% del 90% = 67.5% vs 22.5%)

```{r}
# Validaci√≥n
hoteles_val <- validation_split(hoteles_train, strata = children,
                                prop = 0.75)
hoteles_val
```

---

# .orange[RECETA]: .green[ROLES]


```{r}
# Receta
hoteles_rec <-
  # F√≥rmula y datos
  recipe(data = hoteles_train, children ~ .)%>%
  # Roles
  add_role(contains("date"), new_role = "date") %>% 
  add_role(where(is.factor), new_role = "cuali") %>% 
  add_role(where(is.numeric), new_role = "cuanti") %>% 
  add_role(c(hotel, required_car_parking_spaces, is_repeated_guest), new_role = "binary") %>% 
  add_role(where(is.numeric) & !average_daily_rate, new_role = "maybe_cuali")
```


---

# .orange[RECETA]: .green[FECHAS]

* Con `step_date()` podemos indicarle directamente que extraiga de la fecha los elementos que le pidamos (en nuestro caso mes, d√≠a de la semana y a√±o).

* Con `listHolidays()` del paquete `{timeDate}` seleccionaremos festivos relevantes internacionalmente, y con `step_holiday()` marcaremos las fechas que lo sean. Tras ello eliminaremos la fecha original con `step_rm()`.

```{r}
library(timeDate)
# Receta
hoteles_rec <-
  hoteles_rec %>% 
  step_date(arrival_date, features = c("month", "dow", "year")) %>% 
  step_holiday(arrival_date,
               holidays = c(listHolidays("\\Mary"), listHolidays("\\Easter"),
                            listHolidays("\\Christ"), "NewYearsDay")) %>%
  # Eliminamos la variable
  step_rm(arrival_date)
```

---


# .orange[RECETA]: .green[OUTLIERS/AUSENTE]

Tras ello de momento vamos a **.bg-purple_light[detectar outliers a lo bruto]**: detectando por la media e imputando por la media, pero solo de `has_role("cuanti")`, para no incluir a las binarias. Las cuali por la moda en caso de haber ausentes.

```{r}
library(outliers)
# Receta
hoteles_rec <-
  hoteles_rec %>% 
  # Detectar outliers
  step_mutate(across(where(is.numeric), function(x) { ifelse(abs(scores(x, type = "z")) > 2.5 & !is.na(x), NA, x) })) %>% 
  # Imputar ausentes
  step_impute_mean(has_role("cuanti")) %>%
  step_impute_mode(has_role("cuali"))
```

---

# .orange[RECETA]: .green[TRANSFORMACIONES]

* Aplicamos un filtro de correlaci√≥n para **.bg-purple_light[prevenir problemas de colinealidad]**.

* **.bg-purple_light[Normalizamos por rango]** para la m√©trica.

* **.bg-purple_light[Dummyficamos]** las cualitativas: crea k-1 variables binarias por de cada cualitativa de k niveles.

* **.bg-purple_light[Filtro de cero varianza]**.

```{r}
# Receta
hoteles_rec <-
  hoteles_rec %>% 
  # Filtro de correlaci√≥n
  step_corr(has_role("cuanti"), threshold = 0.9) %>% 
  # Normalizar por rango
  step_range(all_numeric_predictors()) %>%
  # Dummyficamos
  step_dummy(all_nominal(), -all_outcomes()) %>% 
  # Filtro de cero varianza
  step_zv(all_predictors())
```


---

name: fase4-hoteles

# Fase 4: .orange[MODELO Y FLUJO]


Una vez definida la receta, definimos el **.bg-purple_light[modelo]** y unimos con la receta creando un **.bg-purple_light[flujo de clasificaci√≥n]**

```{r}
# Modelo
knn_model <-
  nearest_neighbor(mode = "classification", neighbors = 15,
                   weight_func = "inv", dist_power = 2) %>%
  set_engine("kknn")

# Flujo de trabajo
hoteles_wflow <-
  workflow() %>%
  add_recipe(hoteles_rec) %>%
  add_model(knn_model)
```

---

name: fase5-hoteles

# Fase 5: .orange[EVALUACI√ìN] en validaci√≥n

En este caso tenemos un conjunto de validaci√≥n guardado en `hoteles_val`. Para realizar el **.bg-purple_light[ajuste en train y despu√©s obtener las m√©tricas en validaci√≥n]** usaremos `fit_resamples()`, pas√°ndole como argumento los conjuntos de validaci√≥n que tengamos y las **.bg-purple_light[m√©tricas]** que queremos que evaluar (con `metric_set()` y el nombre de la m√©trica)

```{r}
# Solo contra un conjunto de validaci√≥n
hoteles_knn_fit_val <-
  hoteles_wflow %>%
  fit_resamples(hoteles_val,
                metrics = metric_set(accuracy, sensitivity,
                                     specificity, roc_auc))
```


---

# Fase 5: .orange[EVALUACI√ìN] en validaci√≥n


Con `collect_metrics()` obtenemos las m√©tricas pedidas (dado que solo tenemos un conjunto de validaci√≥n `n = 1` y `std_err = NA`, ya que no tiene con qu√© promediar al solor tener uno)

```{r}
collect_metrics(hoteles_knn_fit_val)
```

---

# Fase 5: .orange[EVALUACI√ìN] con .green[CURVA ROC]

Si te has fijado am√©n de la sensibilidad y la especificidad (y la tasa de bien de clasificados o accuracy), le hemos pedido una m√©trica llamada `roc_auc`: el **.bg-purple_light[√°rea bajo la curva ROC]**

```{r}
collect_metrics(hoteles_knn_fit_val)
```

--

¬øQu√© es la **.bg-purple_light[curva ROC]**? Si recuerdas, aunque la salida que usamos normalmente es la clase predicha directamente, nuestro objetivo subyacente es **.bg-purple_light[calcular la probabilidad estimada de pertenencia]**

---

# Fase 5: .orange[EVALUACI√ìN] con .green[CURVA ROC]

En clasificaci√≥n binaria, por defecto, estamos estableciendo que la **.bg-purple_light[predicci√≥n es 1]** si la probabilidad estimada de serlo es **.bg-purple_light[superior a 0.5]**. 

Imagina que el objetivo es clasificar si una vacuna puede salir al mercado. ¬øEs **.bg-purple_light[suficiente exigirle un umbral del 50%]** para asignar un 1?

--

La idea detr√°s de la curva ROC es **.bg-purple_light[mover dicho umbral de probabilidad]**, desde el 0 hasta el 1, para **.bg-purple_light[cada uno de esos umbrales]** calcular

* **sensibilidad** (% de 1's reales que han sido clasificados como tal)

* **especificidad** (% de 0's reales que han sido clasificados como tal)

Y pintarlos en un gr√°fico (eje x = 1 - especificidad, eje y = sensibilidad)

---

# Fase 5: .orange[EVALUACI√ìN] con .green[CURVA ROC]

.pull-left[

* Eje X: **.bg-purple_light[1 - especificidad]**, conocido como False Positive Rate (FPR), ya que es el % de 0's reales que han sido mal clasificados (como falsos positivos).

* Eje Y: **.bg-purple_light[sensibilidad]**, conocido como True Positive Rate (TPR), ya que es el % de 1's reales que han sido clasificados como tal (verdaders positivos).

* **.bg-purple_light[AUC ROC]**: √°rea bajo la curva ROC, medida que oscila entre 0 (no hay curva) y 1 (la curva es el cuadrado entero). Clasificador dummy aleatorio: 0.5.

]

.pull-right[


```{r echo = FALSE,  out.width = "110%", fig.align = "left"}
knitr::include_graphics("./img/roc_curve.jpg")
``` 

]

---

# Fase 5: .orange[EVALUACI√ìN] con .green[CURVA ROC]


```{r echo = FALSE,  out.width = "50%", fig.align = "center"}
knitr::include_graphics("./img/pcr_roc_curve.jpg")
``` 


---

# .orange[TUNE]

Hasta ahora solo hemos probado un modelo pero la idea es **.bg-purple_light[entrenar varios modelos]** y **.bg-purple_light[evaluar en validaci√≥n]** su calidad o conveniencia.

Para ello lo que vamos a hacer al definir el modelo es **.bg-purple_light[no asignar una constante a los par√°metros]** sino que los vamos a dejar sin fijar, asign√°ndoles `tune()` (entre par√©ntesis una **etiqueta** para luego ser usada), para luego indicarle los ¬´diales¬ª en los que queremos que ¬´sintonice¬ª

```{r}
# Modelo con tune
knn_model_tune <-
  nearest_neighbor(mode = "classification", neighbors = tune("k"),
                   weight_func = tune("weight"), dist_power = tune("dist")) %>%
  set_engine("kknn")
```

---

# .orange[TUNE]

```{r}
# Nuevo flujo (con tune)
hoteles_wflow <-
  workflow() %>%
  add_recipe(hoteles_rec) %>%
  add_model(knn_model_tune)
```

El anterior modelo **.bg-purple_light[no tiene par√°metros fijados]** a priori: vamos a definir un **.bg-purple_light[grid de par√°metros]**

Por ejemplo, podemos definir un grid de 7 valores de `k` (lo dem√°s fijo)

```{r}
grid_knn <- 
  tibble("k" = seq(20, 140, by = 20), "weight" = rep("inv", 7),
         "dist" = rep(2, 7))
grid_knn
```

---

# .orange[TUNE GRID]

Con `tune_grid()` le indicaremos que **.bg-purple_light[en lugar de entrenar un solo modelo]** entre uno por cada fila de par√°metros que tenemos en `grid_knn`, y con `control_grid(verbose = TRUE)` le indicamos que nos informe del proceso. Tras ello con `collect_metrics()` obtendremos de una tacada la m√©trica de todos.

```{r}
# Entrenamos y evaluamos los 7 modelos
hoteles_knn_fit_tune <-
 hoteles_wflow %>%
  tune_grid(resamples = hoteles_val, grid = grid_knn,
            control = control_grid(verbose = TRUE),
            metrics = metric_set(accuracy, sensitivity,
                                 specificity, roc_auc))
hoteles_knn_fit_tune %>% collect_metrics()
```

---


# .orange[TUNE GRID]

Ese grid tambi√©n podemos definirlo para el resto de par√°metros, definiendo los **.bg-purple_light[posibles valores para cada par√°metro]** y probar **.bg-purple_light[todas las combinaciones entre ellos]**. Para eso haremos uso de `expand_grid()`

```{r}
expand_grid("x" = 1:3, "y" = 8:9)
```

---

# .orange[TUNE GRID]

Con dicha herramienta vamos a **.bg-purple_light[crear 18 modelos]**: 3 valores diferentes de vecinos, 2 tipos de promedios y 3 m√©tricas.

```{r}
grid_knn <-
  expand_grid("k" = c(10, 50, 100),
              "weight" = c("inv", "gaussian"),
              "dist" = c(0.01, 2, 10))
grid_knn
```

---

# .orange[TUNE GRID]

```{r}
# Entrenamos y evaluamos los 18 modelos
hoteles_knn_fit_tune <-
 hoteles_wflow %>%
  tune_grid(resamples = hoteles_val, grid = grid_knn,
            control = control_grid(verbose = TRUE),
            metrics = metric_set(accuracy, sensitivity,
                                 specificity, roc_auc))
hoteles_knn_fit_tune %>% collect_metrics()
```

---

# .orange[TUNE GRID]


Incluso podemos generar ese grid de una manera m√°s  **.bg-purple_light[autom√°tica]** haciendo uso de `update()` y `grid_regular()`, para el mismo n√∫mero de valores en cada par√°metro (por ejemplo 3 en cada uno, siempre que haya tres opciones dadas)

```{r}
grid_knn <-
  extract_parameter_set_dials(hoteles_wflow) %>%
  # Actualizamos
  update(k = neighbors(range = c(10, 100)),
         weight = weight_func(values = c("inv", "gaussian")),
         dist = dist_power(range = c(0.1, 10))) %>%
  grid_regular(levels = 3) 
grid_knn # 18 modelos (3 x 2 x 3)
```

---

# .orange[TUNE GRID]

```{r}
# Entrenamos y evaluamos los 18 modelos
hoteles_knn_fit_tune <-
 hoteles_wflow %>%
  tune_grid(resamples = hoteles_val, grid = grid_knn,
            control = control_grid(verbose = TRUE),
            metrics = metric_set(accuracy, sensitivity,
                                 specificity, roc_auc))
hoteles_knn_fit_tune %>% collect_metrics()
```

---


class: inverse center middle
name: clase-9


# CLASE 9: otras validaciones y ggplot

&nbsp;

### [Mejor modelo en validaci√≥n](#show-best)

### [Modelizaci√≥n paralelizada](#parallel)

### [Sobremuestreo](#oversampling)

### [Validaci√≥n cruzada y bootstrap](#cv-hoteles)

### [Visualizaci√≥n de datos](#dataviz)

---

name: show-best

# Fase 5: .orange[evaluaci√≥n]

No solo vamos a poder trastear con tidyverse en esos resultados en validaci√≥n sino que tenemos **.bg-purple_light[dos funciones especialmente pensadas]** para ello: `show_best()` nos devuelve los mejores modelos seg√∫n la m√©trica pedida, `select_best()` nos selecciona el mejor

```{r}
# Los mejores seg√∫n accuraccy
hoteles_knn_fit_tune %>% show_best("accuracy")

# Elegir el mejor seg√∫n ROC
hoteles_knn_fit_tune %>% select_best("roc_auc")
```

---

# .orange[SELECCI√ìN DEL MEJOR]

```{r}
# Finalizamos flujo con el mejor modelo (seg√∫n una m√©trica)
best_knn_model_acc <- hoteles_knn_fit_tune %>% select_best("accuracy")
final_wf <- 
  hoteles_wflow %>% 
  finalize_workflow(best_knn_model_acc)
final_wf
```

---

# Fase 5: .orange[EVALUACI√ìN EN TEST]

```{r}
# Ajustamos a test con ese modelo seleccionado en validaci√≥n
final_knn_fit <- 
  final_wf %>%
  last_fit(hoteles_split) 

# Calculamos m√©tricas en test (las indicadas)
final_knn_fit %>% collect_metrics()
```


---

# Fase 5: .orange[PREDICCI√ìN EN TEST]

Podemos volver a usar `predict()`, extrayendo el flujo de ese ajuste final con `extract_workflow(final_knn_fit)`

```{r}
# Predecir el conjunto test: devuelve la clase
predict(extract_workflow(final_knn_fit), hoteles_test)
```

---

# Fase 5: .orange[PREDICCI√ìN EN TEST]

```{r}
# Predecir las probabilidades (las necesitamos para la ROC)
predict(extract_workflow(final_knn_fit), hoteles_test, type = "prob")
```

---

# Fase 5: .orange[PREDICCI√ìN EN TEST]

```{r}
# Incluir predicciones en tabla
prob_test <- augment(extract_workflow(final_knn_fit), hoteles_test)

# Matriz de confusi√≥n: etiqueta real vs etiqueta predicha
conf_mat_test <-
  prob_test %>%
  conf_mat(truth = children, estimate = .pred_class)
conf_mat_test 
```

---

# Fase 5: .orange[PREDICCI√ìN EN TEST]

```{r}
# todas las m√©tricas en test
conf_mat_test %>% summary()
```

---

# Fase 5: .orange[PREDICCI√ìN EN TEST]

Podemos **.bg-purple_light[dibujar la curva ROC]** haciendo uso de `roc_curve()` pas√°ndole el archivo con las predicciones, y usando las probabilidades de ser 1 (guardadas en `.pred_children` en nuestro conjunto). Aprenderemos a dibujarla mejor pero podemos mientras hacerlo con `autoplot()`

```{r}
roc_data <- prob_test %>% roc_curve(truth = children, .pred_children)
roc_data %>% autoplot()
```


---

name: parallel

# Computaci√≥n .orange[EN PARALELO]

Si queremos probar muchos modelos y/o nuestro volumen de datos es elevado, quiz√°s nos lleve demasiado tiempo: vamos a hacer una incursi√≥n a la **.bg-purple_light[programaci√≥n paralelizada]**. 

```{r}
library(parallel)
library(doParallel)
```

--

Ambos paquetes ser√°n los que nos permitan paralelizar de forma sencilla. La idea es **.bg-purple_light[mandar tareas independientes a procesadores distintos]**, de forma que si una tarea tarda 6 minutos en un pc, al mandarlo a otros dos procesadores, el tiempo pueda bajar hasta los 2 minutos (no es del todo lineal ya que hay un tiempo m√≠nimo necesario en cada paso).

---

# Computaci√≥n .orange[EN PARALELO]

En muchas empresas u organismos de investigaci√≥n se suele tener a disposici√≥n de los usuarios un conjunto de ordenadores (un cl√∫ster) com√∫n a todos de forma que cada persona pueda mandar sus hilos en paralelo. Pero‚Ä¶no tenemos de eso. ¬øEntonces?

&nbsp;

Vamos a **.bg-purple_light[paralelizar en NUESTRO PROPIO ORDENADOR]**: un ordenador suele tener **.bg-purple_light[varios procesadores o cores]** que pueden funcionar de manera ¬´independiente¬ª uno de otro. Vamos a detectar la cantidad de n√∫cleos de los que podemos disponer con `detectCores()`.

```{r}
# Detectamos los cores que tenemos
detectCores()
```

---

# Computaci√≥n .orange[EN PARALELO]

A la hora de paralelizar es importante que lo hagamos con cuidado ya que puede que nuestro ordenador se quede colgado: mi consejo es que definas el n√∫mero de cores a usar como los que tienes menos uno.

Con `makeCluster()` montamos los **.bg-purple_light[cl√∫ster en cada nodo]** y con `registerDoParallel()` registramos la paralelizaci√≥n (puedes ver los hilos abiertos con `showConnections()`).

```{r}
# Iniciamos la paralelizaci√≥n
clusters <- detectCores() - 1
make_cluster <- makeCluster(clusters)
registerDoParallel(make_cluster)
showConnections()
```


---

# Computaci√≥n .orange[EN PARALELO]
 
El √∫nico cambio respecto a antes es indicarle `tune_grid()`  que queremos la **.bg-purple_light[validaci√≥n paralelizada]**, con `control = control_grid(allow_par = TRUE)`. Para que no queden hilos sueltos es importante que al **.bg-purple_light[acabar la paralelizaci√≥n le indiquemos que cerramos los cl√∫ster]**.

```{r}
# Entrenamos y evaluamos los 18 modelos en paralelo
hoteles_knn_fit_tune <-
 hoteles_wflow %>%
  tune_grid(resamples = hoteles_val, grid = grid_knn,
            control = control_grid(verbose = TRUE, allow_par = TRUE,
                                   pkgs = c("outliers")),
            metrics = metric_set(accuracy, sensitivity,
                                 specificity, roc_auc))
# finalizamos clusters
stopCluster(make_cluster)
registerDoSEQ()

# M√©tricas
hoteles_knn_fit_tune %>% collect_metrics()
```


---

name: oversampling

# .orange[SOBREMUESTREO] .green[BAJOMUESTREO]

Un paso que hemos obviado: si tenemos la **.bg-purple_light[variable objetivo desbalanceada]** solo aprender√° de la clase mayoritaria. Este desbalanceamiento podemos mitigarlo realizando **.bg-purple_light[sobremuestro/bajomuestreo]**, a√±adiendo `step_upsample()` (del paquete `{themis}`) a la receta (el par√°metro `over_ratio` nos cuantifica el % de la clase minoritaria entre la mayoritaria).

```{r}
hoteles_rec_oversampling <-
  hoteles_rec %>% 
  themis::step_upsample(children, over_ratio = 0.5)

bake(hoteles_rec_oversampling %>% prep(), new_data = NULL) %>%
  count(children) %>% 
  mutate(porc = 100*n/sum(n))
```

---

# .orange[SOBREMUESTREO] .green[BAJOMUESTREO]

Basta con repetir el proceso con la **receta con sobremuestreo**

```{r eval = FALSE}
# Flujo de trabajo
hoteles_wflow_oversampling <-
  workflow() %>%
  add_recipe(hoteles_rec_oversampling) %>%
  add_model(knn_model_tune)

# Ajuste
hoteles_knn_fit_tune_oversampling <-
  hoteles_wflow_oversampling %>%
  tune_grid(resamples = hoteles_val, grid = grid_knn,
            control = control_grid(verbose = TRUE,
                                   allow_par = TRUE,
                                   pkgs = c("outliers")),
            metrics = metric_set(accuracy, sensitivity,
                                 specificity, roc_auc))
```
  
---

---

names: cv-hoteles

# Validaci√≥n .orange[CRUZADA v-folds]


* cv v-folds

---

names: bootstrap-val-hoteles

# Validaci√≥n .orange[BOOTSTRAP]

* Bootstrap Out-of-Bag

---

name: dataviz

# .orange[VISUALIZACI√ìN] de datos

---

# .orange[RECURSOS] y .green[BIBLIOGRAF√çA]

&nbsp;


#### üìö **.bg-purple_light[Art√≠culos o libros]** cient√≠ficos que han sido sometidos a revisi√≥n por pares.

&nbsp;

#### üîó **.bg-green_light[Recursos online]** recomendados

&nbsp;

#### üíª Recursos para la **.bg-orange[programaci√≥n en R]**

---

# Bibliograf√≠a general

üìö **¬´Statistical tests, P values, confidence intervals, and power: a guide to misinterpretations¬ª**. Greenland et al. (2016) <https://github.com/dadosdelaplace/teaching/blob/main/data_mining/biblio/p-value_Greenland_etal_2016.pdf>

üíª **Tidy Data Tutor**: para visualizar la mec√°nica interna de `{tidyverse}`. <https://tidydatatutor.com/>

üîó Web con recursos para la **introducci√≥n a la estad√≠stica y Machine Learning en R** <https://artofstat.com/>

üíª **Manual introductorio de R** (Javier √Ålvarez Li√©bana): <https://dadosdelaplace.github.io/courses-intro-R/>


---

# Bibliograf√≠a general

üìö **¬´The reproducibility of research and the misinterpretation of p-values¬ª**. Colquhoun (2017) <https://github.com/dadosdelaplace/teaching/blob/main/data_mining/biblio/p-values_Colquhoun_2017.pdf>


üìö **¬´An Introduction to Multivariate Statistical Analysis¬ª**. Anderson (1958) <https://github.com/dadosdelaplace/teaching/blob/main/data_mining/biblio/introduction_mva_anderson_2003.pdf>

üìö **¬´A New Measure of Rank Correlation¬ª**. Kendall (1938) <https://github.com/dadosdelaplace/teaching/blob/main/data_mining/biblio/correlation_kendall_1938.pdf>

üìö **¬´The generalised product moment distribution in samples from a normal multivariate population¬ª**. Wishart (1928) <https://github.com/dadosdelaplace/teaching/blob/main/data_mining/biblio/multivariate_normal_wishart_1928.pdf>

üìö **¬´On lines and planes of closest fit to systems of points in space¬ª**. Pearson (1901) <https://github.com/dadosdelaplace/teaching/blob/main/data_mining/biblio/fit_pearson_1901.pdf>


---

# Recursos dataviz

### Dataviz

üìö **¬´Gram√°tica de las gr√°ficas: pistas para mejorar las representaciones de datos¬ª**. Sevilla (2005) <http://academica-e.unavarra.es/bitstream/handle/2454/15785/Gram%C3%A1tica.pdf>

üìö **¬´Quantitative Graphics in Statistics: A Brief History¬ª**. Beniger and Robyn (1978) <https://github.com/dadosdelaplace/teaching/blob/main/bdba-pca-clustering-2022/biblio/graphics_beniger_robin_1978.pdf>
 
 
üíª **¬´Analizando datos, visualizando informaci√≥n, contando historias¬ª** (curso de dataviz en R). √Ålvarez-Li√©bana y Valverde-Castilla (2022) <https://dadosdelaplace.github.io/curso-dataviz-ECI-2022>

üìö **¬´40 years of boxplots¬ª**. Wickham and Stryjewski (2011) <https://github.com/dadosdelaplace/teaching/blob/main/bdba-pca-clustering-2022/biblio/boxplot_Wickham_Stryjewski_2011.pdf>
 
 


---

# Bibliograf√≠a componentes principales

üíª **Componentes principales** en `{tidymodels}`. <https://www.tmwr.org/dimensionality.html#beans>


üìö **¬´Principal Component Analysis¬ª**. Jolliffe (2002) <https://github.com/dadosdelaplace/teaching/blob/main/bdba-pca-clustering-2022/biblio/pca_jolliffe_2002.pdf>

üìö **¬´Principal Component Analysis¬ª**. Herv√© and Lynne (2010) <http://staff.ustc.edu.cn/~zwp/teach/MVA/abdi-awPCA2010.pdf>

üìö **¬´Principal Component Analysis: a review and recent developments¬ª**. Jolliffe and Cadima (2016) <https://royalsocietypublishing.org/doi/10.1098/rsta.2015.0202>

üîó **¬´The Mathematics Behind Principal Component Analysis¬ª**. Dubey (2018).  <https://towardsdatascience.com/the-mathematics-behind-principal-component-analysis-fff2d7f4b643>


üîó **¬´A One-Stop Shop for Principal Component Analysis¬ª**. Brems (2017). <https://towardsdatascience.com/a-one-stop-shop-for-principal-component-analysis-5582fb7e0a9c>

üìö **¬´On the number of principal components: a test of dimensionality based on measurements of similarity between matrices¬ª**. Dray (2008) <https://github.com/dadosdelaplace/teaching/blob/main/bdba-pca-clustering-2022/biblio/numer_pca_dray_2008.pdf>


---
